*[2020-04-12 15:21:58]* **Unknown User**:

MSG NOT FOUND


> *[2020-04-12 22:13:23]* **Mariano Guerra**:

basic viewer: <https://marianoguerra.github.io/future-of-coding-weekly/history/>


> *[2020-04-12 22:13:50]* **Mariano Guerra**:

the not found messages are because they are not on that weeks' history (probably an older message)


> *[2020-04-12 22:31:56]* **Mariano Guerra**:

now with markdown formatting and username replacement


> *[2020-04-12 23:16:48]* **Mariano Guerra**:

which makes me think that it may be really easy to export to a single markdown page :thinking_face:


> *[2020-04-12 23:21:21]* **Scott Anderson**:

Hah, sorry I did this a couple of times when I decided to post links and follow up with more info, my thoughts are I wanted people to see top level context of the link, next time I'll edit the post if I want to add instead of following up


> *[2020-04-13 01:13:31]* **Kartik Agaram**:

Posting definitely preferable to not posting.

---

*[2020-04-12 18:01:39]* **Unknown User**:

MSG NOT FOUND


> *[2020-04-12 23:14:28]* **Sol Bekic**:

I like this idea as well, and #two-minute-week sounds at least fine ;) As for the problem with summaries vs progress-updates, the format could give even more structure: for example the first 30s as a "recap from scratch", the rest of the video for weekly progress. For bigger changes in project direction or progress the intro can be re-made over time or otherwisd reused the following week.

Sadly there is no more support for cards to skip to a position in a YouTube video, but a custom player could fix that...


> *[2020-04-12 23:22:43]* **Nick Smith**:

Maybe it *is* a good idea to have the updates posted all on the same day of the week (a time-zone-friendly 24h window). This induces pressure for people to post things that a “post any time” model wouldn’t.


> *[2020-04-12 23:28:36]* **Scott Anderson**:

I'm fine doing it in a low effort way. When I joined it was impossible for me to share what I was working on because it was all job stuff that wasn't public, so I had to vaguely talk about my philosophy and interest.  Now I'm working on some small, not super interesting but useful to me, tools that I can share semi-regular progress screen shots. Maybe I'll share sketches as well. I don't post in feedback because I don't want feedback on anything I'm working on. It's all personal and only really needs to serve me


> *[2020-04-13 09:00:40]* **Chris Maughan**:

I'm keen to share and get feedback on my work in progress for sure.  I've been thinking about how to do video/twitch/youtube for a while now, so that might be an interesting adventure :wink:  Sounds like a great idea to me.


> *[2020-04-15 08:51:38]* **Vladimir Gordeev**:

Probably people would like to react to these two-minute-week videos. Should we post link to a Slack thread with the video right into newsletter?


> *[2020-04-15 09:17:39]* **Mariano Guerra**:

yes, I will post a link to the video with a title/summary and a link to the thread (it would help if the author provides the title/summary :slightly_smiling_face:)


> *[2020-04-15 15:29:28]* **Ivan Reese**:

I'm thinking I'll just call mine "Week 1, Week 2, Week 3" since I'm not really doing sprints or anything, I'm just working on things for as long as they take.

Anyone else planning to make a video for the channel? (I'm assuming you're all waiting for the imaginary construct known as "the end of the week")


> *[2020-04-15 15:30:28]* **Sol Bekic**:

**Ivan Reese** I will definitely make one, just have to get around to it ;) (and wait for some things I want to mention to be wrapped up)


> *[2020-04-15 15:31:55]* **Vladimir Gordeev**:

I plan to make one


> *[2020-04-15 15:40:32]* **Mariano Guerra**:

imaginary construct guy here :slightly_smiling_face:


> *[2020-04-15 16:04:10]* **Chris Maughan**:

Yes, I'll make one; is there a channel now?


> *[2020-04-15 16:09:40]* **Vladimir Gordeev**:

**`#two-minute-week`**


> *[2020-04-15 16:20:02]* **Chris Maughan**:

Thanks :wink:


> *[2020-04-17 09:55:13]* **Nick Smith**:

I think I need to buy a better microphone :sweat_smile:. I'm also trying to summarise the progress of my project more broadly so I can situate my videos (and start a blog as well).


> *[2020-04-17 10:13:49]* **Sol Bekic**:

**Nick Smith** if you have a decent webcam (and you are not using it to record video already), you can try using it as a microphone a bit more close-up ;)


> *[2020-04-17 10:14:54]* **Nick Smith**:

Ah, I didn't think of that. I have a reasonably good webcam... I should test out its audio quality!


> *[2020-04-17 15:28:05]* **Ivan Reese**:

Yeah, the trick about microphones is that you want them as close to your mouth as possible, ideally about 1" to 4" away (it varies depending on the mic). If the mic doesn't have any wind protection (eg: your breathing sounds loud), you can put it off to the side of your mouth so that it's out of the direct path of air. Even a bad mic up close will make speech easier to understand than a good mic at a distance.


> *[2020-04-17 16:13:57]* **Chris Maughan**:

**Ivan Reese** How do you edit videos?  i.e. which software do you use?  Not something I've really done.  Was thinking iMovie on Mac as a first try; but whatever...?


> *[2020-04-17 16:19:42]* **Ivan Reese**:

A) I put together a page of info you may find helpful: <https://futureofcoding.org/two-minute-week>
B) I will expand that page based on our discussion

I personally use Final Cut Pro X to edit videos, and (sometimes) Ableton Live to process audio. I also kill mosquitoes with a flamethrower robot, yes.

iMovie is fine, I used it for years. But what I recommend is just rehearsing your video, and recording every rehearsal as though it were the real thing. It's a two minute video, so you could probably do 5 rehearsals in 15 minutes. By that 5th one, your delivery will be smooth, exciting, and not need editing (unless you're trying to do multiple cameras or something — in that case, yeah, iMovie is great). That's how I did my two minute video — rehearse it with a stopwatch until it was consistently under 2 minutes, and tight enough that I felt good about what to say and do.


> *[2020-04-18 07:33:05]* **Nicolas Decoster**:

Like **Mariano Guerra**, I am also an imaginary construct guy. And, unfortunately, these times, I am very very busy in some non future of coding project (yes it is sad, but at least I use this as case study for FoC), which keeps me from coming here as often as I want and keeps me from doing thos 2 minutes videos. But I would be happy to try this medium! Hope I will have more time for all this (and to actually work on FoC projects, first of all) in a few months, maybe in June (and maybe *full* time, I can't wait).

---

*[2020-04-13 07:01:26]* **Ivan Reese**:

<https://www.onegraph.com/>

Is this interesting to our community? Asking for a friend.


> *[2020-04-13 07:15:55]* **Vladimir Gordeev**:

not for me


> *[2020-04-13 08:48:31]* **Ian Rumac**:

In a way it is - would be more interesting if we had devs here - how dynamic is this? How much work does it take to implement a new graph? How do users react to it? Are they aiming for devs only or are they going to expand into a no-code like hub?


> *[2020-04-13 16:39:04]* **Shalabh Chaturvedi**:

Interesting query language that just describes the structure of the answer you seek, without the values (GraphQL). Is there a name for this pattern? I generally like the one-graph/one-model approaches. Layering on top of existing diverse APIs could be complex though.

This also reminds me of <https://medium.com/@juancampa/web-apis-game-engines-and-the-universal-inspect-button-4c49eac1073c> - wonder what happened to <http://membrane.io|membrane.io>


> *[2020-04-13 17:13:30]* **Chris Knott**:

I like it. I don't follow the step where he "pastes the query into the app" though - why isn't that shown?


> *[2020-04-13 17:20:19]* **Karki**:

I like it and would like to see more such stuff :slightly_smiling_face:
Anything to do with rapid application development, prototyping is welcome here!


> *[2020-04-14 10:26:47]* **Prathyush**:

The thing of interest could be the idea of interactively exploring an API by tinkering around it: <https://www.onegraph.com/graphiql?shortenedId=A2AFGV>

I like the idea here of progressively drilling down a tree, selecting elements of interest to create a query  just by using mouse &/ key commands. Think of this for a website builder.

---

*[2020-04-11 19:49:30]* **Unknown User**:

MSG NOT FOUND


> *[2020-04-13 09:02:16]* **Konrad Hinsen**:

**Doug Moen** It all depends on what you are doing. With today's state of the art, fixed point is the best choice for dealing with money. Floating point is the best choice for scientific and engineering computing. Rationals are best for symbolic computing. I expect all of them to remain relevant in some context for a long time to come.

Programming languages make some representations easier to use than others, motivated by some specific usage context which is rarely explicitly stated. The Scheme story you cite is a nice example. Prioritizing rationals, as Scheme does, means applying the principle of least surprise with respect to precision. Prioritizing floats, as e.g. Python does, is doing the same with respect to performance. Whichever choice you make _will_ create unpleasant surprises in the other domain sooner or later. It's the job of language tutorials to explain this, but they rarely do because their authors tend to consider their language's choice to be the obviously right one.

More generally, it would be nice if language's engineering tradeoffs were made more explicit. Instead, it's mostly done advertising-style: emphasize the strong points and don't talk about the inevitable disadvantages.

As for fixed-point, all I am saying is that it should be more generally known and better supported, because there are good application domains (such as money) and likely more would be discovered if more people played with it creatively. Example: some people have used it with good results (in terms of performance) in scientific computing, by adapting the scientific models to the available precision. When simulating emergent phenomena, where the low-level details end up being unimportant, this looks like a very promising approach.


> *[2020-04-13 09:09:42]* **Nick Smith**:

I'll also mention I'm very grateful for that paper you linked **Doug Moen**. Oddly enough though, it's not critical of rationals. It actually advocates for a unification of integers, floats and fixed point numbers under the rational umbrella, with the ability to explicitly choose places where rounding should occur in order to seamlessly opt-in to the more efficient machine representations. That's what I'm hoping to do in my own programming language.


> *[2020-04-13 09:14:44]* **Nick Smith**:

Here's the key idea of the paper:


> *[2020-04-13 14:12:38]* **Doug Moen**:

**Konrad Hinsen** said "With today's state of the art, fixed point is the best choice for dealing with money."

I would suggest that for general purpose financial computation, decimal floating point is a better choice. Eg, see <<http://dec64.com|dec64.com>>. That's the format I would choose for a financial spreadsheet app. Fixed point could work if the only operations are addition and subtraction. Even then, arithmetic operations that truncate on overflow would be dangerous for financial computations. But general financial computation also includes interest rate computations, and other related computations, which involve multiplication, division and exponentiation. With fixed point, you would have a much higher risk of overflow or loss of precision for intermediate values in such computations. Decimal floating point fixes these problems.


> *[2020-04-14 12:49:39]* **Konrad Hinsen**:

**Doug Moen** OK, I have to admit that I never do much financial computing except for my very modest personal needs! And decimal floating point, while certainly a promising idea to explore, is unattractive in my corner of the computational universe (scientific computing) as long as it's not implemented in hardware to make it fast.

But I do maintain my suggestion that fixed-point (compiled to integer arithmetic) could find more uses than it has today in scientific computing.

---

*[2020-04-13 14:53:45]* **Vladimir Gordeev**:

stumbled upon this: <https://medium.com/@mrjoelkemp/jvm-struggles-and-the-beam-4d9c58547410>
I think this ability to represent running program spatially, ability to zoom in into any part is something that I certainly wish to have.

---

*[2020-04-13 22:47:08]* **Shalabh Chaturvedi**:

malleable.systems is on HN now: <https://news.ycombinator.com/item?id=22857551>. People really missing what its about methinks.


> *[2020-04-13 22:48:11]* **Shalabh Chaturvedi**:

Previously in slack: <https://futureofcoding.slack.com/archives/C5T9GPWFL/p1584718837435500>


> *[2020-04-13 22:50:55]* **Srini Kadamati**:

yeah … as usual the comments have been less than relevant / interesting


> *[2020-04-13 22:51:55]* **Srini Kadamati**:

I think many folks in HN (at least those vocal ones) have blinders on. Maybe it has to do with the nature of excellence in software development, coming from focus / optimization? Maybe its a cultural thing of just not doing a good job drawing from past CS history or related fields (what could CS possibly learn from carpentry?!) .. but still


> *[2020-04-14 00:41:32]* **Kartik Agaram**:

HN is easy and fashionable to diss, but I found this thread useful. Yes you have to filter, and yes you need some flame-retardant underwear at times, but if you're willing to sift through you get some gems.

Here I'll highlight <https://news.ycombinator.com/item?id=22860549> as surfacing a steelman question I hadn't considered before. One way to keep things malleable is to minimize dependencies. But how do you encourage people messing with your system to also minimize dependencies so they avoid making the sorts of messes Excel is known for?


> *[2020-04-14 00:42:37]* **Kartik Agaram**:

Of course I also enjoyed your comment, Shalabh :slightly_smiling_face:

<https://news.ycombinator.com/item?id=22857551#22861015>


> *[2020-04-14 00:46:33]* **Kartik Agaram**:

I'll put on my flame-retardant underwear to say this, but: I found the HN thread more useful than the post it was commenting on.

_/me ducks_


> *[2020-04-14 03:44:49]* **Dan Cook**:

"People really missing what it's about"

Welcome to the industry :)


> *[2020-04-14 08:15:11]* **Chris Knott**:

Thread was rather ruined by guy from MintData adspamming replies...

I agree though that the comments were very helpful, mainly in highlighting things I strongly disagree with.

Many of their complaints boil down roughly to "non-programmers will get programming wrong", however they display a stunning arrogance that ignores the fact that programmers are likely to *get the actual problem at hand wrong*. This apparently isn't an issue.

e.g. this guy <https://news.ycombinator.com/threads?id=mbrodersen> - _"The real world is complex. The problems software solve in the real world are complex. Economics, sales, politics, personalities, random world events, competition etc. has always and will always be a force pushing software development in non-ideal directions."_

ie. the genuine reality of the world is likely to interfere with the ideal design of the program!!

The solution is that the person who is genuinely understands the issue (the lawyer, the doctor, the plumber) needs to hand control over to a programmer who knows nothing about the actual problem...


Sometimes programmers forget that their only particular skill is being talented at operating a specific kind of gizmo (a microprocessor). It's like yo-yoists suddenly declared themselves the kings of the world because of their unnatural ability of getting yo-yos to do what they want.

Basically this guy is so close but so far. He sees himself as *fundamentally different* from a doctor, due to his ability to reason clearly about the world. But this is wrong. The doctor is likely better at reasoning about medicine than him. He is only better at getting a processor to reflect his mental model, because he is skilled in manipulating this gizmo.

The thing they miss is; they are all "end-users" from some perspective. Are they writing x86 directly? No. Then they are merely moulding some environment created by someone else... </rant>


> *[2020-04-14 12:49:30]* **J. Ryan Stinnett**:

It was definitely interesting to see how a broader audience like HN reacts to the ideas today. :sweat_smile: Some people there are very comfortable with the current world of computing and don't see a need for change, so they indeed seemed to miss the point, but that's probably okay. To be honest, it's very early days for these malleability ideas, so it seems natural. I am sure many people (esp. on HN) might not be interested when there's no startup to back or quick solution to try out today, and that's okay. For now, I'm mainly hoping to reach anyone interested in experimenting with these ideas or wanting to learn more about those who are doing so.

At the same time, there was some good discussion of finer details in a few of the sub-threads, and I hope it has at least planted a seed for people to think about the ideas over time. Even if people disagree or don't see the point in it today, hopefully they are at least now aware that some people do, and may be more open to such ideas down the road.

Since the HN post appeared, a lot of new people have gotten in touch to share their excitement for these ideas, so overall I'd say the HN post was a positive step even if there are many confused people in the comments. Thanks to everyone here who may have waded in the HN comments with their own perspective. :smile:


> *[2020-04-14 12:52:21]* **J. Ryan Stinnett**:

**Kartik Agaram** If there are any elements of the HN thread in particular that might refine how the malleability ideas are portrayed for the future, do let me know so it can be improved. Or if you mean you're just not interested in the topic / not important to you, that's okay too, no hard feelings. :slightly_smiling_face:


> *[2020-04-14 15:53:10]* **Kartik Agaram**:

Oh I'm _very_ interested in the topic. This is why I have strong feelings about it.


> *[2020-04-14 16:46:02]* **J. Ryan Stinnett**:

**Kartik Agaram** Ah great, I wasn't sure how to interpret your statement above "I found the HN thread more useful than the post it was commenting on"... I assume it means you don't find the <https://malleable.systems/> site useful, but you are interested in the topic, so I am curious if you see room for improvement or if you feel a completely different approach is needed. Thanks for your earlier suggestion to add info on trade-offs. :slightly_smiling_face:


> *[2020-04-14 17:27:48]* **Kartik Agaram**:

Yeah, sorry about that :grimacing: [1]. I was referring purely to the narrow subjective feeling I got while reading the prose on both pages. The domain name and the headline resonates strongly. When your previous thread rolled by I spent a lot of time trying to pin down what bothered me about it, and to come up with some constructive feedback. I couldn't think of any, so I chose to err on the side of saying nothing. This time around I'm still unable to be as constructive as I would like, sorry about that. I'm still thinking about this, because it matters a lot to me. I _want_ this page to be superior to drive-by comments by people on the internet.

[1] I come from a culture where feedback is often incredibly subtle, and given with lots of circumlocution. In spite of that I'm a pretty unsubtle guy. The result: many times in my life I've failed to heed warnings that (to others) seemed really repeated and increasingly unsubtle. This still happens, even after I moved to the West. As a result, I sometimes accidentally come across as overly harsh without intending to, the way someone may speak overly loudly if they can't hear themselves. At other times, I consciously err on the side of harshing, just to make a contrast really obvious and make sure that others don't end up in the failure modes I've found myself in.


> *[2020-04-14 23:53:55]* **J. Ryan Stinnett**:

**Kartik Agaram** Thanks for the detailed reply! That helps me understand your perspective. If you happen to think of changes down the line or would like to contribute a post on the site, feel free to react out. :slightly_smiling_face: 

It might be interesting for someone (other than me) to write an “anti-post” on the blog synthesising all the ways it will “definitely never” work... :thinking_face: It would be good to have another voice in the spectrum of perspectives represented. I think such a post would just inspire me further to prove it can be done. :sweat_smile:


> *[2020-04-15 07:42:04]* **Kartik Agaram**:

I don't feel that it will definitely never work. I think it _has to_ work, because the alternatives all suck. What I share in common with your hypothetical interlocutors is the unspoken question, "how could this _possibly_ be made to work?"

In <https://futureofcoding.slack.com/archives/C5T9GPWFL/p1586869277389100?thread_ts=1584718837.435500&cid=C5T9GPWFL> you suggested that you're trying to separate goals from solutions and focus on the former. That's reasonable as a goal for this particular page. (It's also why I find this page unsatisfying.) But it also seems reasonable for it to trigger conversations about the how. That doesn't feel like "missing the point". Isn't that sort of conversation what this page is designed to engender?

Perhaps it will help to triangulate by bringing up my mission: <http://akkartik.name/about>. Not to brag, but we're attacking highly overlapping if not isomorphic problems. By definition I should have addressed any shortcomings I bring up here. It stays high-level, focuses on goals, but also indicates the sorts of trade-offs I'm willing to make. I'd love to receive similar criticism from you about what it's lacking. I should probably update it after my recent efforts writing my paper :sweat_smile: It's quite possible there's a cultural chasm here from me spending too much time on HN. I'd love to understand it better.

Perhaps it would help to drill down into which comments you consider to be missing the point. It might require a private conversation, but it might help make this conversation more concrete. Here, I'll start by summarizing how I view the top-level comments:

<https://news.ycombinator.com/item?id=22858254>: neutral sentiment, acknowledges you're stating an unpopular opinion, responds with another. Seems useful for generating ideas, and -- reading between the lines -- sympathetic.

<https://news.ycombinator.com/item?id=22859409>: negative sentiment. I would steelman it ("what could this be true of?") as asking a) do you propose limits to extensibility, and b) how do you imagine the system as a whole self-regulating in response to bad changes? That seems useful, even if it's not phrased constructively.

<https://news.ycombinator.com/item?id=22862292>: not useful, as **Chris Knott** already pointed out.

<https://news.ycombinator.com/item?id=22859613>: positive sentiment. Points out the future is already here, maybe just not evenly distributed.

<https://news.ycombinator.com/item?id=22874983>: negative sentiment, but suggests that your problem statement needs focus. Seems like useful feedback.

<https://news.ycombinator.com/item?id=22858315>: neutral sentiment, draws a connection with another story on the frontpage to highlight a trade-off. Super useful, to my mind. Engendered a response (<https://news.ycombinator.com/item?id=22858888>) from someone seemingly ripe to join the movement.

<https://news.ycombinator.com/item?id=22858897>: neutral sentiment, brings up Plan 9 as prior art. My favorite sub-thread, if my actions are any guide. (Plan 9 isn't a major obsession of mine.)

<https://news.ycombinator.com/item?id=22864602>: negative sentiment, airs a conservation of complexity argument that might be worth addressing head-on. Maybe you need a FAQ?

Other people making positive noises in startlingly diverse choices of words:
* <https://news.ycombinator.com/item?id=22862660>
* <https://news.ycombinator.com/item?id=22859957>
* <https://news.ycombinator.com/item?id=22862143>
* <https://news.ycombinator.com/item?id=22872606> (supporting the right to make a mess)

<https://news.ycombinator.com/item?id=22859278>: Someone being politely skeptical _by using Rails as an example_. So they're missing the point a bit, thinking about how opinionated you should be _after you have achieved malleability_. Still kinda interesting to me.

This is just the top-level comments, but at a glance the responses in the major sub-trees seem to mostly be ping-pong rebuttals. So to first approximation half the comments are supportive of the endeavor!

Overall, there's a refreshing lack of "startup mindset" in this thread, particularly if -- like me -- you go in expecting 90% of everything to be crap. Nobody's asking you how you make money, or to to define a market, or to tweak the website. Great example of my thesis that HN is really 2 or 3 mostly-decoupled communities.


> *[2020-04-15 16:06:51]* **Shalabh Chaturvedi**:

>  HN is easy and fashionable to diss, but I found this thread useful. Yes you have to filter, and yes you need some flame-retardant underwear at times, but if you're willing to sift through you get some gems.
Just wanted to say I generally agree with this, which is why I go to HN :smile:. I guess I was just expecting to see a higher 'hit rate' with this post.


> *[2020-04-15 16:07:15]* **Shalabh Chaturvedi**:

FWIW, **Konrad Hinsen**’s Emacs write-up is on HN now: <https://news.ycombinator.com/item?id=22875106> [edit: oops, fixed link to HN]


> *[2020-04-15 16:39:37]* **Konrad Hinsen**:

Thanks for the pointer (I don't follow HN much these days). It's a pity that most comments focus on comparing Emacs to other text editors with little reference to malleability!


> *[2020-04-16 04:10:04]* **Dan Cook**:

**J. Ryan Stinnett**: "anti-post" - You mean like BV's "Future of programming"?

<https://youtu.be/8pTEmbeENF4|https://youtu.be/8pTEmbeENF4>


> *[2020-04-19 21:17:47]* **J. Ryan Stinnett**:

**Dan Cook** Ah, that video's more like history plus an alternative universe, but that would also be interesting, yes! :smile: For "anti-post", I was thinking something like "malleability will never work because X, Y, Z, ..." (hopefully as something longer form like a blog post where there's more to think about than your typical HN comment).

---

*[2020-03-20 15:40:37]* **Unknown User**:

MSG NOT FOUND


> *[2020-04-14 03:38:47]* **Kartik Agaram**:

Potential case study in recovering malleability from existing software, **J. Ryan Stinnett**: <https://mastodon.social/@akkartik/103994830568601931>.

In general, the thing I find missing in the <https://malleable.systems> mission (and manifestos in general) is any mention of trade-offs. What are we willing to give up to achieve the stated goals? In this case study, malleability is only possible when we control the size and complexity of our software stacks. That might be a common compromise.


> *[2020-04-14 13:01:17]* **J. Ryan Stinnett**:

**Kartik Agaram** Thanks, that's a good point. So far the mission has been focused on the ideals and goals without proscribing solutions, so I wasn't sure if trade-offs would make sense there.

But indeed, there may be common trade-offs that come up across different approaches. Seems like a good subject for a new post, so I filed an issue: <https://github.com/malleable-systems/malleable.systems/issues/13>


> *[2020-04-14 13:12:39]* **Konrad Hinsen**:

Yes, trade-offs are an important point. In my guest blog post (<https://malleable.systems/blog/2020/04/01/the-most-successful-malleable-system-in-history/>) I point out one of them, which is responsibility for the overall system. If you let users mess around with it, you can't then let them sue the original authors if it breaks. And if you let people distribute their own add-ons, that makes three parties among which responsibility must be divided in some way.

Size and complexity are also an issue, but less so if you get away from the assumption of a software _stack_ implying vertical dependencies. Replace this by a network of modular subsystems with reasonably stable APIs, and you can have malleability for the whole system and for each subsystem. Do it recursively and you can perhaps scale to really big and complex stuff (though I am obviously speculating here).

Sure, we have no technology for building systems out of modular subsystems. That remains to be done.


> *[2020-04-14 18:55:10]* **Edward de Jong**:

Anyone arguing that Emacs is a successful product is way off-base. Emacs is a disaster as a user interface. That nerds endure it is testimony to how some people have great memories and enjoy obscure powerful things. 99.9% of humanity rejects Emacs as a reasonable interface for editing. Having worked in word processing and desktop publishing for years, it was obvious from the first version of WordStar, followed by WordStar 2000, DisplayWrite, WordPerfect, then to FrameMaker, Quark xPress, InDesign, and the ubiquitous MS Word, a nice graphical interface trumped the archaic-but-powerful Emacs.  AutoCad which also included LISP inside its system, is a far better example of a successful malleable product that still has a strong company (AutoDesk which has hundreds of employees and a hefty market cap).

Emacs if you tried to sell it would go out of business fast.


> *[2020-04-15 08:40:09]* **Kartik Agaram**:

I spent all day thinking about this, and finally found words to articulate hopefully half of what I intend to convey: <https://github.com/malleable-systems/malleable.systems/issues/13#issuecomment-613900649>. Hopefully I managed to walk the tightrope between showing vehemence and just being harsh.

---

*[2020-04-11 20:19:23]* **Unknown User**:

MSG NOT FOUND


> *[2020-04-14 10:22:29]* **Prathyush**:

The problem here is that very few programmers me included are competent/bothered enough to get an outline or grasp on these matters and dig down to understand what it means.

So we are all but relegated to sit on the gallery watch a few illuminated people who have differing level of understanding on these issues debate the very important issues with a semblance of enjoyment derived from the rhetoric devices they employ to pick apart these conceptions.

---

*[2020-04-14 23:22:44]* **Stefan Lesser**:

I came across a PICO-8 tutorial today. While I was aware of the platform, I didn’t know much about it. What I found most interesting is that the limitations, in particular the restriction to 8192 “tokens” that your Lua source code can maximally have, made the person conducting the tutorial optimize the code several times to reduce the number of tokens used. He achieved that mostly through basic refactoring, often using the DRY principle, but also sometimes making the code a little more concise/clever/obscure.

This (artificial) limitation adds a dynamic to development for PICO-8 that I find fascinating. It adds a forcing function for “keeping code lean” which I haven’t seen like this anywhere else. The only other similar thing I can think of is the 140/280 character limit on Twitter. Or maybe demoscene contest categories that limit the code and/or binary sizes to a certain amount of bytes.

Do you know of any other programming environments or IDEs that use soft metrics or hard limits or any other tricks to introduce an awareness for wastefulness to programming?
And how do you feel about that as a means to improve code quality?


> *[2020-04-14 23:23:51]* **Stefan Lesser**:

About PICO-8: <https://www.lexaloffle.com/pico-8.php|https://www.lexaloffle.com/pico-8.php>


> *[2020-04-14 23:35:28]* **Kartik Agaram**:

Minor counterpoint story: My Mu project leans heavily on projects like the bootstrappable compiler (<https://github.com/certik/bcompiler>) and StoneKnifeForth (<https://github.com/kragen/stoneknifeforth>) which impose draconian limits on lengths of various names.

In Mu I went the route of having no such limit, and having long names like <https://github.com/akkartik/mu/blob/0671315c1af4707fcab30b11967c88fbaa386bf3/085next-word-or-string.subx#L353> made a huge difference in making the setup feel more ergonomic, so that I wasn't immediately hankering for something better the moment I got it working.

The net effect: someone coming to my project only has to learn 2 notations, unlike in other bootstrapping projects where they have to learn 4 or 5, because the bottom two were built so parsimoniously that they're no fun to program in at all.


> *[2020-04-14 23:36:00]* **Kartik Agaram**:

Constraints can be very useful. But the devil is in the details of which constraints you choose and how they interact in the big picture.


> *[2020-04-14 23:39:03]* **George Campbell**:

Android’s VM has a 64K method limit that results in tech to remove unused bits of code. <https://developer.android.com/studio/build/shrink-code.html#shrink-code>


> *[2020-04-14 23:50:48]* **Ivan Reese**:

One of the things discussed on the last episode of the podcast is Devine's interest in keeping the core of Orca small (around 600 LoC in the original JS, if memory serves) to make it easier to port to other languages. And the things you make in it are severely limited by the amount of screen real estate.


> *[2020-04-15 01:47:03]* **Scott Anderson**:

If anyone hasn't seen Joseph White's practice talk explaining the Pico8 design philosophy definitely check it out


> *[2020-04-15 01:47:05]* **Scott Anderson**:

<https://youtu.be/87jfTIWosBw|https://youtu.be/87jfTIWosBw>


> *[2020-04-15 01:47:44]* **Scott Anderson**:

I feel like I've linked it here before, but it's worth bringing up again in any Pico8 design discussion


> *[2020-04-15 01:47:58]* **Scott Anderson**:

Or fantasy console discussion


> *[2020-04-15 01:50:59]* **Scott Anderson**:

I really loved the Orca podcast, I think that idea of keeping software small is really powerful for longetivity


> *[2020-04-15 01:57:50]* **Scott Anderson**:

Software tends to rot without maintenance, open source is one way to encourage continual maintenance, but another way is to make a system where the core is understandable enough that it's non-trivial to completely reimplement it if you've used it


> *[2020-04-15 01:58:31]* **Scott Anderson**:

(reminds me that it'd be a fun excersize to reimplement orca based on docs)


> *[2020-04-15 06:10:19]* **Edward de Jong**:

There is an irreducible limit to the size of any given program. Part of it is due to Ashby's law of requisite variety (see Stafford Beer, Platform for Change), but a lot has to do with the compactness of the notation, and the ease with which redundancy is squeezed out. It is a very interesting exercise to study simple projects and boil them down to near the irreducible minimum. In fact, this is how i designed my Beads language; by starting with projects and then designing a notation that would allow for minimal number of words to express that action. The beauty of less code is there is less chance for error, provided you haven't over minimized and obscured logic by blindly pursuing word count as the goal. One must always balance readability with compactness. This was the original mistake of Iverson, which took him a long time to realize, that APL's invented alphabet was obscuring the power of his language (hence his use of ASCII in the J language sequel to APL).


> *[2020-04-15 14:32:35]* **Doug Moen**:

ColorForth takes this idea of "creative limitation" farther than any other language I can think of. <https://colorforth.github.io/cf.htm>
• The language is written using 48 ASCII characters, which enables you to code using a special keyboard layout (if you like) where your fingers never leave home row.
• Identifiers are typically limited to 6 characters. They must fit into 32 bits after being compressed using "Shannon coding".
• Source files are called "blocks" and are limited to 256 "words". An entire block fits on the screen at once, so there is no need for scrolling.
• Function definitions are typically 1 line long. That's not directly enforced, but Forth code becomes increasingly hard to decipher when functions are longer than this.


> *[2020-04-15 19:05:29]* **Edward de Jong**:

FORTH and its cousin Postscript are very compact languages. I think FORTH is probably the most compact language, but also very difficult to read, as effectively you are pushing things into the stack, and you have to memorize how many items on the stack are consumed by each operator. APL had built-in graphing which was wonderful in its day (character graphics based plotting!), so it became more popular. FORTH was targeting embedded systems. If i am not mistaken it was invented for telescope control. FORTH was actually embedded into each Microchannel board; the Microchannel architecture was invented by Data general, and then licensed by IBM for their PC. The beauty of that architecture was that the boards each had some firmware on them, written in FORTH that would negotiate for interrupt vectors and low memory space. They needed a super compact language, so they used FORTH. But the terrible readability has hindered FORTH's general commercial use. I am surprised at how little people use J and FORTH given that they both work very well, and are super powerful. If you are doing a one man project, you might not care about readability. Perhaps it is all the hoopla around functional programming that makes people ignore these very interesting languages.


> *[2020-04-16 10:32:33]* **Stefan Lesser**:

**Scott Anderson** Thanks for sharing that talk. I hadn’t seen it. I obviously love how he approached the design of his fantasy consoles. So many thoughtful design decisions! For instance moving from a character limit to a token limit to rectify a bias towards minification and encourage shareable code. Love this stuff.


> *[2020-04-19 18:01:07]* **Kartik Agaram**:

I'm watching Joseph White's talk now. I really like his phrase "careful friction".

---

*[2020-04-15 03:44:54]* **Justin**:

This is a great article that touches on psychology, languages, and language
<https://medium.com/@old_sound/programming-languages-are-not-languages-c6f161a78c44>
P.s. those references are :heart_eyes:


> *[2020-04-15 06:04:15]* **Edward de Jong**:

The German philosopher Heidegger believed thinking is speaking to yourself, and that there is no consciousness without language.  Computer languages are languages, just ones with very few nouns. If you carefully examine the task of learning a new language, you have a few dozen numeric primitives, perhaps 500 total verbs, of which you only use about 50 regularly. But then you hit the nouns, and there a million of those. Human languages have a name for all sorts of parts of things. A computer is such a simple universe there aren't even 50 nouns. So they seem very different, but really it is just the giant pile of nouns that makes human languages seem so complex. But the complexity level of grammar of computer languages is pretty comparable.

His point that various build and make tools often require a different tool or language is not always true. It just happens that language designers are sometimes shortsighted, and also because of OS idiosyncrasies which require customization for packaging. I find some of the build tools to be so hard to use that i don't even bother learning the language.


> *[2020-04-18 05:04:16]* **Kartik Agaram**:

I spent a while a few years ago intensively thinking about the difference between languages and tools. But I never considered these terms themselves as _analogies_ when applied to programming. Extremely useful article.

But calling programming languages 'tools', while useful once I think of it as an analogy, still leaves a lot on the table IMO. A tool as we usually conceive of it typically has only a few degrees of freedom. Think of your hands, or a screwdriver, or MS paint. But the state space of a programming language is much more vast and non-linear. The mental image I find most useful is of a language as a little universe being born, budding off from ours through a tiny wormhole that can only transmit information at 48 baud.

Perhaps we need a neologism. I like conlangs and esolangs. Perhaps we need _proglangs_, parasitic constructs off natural language with many attributes of tools but nonetheless vast state spaces more akin to languages.


> *[2020-04-19 09:35:30]* **Nicolas Decoster**:

In fact in french, there are two words: _Langue_ for natural language and _Language_ which is more general and that comprises also formal languages.


> *[2020-04-19 09:53:05]* **Nicolas Decoster**:

And looking for some distinctive characteristics between natural and formal languages I have just came across the notion of "double articulation", or "duality of patterning" which is specific to human language (or speech) and might allow a "potentially infinite number of meaningful language sequences" (citing wikipedia page). There is an articulation of "tokens" that carry meaning like "cat" in "the cat is sleeping". And token that carry no meaning, like sounds or letters, the "c" in "cat" which carry no meaning at all.


> *[2020-04-19 10:07:23]* **Nicolas Decoster**:

This second category of "token" is called "Figurae", and I find the wikipedia page about it very interesting. One of the examples is "three-horizontal-band" national flags (like Russia) : for analysis of those flags a given horizontal-color-bar is a figurae. It as no meaning itself, but the meaningful Russian flag is a given combination of three of them.


> *[2020-04-19 10:11:46]* **Nicolas Decoster**:

I like the term "Figurae", as it feels to me more general and not tied to text languages.

---

*[2020-04-15 13:27:24]* **Josh Cho**:

Are there any languages with explicit focus (and philosophy) around intermediary steps between ideas and working code? Modern programming languages feel like I must, in part, produce completed structures of code, rather than brainstorming and exploring. Programming inevitably alternates the code from working to not working to working to not working, etc, and we would benefit from languages that were more explicit about facilitating the ‘not working’ states. From my rough intuition, the ‘not working’ states of code outweigh ‘working’ state in terms of time and importance (e.g. compiler for code that is exploratory but does not work).

REPL, for a very simple idea, is praised so much (and so widely used) perhaps for this reason — it facilitates intermediate steps. This would be a rough parallel to how Bret Victor mentions that “ideas are important” to him. I looked at <https://medium.com/bits-and-behavior/four-years-of-studying-exploratory-programming-4656586b1d3b|Exploratory Programming>, but it doesn’t seem to capture exactly what I want (i.e. goes a bit too shallow).

EDIT: Also relevant, <http://tomasp.net/histogram/|Histogram> and <https://youtu.be/X36ye-1x_HQ?t=1273|Type-driven Development>


> *[2020-04-15 13:34:29]* **Mariano Guerra**:

<https://hazel.org/> has first class concepts of errors (missing code, binding errors, conflicts, type errors)


> *[2020-04-15 13:35:26]* **Mariano Guerra**:

unison promises that your code is always in a valid state: <https://www.unisonweb.org/docs/tour/>


> *[2020-04-15 13:36:00]* **Mariano Guerra**:

dynamically typed languages support incomplete programs as long as you don't step into the incomplete code :slightly_smiling_face:


> *[2020-04-15 13:36:25]* **Mariano Guerra**:

in smalltalk there's people that fill the code as they go in the debugger


> *[2020-04-15 13:42:00]* **Vladimir Gordeev**:

I think **Josh Cho** is saying that during development you try out many ideas and finally get to working code. Working code is checked in to VCS, while all these steps to this working code are lost, while they might be the most valuable to learn.

Am I right?


> *[2020-04-15 13:57:30]* **Josh Cho**:

Yes **Vladimir Gordeev**, not to get too philosophical, but humans always focus more on what is than what is not (i.e. yin-yang). So we are bound to focus on what works, our successes, rather than what does not work, our failures, or our intermediaries. This kind of human bias/inevitability is bound to be present in computing, which is often too fast for its own good.

Maybe we can step back a little and think about the in-between…? <http://tomasp.net/histogram/> is the only instance where I have seen anyone do some thinking like this to a sufficiently satisfying extent.


> *[2020-04-15 13:58:30]* **Josh Cho**:

**Mariano Guerra** I am looking at Unison right now for the first time and it’s very interesting. Scratches as an alternate to REPL might have some interesting ideas in this space.


> *[2020-04-15 14:01:57]* **Sol Bekic**:

"Livecoding" is about continuously modifying the code as it runs. This doesn't necessarily improve the experience with having non-working code, but it does let you work with partially-working code and "code as you go". The system I am working on (<https://alive.s-ol.nu>) takes an alternate approach to the common REPL-based livecoding that supports continuously changing FRP programs at runtime.


> *[2020-04-15 14:03:09]* **Josh Cho**:

The psychological equivalent would be how long it takes for our nonverbal, implicit ‘thoughts’ or qualia to become verbal, explicit <thoughts>. We have intuitions before explicit thoughts, and modern psychology has focused too much on what can be observed (verbal thoughts, or even worse, behavior) that it has missed out on large portion of our psyche.

Intuition precedes thoughts, but we only observe thoughts because they are easy to observe.


> *[2020-04-15 14:07:40]* **Josh Cho**:

**Sol Bekic** Yeah live-coding or even something like Orca (which has no distinctive distinction between code and output) are also important in this space. But I think we can definitely go further — the idea is simple but its adoption is surprisingly slow. I think this shows how people are willing to just withstand discomfort of ‘not seeing’.


> *[2020-04-15 16:09:19]* **Will Crichton**:

I would separate methodologies that structure process from languages that enable (or make easier) aspects of process. Type-driven and test-driven development are both methodologies that focus on incrementally developing a program specification through types or tests.

A language like Idris or Hazel supports type-driven development by having an explicit notion of holes. A language like <https://www.pyret.org/|Pyret> supports test-driven development by allowing unit tests to be co-located with functions.


> *[2020-04-15 17:34:44]* **Ivan Reese**:

There's also an entire discipline and ecosystem around non-functional or minimally-functional prototypes. There's paper prototyping, wireframes, modern HyperCard-like tools — hell, the UI prototyping group at Apple used to (maybe still does) use Keynote presentations for user testing because they're so much faster to make, and you can do a bunch of tricks to make them feel like a working app.


> *[2020-04-15 23:49:06]* **Chris Rabl**:

was thinking about "comment-driven development" a while back and came up with this sketch: typically when i'm writing a complex series of transformations, i'll write out all the steps in individual comments and then "fill in the blanks" with code once i have an outline for the whole transformation. would be interesting to have the comments exist as "blocks" that could be expanded and contracted (and nested?) so you'd be able to zoom out and see the entire system at a glance without looking at the code


> *[2020-04-16 05:43:47]* **Don Abrams**:

Similar to this is gradual typing where you start "sloppy" and gradually add guarantees to your code. It's an area of active research (typescript being the most well known)


> *[2020-04-16 05:48:37]* **Don Abrams**:

It all depends on your definition of working. We could easily make a language where every library/function had a default (noop) and only good states could be entered (like scratch). But does it really help you sketch out your idea?


> *[2020-04-16 14:58:13]* **Leonard Pauli**:

(**Chris Rabl** I'm working on something like that! I imagine there is a gradient from detailed/machine code implementation - to abstract/natural language description; Imagine if you're able to start out each "block" at any level, and then iteratively add details as needed. Combine that with an auto-complete that works more like google search than word completion, but context sensitive, and somewhat semi-structured such that some computer-processable "meaning" may be derived (declarative probably preferred); Then, the "comments"/most abstract/top-most (as in top-down) "notes" would "always" be "in sync" with the implementation, and you'd have something "useful" at each level of detail)


> *[2020-04-16 15:36:14]* **Chris Rabl**:

i've been using "outliner" apps for the last few months (OmniOutliner, specifically) to jot down thoughts and keep notes in a more structured way. what i've found is that the outline medium contributes greatly to the breadth of what i'm trying to express and allows me to both dive deeper to add detail or collapse elements to see the bigger picture. (which is tangential, but related to what **Don Abrams** said about starting "sloppy" and adding guarantees). as far as what you're building **Leonard Pauli**, it seems like the real utility there is in the comment blocks that you get "for free" as a result of building them first. a point of contention though: how do you make sure that when you change the code at a lower level, that it will "line up" with the comment you wrote before? what happens when your mental model for how it _*should*_ behave or be built differs substantially from how you actually end up implementing it? the nice part about using types as your guide, as Don alluded to, is that they are an intrinsic part of the code: if the types don't line up with the values you're passing in, your program won't compile. how can we make the same guarantees for natural language?


> *[2020-04-16 15:38:14]* **Don Abrams**:

Yeah, sadly they are usually "adjunctions" rather than "isomorphisms" (sorry for the vocab)


> *[2020-04-17 19:35:34]* **Leonard Pauli**:

I suppose you could be confusing and say define "yes" as "false" on a lower level, if the editor doesn't already have a relation between those two "concepts", though the system would still be "consistent".

For the "comments" to be in sync with the implementation, they have to be connected somehow. Ideally, the "comments" would be isomorphic to the actual implementation. One end, natural language/plain text, the other end, binary machine code. Typescript types allows you to get closer to NL, though I want to get even closer. My current plan is to sacrifice NL free-form, thus gaining realistic ability for structured representation of the "comment", that then "becomes" the implementation. Instead of trying to solve "complete NLP",  the autosuggestion will (hypothesis) push you into using a parsable format. Thus, you'll get 80% of the way with 5% of the effort. As with types, the words you use will either have to be explained further, or linked to existing concepts, until you reach the base types. As with "io-monads are not necessary in a complete system", this might maybe only work fully where everything is declarative. The outline is really a graph structure, where one node may exist in multiple places, and be aliased to fit the context/DSL. If you change the meaning of a concept, you'll see all its names, and possibly choose to change them (the name or the connection).

Though this is not a sufficiently complete solution... A theory is that the "next big FoC paradigm shift" would require quite a lot of parts coming together and contributing natively to each other. Many ideas might be "interesting" on their own, but in isolation, they provide less value then the current status quo. I've often found it hard to communicate certain aspects of the system, as you would have to imagine all parts being there at once. (saw a quote by Tim Berners-Lee, stating that he had to mask the web as a documentation system and build it for real, as stakeholders couldn't fantom to imagine it filled with all the sites we have today, and thereby not recognizing its potential). Though when all the components connect, you get something "many magnitudes better" than what we have today. Well, that's the idea at least :)

---

*[2020-04-16 05:20:14]* **Christopher Galtenberg**:

<https://twitter.com/jonathoda/status/1250477469032996872|https://twitter.com/jonathoda/status/1250477469032996872>

---

*[2020-04-17 04:59:32]* **Kartik Agaram**:

Don Knuth: _"The Art of Computer Programming is a manifesto. It describes the way I love to do math and the way I wish I had been taught."_ :thinking_face:

<https://www.quantamagazine.org/computer-scientist-donald-knuth-cant-stop-telling-stories-20200416|https://www.quantamagazine.org/computer-scientist-donald-knuth-cant-stop-telling-stories-20200416>

---

*[2020-04-17 12:43:28]* **undefined**:

I'm building my FoC project in a


> *[2020-04-17 15:24:32]* **Chris Maughan**:

How do I say 'both' :wink:


> *[2020-04-17 15:25:01]* **Chris Maughan**:

Ah, I can click both, fine :wink:


> *[2020-04-17 15:47:13]* **Kartik Agaram**:

Yeah, same here.


> *[2020-04-17 15:49:20]* **Doug Moen**:

Both for me, too.


> *[2020-04-17 18:23:51]* **Shalabh Chaturvedi**:

"it's complicated"

---

*[2020-04-17 15:24:10]* **undefined**:

...And my FoC project has a


> *[2020-04-17 18:26:35]* **Chris Granger**:

It's static, but entirely inferred so I'm not sure it carries the implication that you'd take from it having a "Static Type System"


> *[2020-04-17 21:49:22]* **Ivan Reese**:

**Doug Moen** and **Jimmy Miller** — you're both building projects with a dynamic type system, using a statically typed language. On a cursory consideration, that feels very against-the-grain. Care to share your reasoning?


> *[2020-04-18 00:02:11]* **Tim Babb**:

I have Chris's case too, but also if a type can't be inferred/narrowed statically, it reverts to dynamic


> *[2020-04-18 02:06:10]* **Doug Moen**:

**Ivan Reese** I'm building a runtime and virtual machine for a dynamically typed language. That is normally done in a systems language like C, C++, Rust, Zig, so you can have performance. Look at Python, Ruby, Javascript, Perl, etc, that's how it's done. I picked C++ because I'm familiar with it, but also because there are a lot of specialized 3D graphics libraries I'd like to link with that are in C++, and not replicated in other languages. Rust would be my second choice because there are an increasing number of interesting Rust crates for programming GPUs. C++ and Rust are both horrible, complex languages, with slow compilers, that kill your productivity. Any alternative language that I could switch to would be better in some ways, but would lock me into an ecosystem that would make some things I want to do extremely difficult or impossible. What if I want to build a small and performant native app, or a small and performance WebAssembly module, containing my language? Will Haskell or Python or Racket or O'Caml or Pharo get me there? I feel there are no good choices of implementation language.

My language is dynamically typed because I prefer dynamic typing, it's easier to implement a dynamically typed language, and it's the best choice for exploratory and live programming. Curv is a language for making art, not for _deploying applications_ on a _server_, so why do my users need static typing?


> *[2020-04-18 02:08:38]* **Doug Moen**:

Since this is Future of Coding, maybe we can discuss the ideal FoC implementation language for building your new language. Maybe we can design it and implement it as a group project. :grinning:


> *[2020-04-18 02:13:06]* **Ivan Reese**:

Re, your first comment: Ah, that all makes perfect sense.

Re, your second comment: I can't tell if this is a recursion joke or a serious suggestion. If it is a serious suggestion, I'd suggest starting a new thread with what you have in mind. I have it on good authority (ie: forthcoming survey results) that there are a lot of folks here looking to collaborate on a project, just waiting for someone to issue the call to arms.

---

*[2020-04-17 18:21:07]* **Daniel Garcia**:

<https://twitter.com/rsnous/status/1219926954633129984>


> *[2020-04-17 18:31:33]* **Timwithlip**:

I think it's inevitable if the early users are incentivized to have their early expertise via means of their own economic survival. At the same time this also makes sense, because there's always a risk in trying something new, there also needs to be a reward.


> *[2020-04-17 20:59:54]* **Alex Wein**:

SQL actually is used by non-developers.  When I search indeed (SF bay), I'm seeing a pretty broad range of roles, including one in Customer Support on the first page of results


> *[2020-04-17 21:17:15]* **Daniel Garcia**:

A point to note in that job post is: *basic* SQL queries. So, *some* SQL is used by non-developers


> *[2020-04-18 00:13:53]* **Tim Babb**:

I've come to believe that any system which requires mental simulation of a complex process that can't be seen will always remain exclusive to "experts".

Textual coding (including SQL) requires this in at least two ways: mentally simulating a parser/lexer, and then mentally simulating the process described.

Mentally simulating something complex and invisible (playing chess, coding, math, chemistry, counting cards, ...) probably can't ever be done without extensive training. I think because of that, it will only be done by those with extremely strong need for it (i.e. high enough to justify hundreds of hours acquiring a new skill), or who are lucky enough to find the effort of training rewarding in itself instead of a cost.

Also it's a core thesis of mine that simply making the invisible, mentally-simulated stuff _visible_ could massively lower the barrier and admit many more people into the field!


> *[2020-04-18 04:35:19]* **Stefan Lesser**:

That quote about SQL is from a reunion in 1995 reminiscing about what… the early 70s? Given the user interfaces and interactions at the time, I’d say they did a pretty good job!


> *[2020-04-18 17:23:21]* **Tom Lieber**:

I know people with multiple degrees who struggle to connect HDMI cables, a task barely more difficult than a square-peg-square-hole baby toy. When it comes to getting started, it's not about how difficult the task is, but the narrative the person has about the task.

You can _tap and click_ stuff today, so people's narratives about _typing_ stuff has changed. At the time SQL was invented, a non-programmer would be what—someone who could use DOS but not Fortran or BASIC? If Phyllis Reisner ran the same human-factors tests today, SQL would probably appear to be less usable than it was in the '70s. Actually, that'd be a fun study. :laughing:

Out of curiosity, I browsed a few beginner SQL tutorials just now. Five didn't say anything how easy it is to get started with SQL, or imply in any way that SQL was designed with human factors in mind. The sixth does point out that, hey, there's a million database software packages out there now and most have custom commands, but all you gotta learn is six commands (with a list of their simple, evocative names) and you'll know pretty much everything you need to know about SQL. Now that's a tutorial for non-programmers about a language designed for non-programmers.

---

*[2020-04-18 03:16:30]* **Nick Smith**:

I've spent the last few days considering starting a blog, but I'm encountering a moral dilemma.

I think humanity already overshares too often. I think we put a lot of half-baked thoughts in the public space, and the world consequently suffers from "information overload" where we can't figure out what to pay attention to / what is valuable. It happens in news media, social media, blog posts, and this Slack. In this Slack, the main instigator of discourse seems to be the posting of links (65% of posts in the last 3 weeks). How much time are we wasting on distracting tidbits of public information?

So when I'm drafting ideas for a blog, I'm encountering this worry that my half-baked thoughts will just be further distractions. Notice that Bret Victor, who many of us here appreciate, doesn't have a blog. He doesn't share ideas until he's sure he has a valuable, coherent message, and sometimes he spends years preparing his next message. Perhaps this is the best way to communicate.

Of course, many of us want to share ideas so that we can, in effect, "work together" on the future of programming. I think collaboration is valuable, but perhaps public communication is not the best way to do this. In a private setting, discourse is informal, and half-baked ideas can be happily lost to history. When people work together privately, they can filter through ideas rapidly, and only publish information when they have a battle-tested, coherent message.

Unfortunately, private collaboration is still most effective in person, because humanity doesn't yet have the technology to digitize the experience that physical workplaces provide. Perhaps an in-person communication style is nevertheless one we should aspire to, to prevent the dissemination of half-baked ideas. I don't know how best to achieve this, but **`#two-minute-week`** seems compatible, at least.

It's also unfortunate that our societal structure isn't conducive to the formation of altruistic "working groups", which would be the ideal collaborative environment, but that's a whole separate discussion which we've touched on before.

Thoughts?


> *[2020-04-18 03:36:39]* **Dan Cook**:

I also think the two minute week idea is a great step in that direction


> *[2020-04-18 03:46:50]* **Kartik Agaram**:

It is indeed a dilemma. There's a tension between seeking serendipity and adding noise. The good news, as I see it: it's not a very important dilemma. We don't have to optimize it just right. It's enough to satisfice. If people don't complain, you aren't oversharing, and so you shouldn't worry about oversharing.

The effects of noise are cumulative. Each new piece adds a little bit of downside. But the potential upside is very great if you find a Lennon to your McCartney. So it's better to err on the side of oversharing, IMO.

Sharing is naturally regulating: if you don't get much response you'll naturally slow down. At least if you don't start watching artificial metrics like analytics or reshares or whatever. I just focus on what makes the good conversations happen, where I end up with some extra clarity inside my head.


> *[2020-04-18 03:48:43]* **Timwithlip**:

I think it's a matter of scale. Our brains are for the most part evolved for communities of 150 people. We should share often with those closest to us. Do we really need to have 1,500 people sharing with all of us at the same time to evolve? Probably not.

 There might be some incredibly insightful ones for whom a half-baked idea is a gold mine for everyone else, but I suspect that many of those often spent time alone with their thoughts beforehand (eg. Look how long Nassim Nicholas taleb procrastinated before publishing).

Interestingly enough, the reality of the human brain aligns much better with elder-led learning of many indigenous groups. Too bad we worked so systematically at destroying many of those societies. Gladly, all is not lost and they are resilient......

Those are my half-baked ideas at least.


> *[2020-04-18 04:00:54]* **Kartik Agaram**:

The way I see it, serendipity = finding someone new to import into one's 150. The large ocean of writings we call the internet provides the fodder for such promotions, freeing us from the tyranny of geography. Strong net positive, IMO. I just wish we hadn't invented web apps to mess with the writing and throw up pop-ups and whatnot.


> *[2020-04-18 04:18:00]* **Chris Rabl**:

i normally take solace in the fact that nobody reads my blog so i can post whatever i want there :slightly_smiling_face: but in all seriousness, maybe don't treat it like a blog then? i think there's value in writing about your experiences + synthesizing information, and there are ways to do that without keeping a "journal". some good examples in this twitter thread that's been making the rounds lately: <https://twitter.com/Mappletons/status/1250532315459194880>


> *[2020-04-18 05:23:56]* **Ivan Reese**:

A variation on what **Chris Rabl** suggests, which works well for me and a few other folks I follow:

Write blog posts, publish them to your site, but don't make any inbound links to them. They're secret.

Continue working on them as your thinking evolves. Never stop.

Occasionally, you'll find yourself in a conversation where one of these posts would make a relevant contribution. Share the link with just those people. They'll only see that one post.

You get all the benefits of clarifying your thinking through writing, and contributing to conversations, without creating noise pollution.


> *[2020-04-18 05:41:38]* **Kartik Agaram**:

My website at <http://akkartik.name> is the tip of the iceberg for my notes. Anytime I tag a new note with 'publish' it gets a URL on my site without putting it on the frontpage. Most of these notes are poorly formatted, but I often react to conversations by using my site search for things I've written in the past. Every once in a while I'll clean one up to share it more deliberately. (Though that hasn't happened very often. Mostly I just rephrase for the new context, because what I had before is never _quite_ right for this new conversation.) Still good as an exo-brain, though.

Bumping back to the original topic, 99% of the time the goal is just to write more, because it clarifies one's thinking. If a blog helps you do that, do a blog. Otherwise try something else. Thinking about 'information overload' and 'polluting the commons' is counter-productive in that situation. Focus first on being the best 'you' you can be. The world has recovered from meteor impacts, and the universe has regular supernovas. They can deal with a few blog posts.


> *[2020-04-18 06:05:16]* **Nick Smith**:

I'll respond to everyone at once:
• We definitely *can* overshare without causing complaint. There are a lot of blog posts out there, and I'm sure most readers will just close the page if they find a post uninsightful or misinformed; they won't send an email to the author. I strongly disagree with the proposal to do whatever I feel is best for myself without concern for others. That's a very egocentric worldview. Wasting people's time is a real and pervasive problem.
• I agree it is sensible to share more with those you are closest to. That's a good replacement for social media posts. I already excel at this because I don't post any social media content whatsoever :stuck_out_tongue:! Unfortunately it doesn't work well for niche technical topics, since your family and housemates probably aren't interested in the future of programming, and even software engineering colleagues may not be. Unfortunately, I don't have many people to talk to IRL about my research interests.
• Yes, maybe what I really want is not a blog, but an externalisation of my beliefs and ideas that I can share with people when appropriate. I've been liking the way Andy Matuschak does this. Roam Research seems to be the new hotness for linked notes, though I'd rather not build my knowledge base on a proprietary platform.


> *[2020-04-18 09:51:28]* **S.M Mukarram Nainar**:

I think gwern's philosophy is quite applicable here: <https://www.gwern.net/About|https://www.gwern.net/About>
Unfortunately as far as I can tell, there aren't software packages that enable this workflow or similar ootb, though I suppose a wiki more or less does it.

---

*[2020-04-18 18:40:13]* **Ivan Reese**:

:postal_horn: <!channel> :postal_horn:

We have a new channel — **`#two-minute-week`**

In this new channel, you can post a two minute video recapping your progress on your FoC project once each week. This will be a fun way for us to keep up on everyone's projects, get inspired, and distill our thinking into a concentrated form.

There's a writeup with more info and recording tips on the website: <https://futureofcoding.org/two-minute-week>

This is a brand new channel and a new mode of interaction for us, so if you have ideas or suggestions for neat things we can do now that this channel exists, drop them in **`#meta`**.

I'm excited to see all the neat and varied projects we're all building, and follow their progress from week to week. :beers:


> *[2020-04-18 18:43:28]* **Corey Montella**:

Is there a day we should coordinate our posting? Like, every sunday? Or do we post throughout the week?


> *[2020-04-18 18:44:42]* **Corey Montella**:

Oh wait, I see you said any day just once a week.

---

*[2020-02-12 10:23:58]* **Unknown User**:

MSG NOT FOUND


> *[2020-04-18 21:13:23]* **Ben Wheeler**:

I do agree with the author that programmers are too enamored of the “right” way of modularizing code.

Like all of use I have run into problems where code was so cleverly written that it felt impossible to change anything and understand its full implications (e.g., in large Rails apps). And I have run into problems where a change was made in one place but similar changes should have been in related places, because there was code duplication (which might have been refactored, but wasn’t.)

In my experience the first kind of problem is much, much more often disruptive than the second kind of problem, in practice.

This is one of my great reservations about FoC’s consensus about the direction languages should go. I’m an apologist for procedural programming!

---

*[2020-04-19 06:04:11]* **U012FRV0EV7**:

has anyone seen this?

<http://www.try-alf.org/blog/2013-10-21-relations-as-first-class-citizen>

I think it's an interesting idea... I think almost all high-level programming can be done with only types, relations, and pattern-matching/destructuring. (of course, we will always need people or Machine Learning to find how to execute the high level code in efficient ways)


> *[2020-04-19 17:14:47]* **Tom Lieber**:

I haven't, but thanks, I love it! I'm curious to hear other opinions, though, because I hashed out a related API in here a while back without being able to explain my motivation nearly as well, and seemed to get mostly confused looks.

---

*[2020-04-19 13:15:27]* **Ian Rumac**:

Yes - there is only 1 and 0, everything else is a relation built upon some rules in different viewpoints.

---

*[2020-04-19 14:01:51]* **Stefan Lesser**:

This post by Dorian Taylor <<https://doriantaylor.com/agile-as-trauma|https://doriantaylor.com/agile-as-trauma>> makes a few connections I found interesting: 

1. Framing the agile movement as a response to trauma — I suspect many other things in our industry could be framed that way?
2. Composition naturally leads to iterative process — not sure if that “naturally” there is justified, but certainly an observation to ponder.
3. How collaboration is such an important part of the agile approach although “programming itself is a quasi-solipsistic activity. A programmer requires, strictly speaking, no more collaboration than does a novelist or painter.”
4. “[T]he presence of a feature can only indicate to a user if a goal is possible, behaviour will determine how painful it will be to achieve it.” and “[Behavior] blurs the line between “fixing bugs” and “building features”, and coalesces the two into a unitary process of “sculpting behaviour”.
1. “Even in a world after programmers, there will still be the work of figuring out—albeit no longer in code—just what you want to tell the computer to do for you—how you want it to behave. There are still a lot of decisions to make aside from what framework you write it in, or whether you use NoSQL, or how you lay out the source tree. If you eliminate the decisions that involve getting the artifact to work at all, the remaining decisions are going to involve whether it works better one way than another. Most of these decisions are going to be the result of trial and error, and a sizable chunk of those are going to involve feedback from users.”
And he touched a few other things we talked about here before.