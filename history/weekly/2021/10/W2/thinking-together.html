
<!doctype html>
<html>
  <head>
    <meta charset=utf-8>
    <title>Future of Coding History</title>
    <link rel="stylesheet" href="https://marianoguerra.github.io/future-of-coding-weekly/history/style.css">
  </head>
  <body>
    <div id="ui">
      <a id="logo" href="https://futureofcoding.org">
        <img src="https://marianoguerra.github.io/future-of-coding-weekly/history/logo.svg" alt="Future of Coding History">
      </a>
      <div id="small-logo">
        <a href="https://futureofcoding.org">Future of Coding</a> History
      </div>
      <div id="center">
        <h4>
          You are viewing archived messages.<br>
          Go <a href="https://marianoguerra.github.io/future-of-coding-weekly/history">here</a> to search the history.
        </h4>
      </div>
      <div id="actions"></div>
    </div>
    <div id="msgs-output">
<div id="2021-10-04T17:55:15.276Z" class="post"><span class="user">Diego Moya</span> <a href="#2021-10-04T17:55:15.276Z" class="date">2021-10-04 17:55:15</a> <div class="message"><p>Artificial Intelligence is known to be a generic umbrella term for a wide variety of techniques. The current AI renaissance based on Machine Learning is all about advanced statistical techniques, and they're getting awesome never-seen-before results in all kinds of artistic media or tasks requiring observation and adequate reactions. Yet it often feels like these techniques don't really understand the problem they're solving, they merely act by imitation of what they were trained on.</p>
<p>Classic AI, the one based on logic inferences, is strong in that task of understanding the situation and giving precise answers. Yet it lacks intuition, often resorts to brute force, and has not been seen to be able to generate anything resembling creativity (or not on the levels of the Deep Learning). I have often wondered if there would be a way to combine the strengths of both, but I know of no research that has attempted to do that.</p>
<p>Do you know of any techniques that combines ML with deductive reasoning, using the first to "learn" about a problem domain and the second to "clean up" inconsistencies and errors in the solutions created "by gut feel" with the former?</p>
</div> <div class="attachments"></div> <div class="files"></div> <div class="replies"><div id="2021-10-04T18:12:16.277Z" class="reply"><span class="user">Denny Vrandeƒçiƒá</span> <a href="#2021-10-04T18:12:16.277Z" class="date">2021-10-04 18:12:16</a> <div class="message"><p>Some terms I have seen for that is "neuro-symbolic integration" or "hybrid AI", eg. <a href="https://arxiv.org/abs/2012.05876"></a><a href="https://arxiv.org/abs/2012.05876">https://arxiv.org/abs/2012.05876</a></p>
</div> <div class="attachments"><blockquote><p>üîó <a href="https://arxiv.org/abs/2012.05876">Neurosymbolic AI: The 3rd Wave</a></p>
</blockquote>
</div> <div class="files"></div></div><div id="2021-10-05T00:27:46.278Z" class="reply"><span class="user">Nick Smith</span> <a href="#2021-10-05T00:27:46.278Z" class="date">2021-10-05 00:27:46</a> <div class="message"><p><a href="https://www.relational.ai/">RelationalAI</a> seems to be exploring this intersection. Perhaps <strong>@Molham Aref</strong> has something to say üòá.</p>
</div> <div class="attachments"></div> <div class="files"></div></div><div id="2021-10-05T03:05:35.278Z" class="reply"><span class="user">Molham Aref</span> <a href="#2021-10-05T03:05:35.278Z" class="date">2021-10-05 03:05:35</a> <div class="message"><p>indeed <a href="https://twitter.com/NickSmit_">Nick Smith</a>, the work we are doing at RelationalAI is at the intersection of statistical and logical/relational modeling.  There are so many ways to combine these approaches.  Check out this overview talk by <a href="https://www.youtube.com/watch?v=_cQITY0SPiw">Henry Kautz</a> at AAAI 2020 which influenced a talk by <a href="https://ibm.ent.box.com/s/3kgxhuy8h9x98nnck26a0498q9rjkwhp">Alex Gray</a> at IBM‚Äôs Advances in Neuro-Symbolic AI <a href="https://researcher.watson.ibm.com/researcher/view_group.php?id=10510">Seminar Series</a>.  I hope that helps.</p>
</div> <div class="attachments"><blockquote><p>üé• <a href="https://www.youtube.com/watch?v=_cQITY0SPiw">The Third AI Summer,  Henry Kautz, AAAI 2020 Robert S. Engelmore Memorial Award Lecture</a></p>
<p>üîó <a href="https://researcher.watson.ibm.com/researcher/view_group.php?id=10510">Advances in Neuro-Symbolic AI ‚Äî IBM Seminar Series - IBM</a></p>
</blockquote>
</div> <div class="files"></div></div><div id="2021-10-06T11:47:31.281Z" class="reply"><span class="user">Alexander Chichigin</span> <a href="#2021-10-06T11:47:31.281Z" class="date">2021-10-06 11:47:31</a> <div class="message"><p>If you're interested in modern AI research (and not only merging ML and logic) you should look at "Artificial General Intelligence" -- this is contemporary term for "actual AI", they have an annual conference, journals and many other things. As well as several research avenues and approaches, some of them combining others (presumably) subsuming both ML and logical reasoning.</p>
</div> <div class="attachments"></div> <div class="files"></div></div><div id="2021-10-06T21:05:44.282Z" class="reply"><span class="user">dnmfarrell</span> <a href="#2021-10-06T21:05:44.282Z" class="date">2021-10-06 21:05:44</a> <div class="message"><p>If you're interested in understanding the limitations of mainstream AI approaches you might like these books: The Myth of Artificial Intelligence by Larson and Rebooting AI by Marcus and Davis. And this recent article: <a href="https://spectrum.ieee.org/deep-learning-computational-cost"></a><a href="https://spectrum.ieee.org/deep-learning-computational-cost">https://spectrum.ieee.org/deep-learning-computational-cost</a></p>
</div> <div class="attachments"><blockquote><p>üîó <a href="https://spectrum.ieee.org/deep-learning-computational-cost">Deep Learning‚Äôs Diminishing Returns</a></p>
</blockquote>
</div> <div class="files"></div></div><div id="2021-10-06T21:09:06.282Z" class="reply"><span class="user">dnmfarrell</span> <a href="#2021-10-06T21:09:06.282Z" class="date">2021-10-06 21:09:06</a> <div class="message"><p>It sounds like you're talking about logical abduction (instead of deduction/induction) which Larson discusses. Forming hypotheses based on experience that may or not be true but are better than random guesses and cheaper to calculate. Inference</p>
</div> <div class="attachments"></div> <div class="files"></div></div><div id="2021-10-07T03:32:36.283Z" class="reply"><span class="user">William Taysom</span> <a href="#2021-10-07T03:32:36.283Z" class="date">2021-10-07 03:32:36</a> <div class="message"><p>It does seem that these statistical techniques somehow end up modeling what people would call gut reactions: the first thing you think of when you haven't yet thought things through.</p>
</div> <div class="attachments"></div> <div class="files"></div></div><div id="2021-10-08T06:28:26.286Z" class="reply"><span class="user">Alexander Chichigin</span> <a href="#2021-10-08T06:28:26.286Z" class="date">2021-10-08 06:28:26</a> <div class="message"><p><strong>@William Taysom</strong> I'm pretty sure that's exactly because both "gut feeling" and ML are based on pattern recognition and matching. üôÇ Patterns are the first thing brain attains to. Only when it fails we reach for models.</p>
</div> <div class="attachments"></div> <div class="files"></div></div><div id="2021-10-08T11:18:43.287Z" class="reply"><span class="user">dnmfarrell</span> <a href="#2021-10-08T11:18:43.287Z" class="date">2021-10-08 11:18:43</a> <div class="message"><p>Larson claims the limitation with AI is it can only recognize patterns it has seen. Take self driving cars for example. If you're driving behind a pickup truck on the highway and a birthday balloon falls off the back of it, you probably realize it is safe to drive over it. You've never seen this happen before but you know that balloons are filled with air, and its movement suggests it too. What about an AI? Well if it hasn't been trained on this scenario, perhaps it slams on the brakes and causes a collision.</p>
</div> <div class="attachments"></div> <div class="files"></div></div><div id="2021-10-08T11:47:43.287Z" class="reply"><span class="user">William Taysom</span> <a href="#2021-10-08T11:47:43.287Z" class="date">2021-10-08 11:47:43</a> <div class="message"><p>I can tell you that Teslas freak out over a lot less than a balloon.  It's a lot less of an "autopilot" than mixed initiative automatically adjusting autonomous system.  I haven't used those words in a long time.  <a href="https://www.semanticscholar.org/paper/Dimensions-of-Adjustable-Autonomy-and-Interaction-Bradshaw-Feltovich/e4bfe3b40d36f0b8c79c4c98319d4bf51569d080"></a><a href="https://www.semanticscholar.org/paper/Dimensions-of-Adjustable-Autonomy-and-Interaction-Bradshaw-Feltovich/e4bfe3b40d36f0b8c79c4c98319d4bf51569d080">https://www.semanticscholar.org/paper/Dimensions-of-Adjustable-Autonomy-and-Interaction-Bradshaw-Feltovich/e4bfe3b40d36f0b8c79c4c98319d4bf51569d080</a></p>
</div> <div class="attachments"><blockquote><p>üîó <a href="https://www.semanticscholar.org/paper/Dimensions-of-Adjustable-Autonomy-and-Interaction-Bradshaw-Feltovich/e4bfe3b40d36f0b8c79c4c98319d4bf51569d080">[PDF] Dimensions of Adjustable Autonomy and Mixed-Initiative Interaction | Semantic Scholar</a></p>
</blockquote>
</div> <div class="files"></div></div></div></div><div id="2021-10-07T22:48:40.286Z" class="post"><span class="user">Ildar</span> <a href="#2021-10-07T22:48:40.286Z" class="date">2021-10-07 22:48:40</a> <div class="message"><p>Hey haven't been here in years</p>
</div> <div class="attachments"></div> <div class="files"></div> <div class="replies"></div></div><div id="2021-10-07T22:48:43.286Z" class="post"><span class="user">Ildar</span> <a href="#2021-10-07T22:48:43.286Z" class="date">2021-10-07 22:48:43</a> <div class="message"><p>How is everyone</p>
</div> <div class="attachments"></div> <div class="files"></div> <div class="replies"><div id="2021-10-07T23:51:21.286Z" class="reply"><span class="user">Ivan Reese</span> <a href="#2021-10-07T23:51:21.286Z" class="date">2021-10-07 23:51:21</a> <div class="message"><p>Hi! Welcome back. A lot has changed in the past year. I recommend taking a moment to read through our new <a href="https://futureofcoding.org/member-handbook">Member Handbook</a>, where we've captured a lot of the norms and patterns around how we structure our discussions nowadays.</p>
</div> <div class="attachments"></div> <div class="files"></div></div><div id="2021-10-08T11:34:50.287Z" class="reply"><span class="user">William Taysom</span> <a href="#2021-10-08T11:34:50.287Z" class="date">2021-10-08 11:34:50</a> <div class="message"><p>The Random Encounters channel has lead to some pretty interesting conversations for me at least <a href="https://futureofcoding.org/member-handbook#random-encounters"></a><a href="https://futureofcoding.org/member-handbook#random-encounters">https://futureofcoding.org/member-handbook#random-encounters</a>.</p>
</div> <div class="attachments"></div> <div class="files"></div></div><div id="2021-10-10T03:08:08.292Z" class="reply"><span class="user">Cole Lawrence</span> <a href="#2021-10-10T03:08:08.292Z" class="date">2021-10-10 03:08:08</a> <div class="message"><p>Hi <strong>@Ildar</strong>. I think we met up in NYC once through this community a long time ago, no?</p>
</div> <div class="attachments"></div> <div class="files"></div></div></div></div>
    </div>
  </body>
</html>
