[
    {
        "client_msg_id": "b9156d50-7ee3-4ba1-8529-ef4d07fab615",
        "type": "message",
        "text": "A few shower thoughts on AI and end user programming.\n\u2022 I imagine this group is more averse to AI research compared to baseline in tech/CS. The following comes to mind:\n    \u25e6 Most algorithms today tend to be pretty opaque, whereas we value understandable systems.\n    \u25e6 Current end user systems (e.g. Alexa) are super frustrating when they don\u2019t give you what you want, since their behavior is hard to manipulate.\n    \u25e6 There\u2019s an uneasiness about AI systems replacing the things we DO want to control; we value systems that put people in control.\n    \u25e6 There\u2019s little value for human intuition in most current AI research, with some notable exceptions below.\n\u2022 The deep learning gold rush has created a situation with interesting analogies to the \u201cprogrammer/end user\u201d dichotomy. Researchers who develop the expertise to *design* deep learning systems tend to \u201cthink in deep learning\u201d to the exclusion of better suited approaches in some contexts, while those without a deep understanding have little ability to modify their systems.\n\u2022 Going further with this, two of the most interesting researchers right now IMO are <https://fchollet.com/|Fran\u00e7ois Chollet> and <https://web.mit.edu/cocosci/josh.html|Josh Tenenbaum>, both of whom see _program synthesis_ as the key to advancing AI in a more interesting and useful direction. There\u2019s a parallel with the popular \u201cType I/Type II\u201d thinking analogy: deep learning is great for Type I thinking (pattern matching, interpolation, \u201cgeometry\u201d), while there hasn\u2019t been much progress yet with Type II thinking (generalization, planning, \u201ctopology\u201d). The idea is that you need both: a perception layer that goes from continuous to discrete, and a \u201cprogramming\u201d layer to work with the results. A recent example of program synthesis is <https://arxiv.org/abs/2006.08381|DreamCoder>. \n\u2022 IMO we\u2019re about to see all the wrong assumptions that are encoded in current software systems recapitulated in this new trend in AI research, since these efforts will use existing programming languages for the program synthesis component (DreamCoder uses a lisp). I think there\u2019s an opportunity for our group\u2019s way of thinking to improve on the \u201cprogram synthesis\u201d part of the pipeline.\n\u2022 Chollet\u2019s \u201c<https://arxiv.org/abs/1911.01547|Abstraction and Reasoning (ARC)>\u201d paper and challenge is to me a very clever and appealing illustration of the limitations of deep learning and the potential of program synthesis.\n    \u25e6 One \u201cbig idea\u201d is to optimize for generalization by limiting the number of training examples available to an algorithm.\n\u2022 \u201cBuilding Machines that Learn and Think Like People\u201d is another nice intro to this direction in AI research, linked in this rather <https://gradadmissions.mit.edu/blog/carving-nature-its-joints|delightful essay>.\n\u2022 Lick\u2019s <http://worrydream.com/refs/Licklider%20-%20Man-Computer%20Symbiosis.pdf|Man-Computer Symbiosis> paper from 1960 is as fresh as ever (not to mention <http://worrydream.com/refs/Licklider%20-%20The%20Computer%20as%20Communication%20Device.pdf|The Computer as Communication Device>).\n\u2022 If this is all too nebulous, Chollet\u2019s <https://slideslive.com/38935790/abstraction-reasoning-in-ai-systems-modern-perspectives|NeuroIPS talk> (the first 40 min) is a nice crisp intro.\nInterested if anyone else is thinking about these topics.",
        "user": "U9C92716C",
        "ts": "1642520639.090700",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "U9C92716C",
            "ts": "1642520788.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "0J58",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "A few shower thoughts on AI and end user programming.\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "I imagine this group is more averse to AI research compared to baseline in tech/CS. The following comes to mind:"
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Most algorithms today tend to be pretty opaque, whereas we value understandable systems."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Current end user systems (e.g. Alexa) are super frustrating when they don\u2019t give you what you want, since their behavior is hard to manipulate."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "There\u2019s an uneasiness about AI systems replacing the things we DO want to control; we value systems that put people in control."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "There\u2019s little value for human intuition in most current AI research, with some notable exceptions below."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 1,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "The deep learning gold rush has created a situation with interesting analogies to the \u201cprogrammer/end user\u201d dichotomy. Researchers who develop the expertise to "
                                    },
                                    {
                                        "type": "text",
                                        "text": "design",
                                        "style": {
                                            "bold": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " deep learning systems tend to \u201cthink in deep learning\u201d to the exclusion of better suited approaches in some contexts, while those without a deep understanding have little ability to modify their systems."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Going further with this, two of the most interesting researchers right now IMO are "
                                    },
                                    {
                                        "type": "link",
                                        "url": "https://fchollet.com/",
                                        "text": "Fran\u00e7ois Chollet"
                                    },
                                    {
                                        "type": "text",
                                        "text": " and "
                                    },
                                    {
                                        "type": "link",
                                        "url": "https://web.mit.edu/cocosci/josh.html",
                                        "text": "Josh Tenenbaum"
                                    },
                                    {
                                        "type": "text",
                                        "text": ", both of whom see "
                                    },
                                    {
                                        "type": "text",
                                        "text": "program synthesis ",
                                        "style": {
                                            "italic": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": "as the key to advancing AI in a more interesting and useful direction. There\u2019s a parallel with the popular \u201cType I/Type II\u201d thinking analogy: deep learning is great for Type I thinking (pattern matching, interpolation, \u201cgeometry\u201d), while there hasn\u2019t been much progress yet with Type II thinking (generalization, planning, \u201ctopology\u201d). The idea is that you need both: a perception layer that goes from continuous to discrete, and a \u201cprogramming\u201d layer to work with the results. A recent example of program synthesis is "
                                    },
                                    {
                                        "type": "link",
                                        "url": "https://arxiv.org/abs/2006.08381",
                                        "text": "DreamCoder"
                                    },
                                    {
                                        "type": "text",
                                        "text": ". "
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "IMO we\u2019re about to see all the wrong assumptions that are encoded in current software systems recapitulated in this new trend in AI research, since these efforts will use existing programming languages for the program synthesis component (DreamCoder uses a lisp). I think there\u2019s an opportunity for our group\u2019s way of thinking to improve on the \u201cprogram synthesis\u201d part of the pipeline."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Chollet\u2019s \u201c"
                                    },
                                    {
                                        "type": "link",
                                        "url": "https://arxiv.org/abs/1911.01547",
                                        "text": "Abstraction and Reasoning (ARC)"
                                    },
                                    {
                                        "type": "text",
                                        "text": "\u201d paper and challenge is to me a very clever and appealing illustration of the limitations of deep learning and the potential of program synthesis."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "One \u201cbig idea\u201d is to optimize for generalization by limiting the number of training examples available to an algorithm."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 1,
                        "border": 0
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "\u201cBuilding Machines that Learn and Think Like People\u201d is another nice intro to this direction in AI research, linked in this rather "
                                    },
                                    {
                                        "type": "link",
                                        "url": "https://gradadmissions.mit.edu/blog/carving-nature-its-joints",
                                        "text": "delightful essay"
                                    },
                                    {
                                        "type": "text",
                                        "text": "."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Lick\u2019s "
                                    },
                                    {
                                        "type": "link",
                                        "url": "http://worrydream.com/refs/Licklider%20-%20Man-Computer%20Symbiosis.pdf",
                                        "text": "Man-Computer Symbiosis"
                                    },
                                    {
                                        "type": "text",
                                        "text": " paper from 1960 is as fresh as ever (not to mention "
                                    },
                                    {
                                        "type": "link",
                                        "url": "http://worrydream.com/refs/Licklider%20-%20The%20Computer%20as%20Communication%20Device.pdf",
                                        "text": "The Computer as Communication Device"
                                    },
                                    {
                                        "type": "text",
                                        "text": ")."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "If this is all too nebulous, Chollet\u2019s "
                                    },
                                    {
                                        "type": "link",
                                        "url": "https://slideslive.com/38935790/abstraction-reasoning-in-ai-systems-modern-perspectives",
                                        "text": "NeuroIPS talk"
                                    },
                                    {
                                        "type": "text",
                                        "text": " (the first 40 min) is a nice crisp intro."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Interested if anyone else is thinking about these topics."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1642520639.090700",
        "reply_count": 15,
        "reply_users_count": 5,
        "latest_reply": "1642668188.101000",
        "reply_users": [
            "U8A5MS6R1",
            "U9C92716C",
            "UA14TGLTC",
            "UJBAJNFLK",
            "UKFNXF0F9"
        ],
        "is_locked": false,
        "subscribed": false,
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U013HU44GLS",
                    "U02E4DAQGSZ",
                    "U014WA16VNJ",
                    "UA14TGLTC",
                    "UJBAJNFLK"
                ],
                "count": 5
            }
        ]
    },
    {
        "client_msg_id": "b52ac473-0bf3-4528-a2aa-a698b98c836b",
        "type": "message",
        "text": "&gt;  I imagine this group is more averse to AI research compared to baseline in tech/CS.\nHa - I certainly am more averse to AI, specifically the trend of slapping ML on anything and everything. Consider copilot, which autocompletes textual code, without modeling any semantics. It kinda seems backwards.. first we make something hard to do, then try to work around it by heavy ML / statistical models. No wonder when its wrong it is totally wrong: secret keys, joke code etc.\n\nHaving said that, I got a few very good responses to a tweet once <https://twitter.com/chatur_shalabh/status/1312073013194493952>\n\nI'll summarize:\n1. instead of putting ML into production directly, use it to find a function that does what you want, then render it out as human-readable code for deployment\n2. exploratory programs - write a program to generate some shapes, then use a DNN to generate shapes you did not think of\n3. given some requirements in a constraints language, do a ML driven search in a very broad solution space\n",
        "user": "U8A5MS6R1",
        "ts": "1642536268.091300",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "from_url": "https://twitter.com/chatur_shalabh/status/1312073013194493952",
                "ts": 1601657558,
                "id": 1,
                "original_url": "https://twitter.com/chatur_shalabh/status/1312073013194493952",
                "fallback": "<https://twitter.com/chatur_shalabh|@chatur_shalabh>: Using ML to read, generate or otherwise manipulate code has always seemed absurd *to me*.\n\nWe don't teach the machine to compute mean() or sin() using ML. We just 'implement the algorithm'. Ok, these algos are easy but we also implement more complicated logic.\n\nWhat am I missing?",
                "text": "Using ML to read, generate or otherwise manipulate code has always seemed absurd *to me*.\n\nWe don't teach the machine to compute mean() or sin() using ML. We just 'implement the algorithm'. Ok, these algos are easy but we also implement more complicated logic.\n\nWhat am I missing?",
                "author_name": "Shalabh",
                "author_link": "https://twitter.com/chatur_shalabh/status/1312073013194493952",
                "author_icon": "https://pbs.twimg.com/profile_images/1168926214343536641/wNcbqYu0_normal.jpg",
                "author_subname": "@chatur_shalabh",
                "service_name": "twitter",
                "service_url": "https://twitter.com/",
                "footer": "Twitter",
                "footer_icon": "https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "dgGb",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": " I imagine this group is more averse to AI research compared to baseline in tech/CS."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Ha - I certainly am more averse to AI, specifically the trend of slapping ML on anything and everything. Consider copilot, which autocompletes textual code, without modeling any semantics. It kinda seems backwards.. first we make something hard to do, then try to work around it by heavy ML / statistical models. No wonder when its wrong it is totally wrong: secret keys, joke code etc.\n\nHaving said that, I got a few very good responses to a tweet once "
                            },
                            {
                                "type": "link",
                                "url": "https://twitter.com/chatur_shalabh/status/1312073013194493952"
                            },
                            {
                                "type": "text",
                                "text": "\n\nI'll summarize:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "instead of putting ML into production directly, use it to find a function that does what you want, then render it out as human-readable code for deployment"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "exploratory programs - write a program to generate some shapes, then use a DNN to generate shapes you did not think of"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "given some requirements in a constraints language, do a ML driven search in a very broad solution space"
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": []
                    }
                ]
            }
        ],
        "thread_ts": "1642520639.090700",
        "parent_user_id": "U9C92716C"
    },
    {
        "client_msg_id": "3c00ff6f-fcd9-4084-b342-137397ac8a89",
        "type": "message",
        "text": "Thanks Shalabh. I hope you\u2019ll give the papers above a skim (<https://arxiv.org/abs/1911.01547|On the Measure of Intelligence>, <https://arxiv.org/abs/1604.00289|Building Machines That Learn and Think Like People>), as I think you\u2019ll find some good responses to the question you posed. To me the responses you got are nice but just scratch the surface. For instance, <https://fluxml.ai/blog/2019/03/05/dp-vs-rl.html|differentiable programming> is a very rich area to explore, even without introducing \u201cheavy ML\u201d, and can mesh very well with existing domain knowledge. I agree with your criticism of Copilot (and GPT-3 in general), and I think _causal models_ have to be at the core of any collaborative human-computer system.",
        "user": "U9C92716C",
        "ts": "1642542234.091700",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "K1e",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thanks Shalabh. I hope you\u2019ll give the papers above a skim ("
                            },
                            {
                                "type": "link",
                                "url": "https://arxiv.org/abs/1911.01547",
                                "text": "On the Measure of Intelligence"
                            },
                            {
                                "type": "text",
                                "text": ", "
                            },
                            {
                                "type": "link",
                                "url": "https://arxiv.org/abs/1604.00289",
                                "text": "Building Machines That Learn and Think Like People"
                            },
                            {
                                "type": "text",
                                "text": "), as I think you\u2019ll find some good responses to the question you posed. To me the responses you got are nice but just scratch the surface. For instance, "
                            },
                            {
                                "type": "link",
                                "url": "https://fluxml.ai/blog/2019/03/05/dp-vs-rl.html",
                                "text": "differentiable programming"
                            },
                            {
                                "type": "text",
                                "text": " is a very rich area to explore, even without introducing \u201cheavy ML\u201d, and can mesh very well with existing domain knowledge. I agree with your criticism of Copilot (and GPT-3 in general), and I think "
                            },
                            {
                                "type": "text",
                                "text": "causal models",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " have to be at the core of any collaborative human-computer system."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1642520639.090700",
        "parent_user_id": "U9C92716C",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UJBAJNFLK"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "519eb2af-05d7-43ab-b102-f0be833a833c",
        "type": "message",
        "text": "\"Anyone else is thinking about these topics?\"  In a word, yes.",
        "user": "UA14TGLTC",
        "ts": "1642562825.092800",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "a=3",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\"Anyone else is thinking about these topics?\"  In a word, yes."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1642520639.090700",
        "parent_user_id": "U9C92716C",
        "reactions": [
            {
                "name": "drum_with_drumsticks",
                "users": [
                    "U9C92716C"
                ],
                "count": 1
            },
            {
                "name": "boom",
                "users": [
                    "U9C92716C"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "752f8508-9d1b-4537-8551-2ce4a20b8b18",
        "type": "message",
        "text": "Thanks <@U9C92716C> for all the references you provided! Just what I have been looking for for a while: a high-level overview of the non-boring activities around AI.\nMy own current view of AI: its role is in discovery, not decision making. I want AI tools to suggest things to me, much like code completion in an editor, but let me decide what to do with them.",
        "user": "UJBAJNFLK",
        "ts": "1642585345.093800",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "MKta",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thanks "
                            },
                            {
                                "type": "user",
                                "user_id": "U9C92716C"
                            },
                            {
                                "type": "text",
                                "text": " for all the references you provided! Just what I have been looking for for a while: a high-level overview of the non-boring activities around AI.\nMy own current view of AI: its role is in discovery, not decision making. I want AI tools to suggest things to me, much like code completion in an editor, but let me decide what to do with them."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1642520639.090700",
        "parent_user_id": "U9C92716C",
        "reactions": [
            {
                "name": "point_up",
                "users": [
                    "U9C92716C",
                    "UA14TGLTC"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "3cc20f15-eb4b-4a06-ba02-543819fc7a5d",
        "type": "message",
        "text": "<@UJBAJNFLK> Thanks for the feedback! I only came across Tenenbaum\u2019s and Chollet\u2019s work recently, and was very pleasantly surprised since I haven\u2019t historically found much to be excited about there. I definitely resonate with your view. If you end up experimenting in that direction, I\u2019d love to hear more.",
        "user": "U9C92716C",
        "ts": "1642595068.094100",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "g33M",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UJBAJNFLK"
                            },
                            {
                                "type": "text",
                                "text": " Thanks for the feedback! I only came across Tenenbaum\u2019s and Chollet\u2019s work recently, and was very pleasantly surprised since I haven\u2019t historically found much to be excited about there. I definitely resonate with your view. If you end up experimenting in that direction, I\u2019d love to hear more."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1642520639.090700",
        "parent_user_id": "U9C92716C"
    },
    {
        "client_msg_id": "babb4fa0-1d2f-483b-8957-d8b0c9d9b677",
        "type": "message",
        "text": "\u2022 AI community is SOTA oriented, if a method leads to good metrics, it will be adopted despite we do not know how it is working. Program synthesis generated human readable program can not outperform unreadable blackbox neural networks, so the interest of it will be limited. It might be useful to distill pattern to detect anomaly, such as seasoning effect of time series. Still, do not know if any program sythesis approach can achive SOTA in anomaly detection tasks.\n\u2022 Program synthesis might be viewed as a form of unsupervised learning. It can help human to interpret the data, finding deep statistics about the pattern. But synthesis program might not be a good representation of knowledge learned from vast amount of data.\n\u2022 \u201cprogrammer/end user\u201d dichotomy to me is about the producer of big language model (such as GPT-3) and users fine-tune them for downstream tasks. Most \"end user\" will not have access to the software/hardware to produce another GPT-3, they will be forced to reuse whatever was given due to cost. Just like we reuse excel for everything.",
        "user": "UKFNXF0F9",
        "ts": "1642595458.094300",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UKFNXF0F9",
            "ts": "1642595845.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "z5IG",
                "elements": [
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "AI community is SOTA oriented, if a method leads to good metrics, it will be adopted despite we do not know how it is working. Program synthesis generated human readable program can not outperform unreadable blackbox neural networks, so the interest of it will be limited. It might be useful to distill pattern to detect anomaly, such as seasoning effect of time series. Still, do not know if any program sythesis approach can achive SOTA in anomaly detection tasks."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "Program synthesis might be viewed as a form of unsupervised learning. It can help human to interpret the data, finding deep statistics about the pattern. But synthesis program might not be a good representation of knowledge learned from vast amount of data."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "\u201cprogrammer/end user\u201d dichotomy to me is about the producer of big language model (such as GPT-3) and users fine-tune them for downstream tasks. Most \"end user\" will not have access to the software/hardware to produce another GPT-3, they will be forced to reuse whatever was given due to cost. Just like we reuse excel for everything."
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    }
                ]
            }
        ],
        "thread_ts": "1642520639.090700",
        "parent_user_id": "U9C92716C",
        "reactions": [
            {
                "name": "thinking_face",
                "users": [
                    "UA14TGLTC"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "b053c3ae-ef5a-49e1-b8a5-e1e18196d355",
        "type": "message",
        "text": "Hi <@UKFNXF0F9>, have you looked at the ARC Challenge paper above? So far, program synthesis is the only competitive approach for that benchmark, which is part of the charm of how it was constructed. To me it\u2019s a good illustration of the limits of today\u2019s SOTA methods.\n\nThe way I see it informally, whether you use program synthesis, NNs, or any other approach in designing your system, it needs both \u201clookup table\u201d and \u201cinductive reasoning\u201d modes for robust real-world operation. Type I vs Type II thinking, if you will. Lookup tables are what you get from (nonrecurrent) NNs, and they beat inductive reasoning for performance (and usually accuracy) if things never change and you have enough data to train with. However, results from chaos theory show that lookup tables can\u2019t be a universal approach when navigating real-world dynamical systems. On the other hand, causal chains are very effective tools for generalization under novel (sparsely sampled) conditions. So inductive reasoning beats lookup tables in new or changing environments, but in most current systems this is left to the engineers designing the system or offloaded to end users.\n\nAs a brief counterexample, classical mechanics is a program synthesis approach (as nicely illustrated in <https://groups.csail.mit.edu/mac/users/gjs/6946/sicm-html/book-Z-H-4.html#%_chap_Temp_2|Structure and Interpretation of ><https://groups.csail.mit.edu/mac/users/gjs/6946/sicm-html/book-Z-H-4.html|Mechanics>), and is a preemiment example of knowledge representation learned from vast amount of data.",
        "user": "U9C92716C",
        "ts": "1642600709.095100",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "zLq",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Hi "
                            },
                            {
                                "type": "user",
                                "user_id": "UKFNXF0F9"
                            },
                            {
                                "type": "text",
                                "text": ", have you looked at the ARC Challenge paper above? So far, program synthesis is the only competitive approach for that benchmark, which is part of the charm of how it was constructed. To me it\u2019s a good illustration of the limits of today\u2019s SOTA methods.\n\nThe way I see it informally, whether you use program synthesis, NNs, or any other approach in designing your system, it needs both \u201clookup table\u201d and \u201cinductive reasoning\u201d modes for robust real-world operation. Type I vs Type II thinking, if you will. Lookup tables are what you get from (nonrecurrent) NNs, and they beat inductive reasoning for performance (and usually accuracy) if things never change and you have enough data to train with. However, results from chaos theory show that lookup tables can\u2019t be a universal approach when navigating real-world dynamical systems. On the other hand, causal chains are very effective tools for generalization under novel (sparsely sampled) conditions. So inductive reasoning beats lookup tables in new or changing environments, but in most current systems this is left to the engineers designing the system or offloaded to end users.\n\nAs a brief counterexample, classical mechanics is a program synthesis approach (as nicely illustrated in"
                            },
                            {
                                "type": "text",
                                "text": " ",
                                "style": {
                                    "bold": true,
                                    "italic": true
                                }
                            },
                            {
                                "type": "link",
                                "url": "https://groups.csail.mit.edu/mac/users/gjs/6946/sicm-html/book-Z-H-4.html#%_chap_Temp_2",
                                "text": "Structure and Interpretation of "
                            },
                            {
                                "type": "link",
                                "url": "https://groups.csail.mit.edu/mac/users/gjs/6946/sicm-html/book-Z-H-4.html",
                                "text": "Mechanics"
                            },
                            {
                                "type": "text",
                                "text": "), and is a preemiment example of knowledge representation learned from vast amount of data."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1642520639.090700",
        "parent_user_id": "U9C92716C"
    },
    {
        "client_msg_id": "f768ae12-8295-475b-a497-60f82befeb8e",
        "type": "message",
        "text": "is ARC Challenge listed here <https://paperswithcode.com/sota> ?",
        "user": "UKFNXF0F9",
        "ts": "1642602511.095300",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "from_url": "https://paperswithcode.com/sota",
                "image_url": "https://paperswithcode.com/static/sota.jpeg",
                "image_width": 377,
                "image_height": 250,
                "image_bytes": 263726,
                "service_icon": "https://paperswithcode.com/favicon.ico",
                "id": 1,
                "original_url": "https://paperswithcode.com/sota",
                "fallback": "Papers with Code - Browse the State-of-the-Art in Machine Learning",
                "text": "6054 leaderboards \u2022 2620 tasks \u2022 5411 datasets \u2022 63341 papers with code.",
                "title": "Papers with Code - Browse the State-of-the-Art in Machine Learning",
                "title_link": "https://paperswithcode.com/sota",
                "service_name": "paperswithcode.com"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "x0Y",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "is ARC Challenge listed here "
                            },
                            {
                                "type": "link",
                                "url": "https://paperswithcode.com/sota"
                            },
                            {
                                "type": "text",
                                "text": " ?"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1642520639.090700",
        "parent_user_id": "U9C92716C"
    },
    {
        "client_msg_id": "de51b807-d555-4e3b-9ff1-dbbc531dd022",
        "type": "message",
        "text": "<https://paperswithcode.com/paper/the-measure-of-intelligence>",
        "user": "U9C92716C",
        "ts": "1642602989.095600",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "from_url": "https://paperswithcode.com/paper/the-measure-of-intelligence",
                "image_url": "https://arc-benchmark.s3.amazonaws.com/figs/arc_test_space.png",
                "image_width": 509,
                "image_height": 250,
                "image_bytes": 245003,
                "service_icon": "https://paperswithcode.com/favicon.ico",
                "id": 1,
                "original_url": "https://paperswithcode.com/paper/the-measure-of-intelligence",
                "fallback": "Papers with Code - On the Measure of Intelligence",
                "text": "Implemented in 2 code libraries.",
                "title": "Papers with Code - On the Measure of Intelligence",
                "title_link": "https://paperswithcode.com/paper/the-measure-of-intelligence",
                "service_name": "paperswithcode.com"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "6Zf7",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "link",
                                "url": "https://paperswithcode.com/paper/the-measure-of-intelligence"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1642520639.090700",
        "parent_user_id": "U9C92716C"
    },
    {
        "client_msg_id": "51537c44-c8d7-43cb-aa14-f1026601f79d",
        "type": "message",
        "text": "<@U9C92716C> Seeing your reference to SICM, you might like this article about deriving mathematical models via machine learning (plus human-provided assumptions): <https://arxiv.org/abs/1911.01429>",
        "user": "UJBAJNFLK",
        "ts": "1642607390.095900",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "from_url": "https://arxiv.org/abs/1911.01429",
                "thumb_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png",
                "thumb_width": 1000,
                "thumb_height": 1000,
                "service_icon": "https://static.arxiv.org/static/browse/0.3.2.8/images/icons/favicon.ico",
                "id": 1,
                "original_url": "https://arxiv.org/abs/1911.01429",
                "fallback": "arXiv.org: The frontier of simulation-based inference",
                "text": "Many domains of science have developed complex simulations to describe phenomena of interest. While these simulations provide high-fidelity models, they are poorly suited for inference and lead to...",
                "title": "The frontier of simulation-based inference",
                "title_link": "https://arxiv.org/abs/1911.01429",
                "service_name": "arXiv.org"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "XSQi",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U9C92716C"
                            },
                            {
                                "type": "text",
                                "text": " Seeing your reference to SICM, you might like this article about deriving mathematical models via machine learning (plus human-provided assumptions): "
                            },
                            {
                                "type": "link",
                                "url": "https://arxiv.org/abs/1911.01429"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1642520639.090700",
        "parent_user_id": "U9C92716C"
    },
    {
        "client_msg_id": "1b1067d5-4dcf-44fd-b402-7a275eab1b69",
        "type": "message",
        "text": "Thank you. Very lucid paper\u2014 and still on the edge of my ability to read without spending all day on the math. Any main takeaways for you? Fig 3 will be a reference to hold onto. I\u2019m still kind of hung up on \u201cNone of these diagnostics address the issues encountered if the model is misspecified and the simulator is not an accurate description of the system being studied\u201d; I\u2019m trying to get my head wrapped around the inductive process of developing the model in the first place and then adapting it as the world changes.\n\nOn another math note, you may find <http://proceedings.mlr.press/v80/balestriero18b/balestriero18b.pdf|this analysis> of how NNs really work interesting. Nice 15-20 min <https://youtu.be/86ib0sfdFtw?t=718s|discussion here> starting at minute 12.",
        "user": "U9C92716C",
        "ts": "1642611067.096200",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "from_url": "https://youtu.be/86ib0sfdFtw?t=718s",
                "thumb_url": "https://i.ytimg.com/vi/86ib0sfdFtw/hqdefault.jpg",
                "thumb_width": 480,
                "thumb_height": 360,
                "video_html": "<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/86ib0sfdFtw?start=718&feature=oembed&start=718&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>",
                "video_html_width": 400,
                "video_html_height": 225,
                "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png",
                "id": 1,
                "original_url": "https://youtu.be/86ib0sfdFtw?t=718s",
                "fallback": "YouTube Video: 061: Interpolation, Extrapolation and Linearisation (Prof. Yann LeCun, Dr. Randall Balestriero)",
                "title": "061: Interpolation, Extrapolation and Linearisation (Prof. Yann LeCun, Dr. Randall Balestriero)",
                "title_link": "https://youtu.be/86ib0sfdFtw?t=718s",
                "author_name": "Machine Learning Street Talk",
                "author_link": "https://www.youtube.com/c/MachineLearningStreetTalk",
                "service_name": "YouTube",
                "service_url": "https://www.youtube.com/"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "a7V",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thank you. Very lucid paper\u2014 and still on the edge of my ability to read without spending all day on the math. Any main takeaways for you? Fig 3 will be a reference to hold onto. I\u2019m still kind of hung up on \u201cNone of these diagnostics address the issues encountered if the model is misspecified and the simulator is not an accurate description of the system being studied\u201d; I\u2019m trying to get my head wrapped around the inductive process of developing the model in the first place and then adapting it as the world changes.\n\nOn another math note, you may find "
                            },
                            {
                                "type": "link",
                                "url": "http://proceedings.mlr.press/v80/balestriero18b/balestriero18b.pdf",
                                "text": "this analysis"
                            },
                            {
                                "type": "text",
                                "text": " of how NNs really work interesting. Nice 15-20 min "
                            },
                            {
                                "type": "link",
                                "url": "https://youtu.be/86ib0sfdFtw?t=718s",
                                "text": "discussion here"
                            },
                            {
                                "type": "text",
                                "text": " starting at minute 12."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1642520639.090700",
        "parent_user_id": "U9C92716C"
    },
    {
        "client_msg_id": "3bb52471-515e-46e8-9762-5859eff0b406",
        "type": "message",
        "text": "The sentence you quote is actually one of the main takeaways for me. It's the same issue we have with Bayesian modelling and many other data-heavy methods: there is some basic layer of assumptions baked into the system before any data flows in, and those assumptions cannot be tested, no matter how much data is available. I suspect it's the same with human learning, but our basic assumptions about the world have been shaped by evolution to be reasonable (perhaps I am overly optimistic here!).",
        "user": "UJBAJNFLK",
        "ts": "1642667395.100200",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "aJUJ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The sentence you quote is actually one of the main takeaways for me. It's the same issue we have with Bayesian modelling and many other data-heavy methods: there is some basic layer of assumptions baked into the system before any data flows in, and those assumptions cannot be tested, no matter how much data is available. I suspect it's the same with human learning, but our basic assumptions about the world have been shaped by evolution to be reasonable (perhaps I am overly optimistic here!)."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1642520639.090700",
        "parent_user_id": "U9C92716C"
    },
    {
        "client_msg_id": "19eee505-0f03-4111-b29f-bdf23094ad19",
        "type": "message",
        "text": "BTW, one of the authors has a nice Web site / blog with material on the use of AI in science: <https://astroautomata.com/>",
        "user": "UJBAJNFLK",
        "ts": "1642667546.100400",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "from_url": "https://astroautomata.com/",
                "image_url": "http://astroautomata.com//assets/images/personal_logo.jpg",
                "image_width": 736,
                "image_height": 250,
                "image_bytes": 1536550,
                "service_icon": "https://astroautomata.com/apple-icon-57x57.png",
                "id": 1,
                "original_url": "https://astroautomata.com/",
                "fallback": "astro automata",
                "text": "Personal website of Miles Cranmer",
                "title": "astro automata",
                "title_link": "https://astroautomata.com/",
                "service_name": "astroautomata.com"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "PpPJM",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "BTW, one of the authors has a nice Web site / blog with material on the use of AI in science: "
                            },
                            {
                                "type": "link",
                                "url": "https://astroautomata.com/"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1642520639.090700",
        "parent_user_id": "U9C92716C"
    },
    {
        "client_msg_id": "edd0a48b-8ec1-48f2-9cae-bc7f9419f4e7",
        "type": "message",
        "text": "I had an interesting exchange with him in the comments section of one blog post: <https://astroautomata.com/paper/symbolic-neural-nets/>",
        "user": "UJBAJNFLK",
        "ts": "1642667609.100700",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "from_url": "https://astroautomata.com/paper/symbolic-neural-nets/",
                "ts": 1592697600,
                "image_url": "http://astroautomata.com//assets/images/discovering_symbolic_eqn_gn.png",
                "image_width": 459,
                "image_height": 250,
                "image_bytes": 1607077,
                "service_icon": "https://astroautomata.com/apple-icon-57x57.png",
                "id": 1,
                "original_url": "https://astroautomata.com/paper/symbolic-neural-nets/",
                "fallback": "astro automata: Discovering Symbolic Models from Deep Learning with Inductive Biases",
                "text": "Personal website of Miles Cranmer",
                "title": "Discovering Symbolic Models from Deep Learning with Inductive Biases",
                "title_link": "https://astroautomata.com/paper/symbolic-neural-nets/",
                "service_name": "astro automata"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "uc11E",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I had an interesting exchange with him in the comments section of one blog post: "
                            },
                            {
                                "type": "link",
                                "url": "https://astroautomata.com/paper/symbolic-neural-nets/"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1642520639.090700",
        "parent_user_id": "U9C92716C"
    },
    {
        "client_msg_id": "85ce22c2-f14a-405f-b123-0a7de39989cd",
        "type": "message",
        "text": "That video looks interesting indeed, the paper is on my reading list. The discussion reminds me of how NNs are introduced in St\u00e9phane Mallat's excellent course (<https://www.college-de-france.fr/site/stephane-mallat/_course.htm>, in French).",
        "user": "UJBAJNFLK",
        "ts": "1642668188.101000",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "from_url": "https://www.college-de-france.fr/site/stephane-mallat/_course.htm",
                "image_url": "https://www.college-de-france.fr//images/interface/video-default-480x360.png",
                "image_width": 333,
                "image_height": 250,
                "image_bytes": 253374,
                "service_icon": "https://www.college-de-france.fr/favicon.ico",
                "id": 1,
                "original_url": "https://www.college-de-france.fr/site/stephane-mallat/_course.htm",
                "fallback": "Accueil",
                "text": "St\u00e9phane Mallat - Sciences des donn\u00e9es - St\u00e9phane Mallat est math\u00e9maticien, laur\u00e9at de la m\u00e9daille de l'innovation du CNRS. Professeur au Coll\u00e8ge de France depuis 2017, il occupe la chaire Sciences des donn\u00e9es.",
                "title": "Accueil",
                "title_link": "https://www.college-de-france.fr/site/stephane-mallat/_course.htm",
                "service_name": "college-de-france.fr"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "U02l",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "That video looks interesting indeed, the paper is on my reading list. The discussion reminds me of how NNs are introduced in St\u00e9phane Mallat's excellent course ("
                            },
                            {
                                "type": "link",
                                "url": "https://www.college-de-france.fr/site/stephane-mallat/_course.htm"
                            },
                            {
                                "type": "text",
                                "text": ", in French)."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1642520639.090700",
        "parent_user_id": "U9C92716C"
    }
]