[
    {
        "client_msg_id": "97426a01-4cd7-4a56-9a9f-8e0e7e26081c",
        "type": "message",
        "text": "<@UEQ6M68H0>\n&gt; \u2026 it makes the game far harder to understand and prove correct than something much more conventional.\n\nThis seems right at first glance, but I would want to learn more about the tooling before I agree. I still have only skimmed the linked papers, but the original authors rely on model-checking for various aspects of BP already, so I suspect proving correctness of tic-tac-toe is within reach.\n\nAs for understanding, well, if the idea that the event log is all that matters to understanding legacy code is true, then a tool that lets you manually or programmatically explore potential event logs might be even better than trying to find all the move validation code in a traditional code base. Certainly, if the way you understand a program is with event logs, that would make answering reachability questions like \"what happens when 'X' tries to move\" or \"what can prevent an 'X' move\" straight-forward. The answer to the first is a printout, and the answer to the second is some representation of \"if it's preceded by an 'X' move.\"\n\nI'm definitely imagining the best possible scenario, though. BP is on my reading list now, so perhaps I'll be brought back to earth soon. :slightly_smiling_face:",
        "user": "UFEQUBNNT",
        "ts": "1581238268.054500",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "CBnC1",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UEQ6M68H0"
                            },
                            {
                                "type": "text",
                                "text": "\n> \u2026 it makes the game far harder to understand and prove correct than something much more conventional.\n\nThis seems right at first glance, but I would want to learn more about the tooling before I agree. I still have only skimmed the linked papers, but the original authors rely on model-checking for various aspects of BP already, so I suspect proving correctness of tic-tac-toe is within reach.\n\nAs for understanding, well, if the idea that the event log is all that matters to understanding legacy code is true, then a tool that lets you manually or programmatically explore potential event logs might be even better than trying to find all the move validation code in a traditional code base. Certainly, if the way you understand a program is with event logs, that would make answering reachability questions like \"what happens when 'X' tries to move\" or \"what can prevent an 'X' move\" straight-forward. The answer to the first is a printout, and the answer to the second is some representation of \"if it's preceded by an 'X' move.\"\n\nI'm definitely imagining the best possible scenario, though. BP is on my reading list now, so perhaps I'll be brought back to earth soon. "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1580955499.046800",
        "parent_user_id": "USUMN6XLH"
    },
    {
        "client_msg_id": "5cd77580-acaa-49dd-b765-9898d64d5923",
        "type": "message",
        "text": "Temporal logic means different things to different people. I suggest you refine your question so that the answers are more relevant to your purposes.\n\nMy Beads language runtime has an automatic temporal logic built in, that schedules affected portions of the screen for refresh based on changes in the underlying model. It is an invisible system that saves the programmer the trouble of calculating for every microscopic change in the underlying model, which layout/drawing functions need to be called again. This is very useful for a 2D world, but to be frank many people are using 3D interfaces now and they refresh the whole model on every single frame, so they don't have to bother guessing which part to redraw (under-draw causes glitches, and over-draw slows the product down). There is a certain brute-force simplicity to stored 3D graphics.\n\nIt also can run backwards post-mortem, which is a temporal operation that is extremely useful for debugging client problems. One of the biggest problems facing software today is the inability for companies to replicate intermittent problems, based on complex user-specific data values, with the result that companies like MS, Apple and Adobe have hundreds of thousands if not millions of open bugs reported that the vast majority of fall into the category \"cannot duplicate\" so they fester in their bug reporting systems. We are in an era where consumers accept sloppy products that are riddled with minor bugs, and i find it personally abhorrent that it is so acceptable. With so many projects grown to a size where a single person cannot understand the product from top to bottom, we are in a very dark age IMHO.",
        "user": "UEQ6M68H0",
        "ts": "1581282078.059800",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UEQ6M68H0",
            "ts": "1581316906.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "sqgN",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Temporal logic means different things to different people. I suggest you refine your question so that the answers are more relevant to your purposes.\n\nMy Beads language runtime has an automatic temporal logic built in, that schedules affected portions of the screen for refresh based on changes in the underlying model. It is an invisible system that saves the programmer the trouble of calculating for every microscopic change in the underlying model, which layout/drawing functions need to be called again. This is very useful for a 2D world, but to be frank many people are using 3D interfaces now and they refresh the whole model on every single frame, so they don't have to bother guessing which part to redraw (under-draw causes glitches, and over-draw slows the product down). There is a certain brute-force simplicity to stored 3D graphics.\n\nIt also can run backwards post-mortem, which is a temporal operation that is extremely useful for debugging client problems. One of the biggest problems facing software today is the inability for companies to replicate intermittent problems, based on complex user-specific data values, with the result that companies like MS, Apple and Adobe have hundreds of thousands if not millions of open bugs reported that the vast majority of fall into the category \"cannot duplicate\" so they fester in their bug reporting systems. We are in an era where consumers accept sloppy products that are riddled with minor bugs, and i find it personally abhorrent that it is so acceptable. With so many projects grown to a size where a single person cannot understand the product from top to bottom, we are in a very dark age IMHO."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1581027718.051600",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "9d594b06-a70a-4e98-8617-f9c58b342ecc",
        "type": "message",
        "text": "I mean \"temporal logic\"(s) in the sense of \"propositional logic\" or \"predicate logic\". It's a niche mathematical topic, and I don't expect many people to know anything about it. I thought it was worth asking though!",
        "user": "UCGAK10LS",
        "ts": "1581283679.060000",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Hh2Y",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I mean \"temporal logic\"(s) in the sense of \"propositional logic\" or \"predicate logic\". It's a niche mathematical topic, and I don't expect many people to know anything about it. I thought it was worth asking though!"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1581027718.051600",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "bc9db91a-2835-44b4-97ab-08d0cd534026",
        "type": "message",
        "text": "I would classify the behaviours you're describing as incremental update, and reverse (or record-replay) debugging, respectively. These are their own theoretical topics :slightly_smiling_face:",
        "user": "UCGAK10LS",
        "ts": "1581283910.060200",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "oKXqu",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I would classify the behaviours you're describing as incremental update, and reverse (or record-replay) debugging, respectively. These are their own theoretical topics "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1581027718.051600",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "aa8b0286-580f-4530-a410-7da476e15af0",
        "type": "message",
        "text": "<@UFEQUBNNT> It would be a great breakthrough if we discovered that decomposing problems into behaviors aided in creating verified models for them. I haven't seen this yet, but it seems worth exploring.\n\nAlso, you're right that BP can seem quite useful if you imagine the best possible scenario. But that doesn't seem how it's being sold. It seems to be sold as a methodogical silver bullet. Just use it and all problems become easy. If they instead said, \"if used well it will help\" I'd be much more amenable.\n\n*Exhibit A* _\"What if we could make changes or understand how complex systems work without having to read and maintain an artifact.\"_ (OP, 3:34) This seems wildly overblown. You still have to maintain the artifact. Especially if you want the desired model to be a linear/affine combination of the input behaviors. Because there are certainly many more combinations of behaviors that lead to spaghetti than not.\n\nI had a conversation with Luca Matteis a month ago (<https://twitter.com/lmatteis/status/1204862635537252352>) where we chatted a bit about my layers as compared to BP. I'm careful not to claim my layers always help. It takes taste to decompose programs into layers the right way. Even so, BP seems to lack one thing layers provide: intermediate combinations are useful, and functionality grows in a monotonic way. What happens to a BP program if you take out one behavior? Is it still legal? Easy to reason about? Useful? I haven't seen anybody answer these questions.\n\n*Exhibit B* Here's a less technical description of BP by the creator: <http://www.wisdom.weizmann.ac.il/~harel/papers/LiberatingProgramming.pdf>. It seems _incredibly_ overblown. We discussed it back in Dec 2018, but that's way beyond the visible window of this forum. Here's a comment I wrote there about it.\n\n---\n\n&gt; ...current methods for dealing with programming the dynamics of reactivity, however powerful and convenient, suffer from the same woes: We sit in front of a screen and write (or draw) programs that prescribe the behavior for each of the relevant parts of the system over time. Then we must check/test/verify that the combined behavior of all the parts satisfies a separately specified set of requirements or constraints. ... There is no need for separate specifications for the operational tasks and the requirements thereof. Anything that falls inside the total sum of what has been played-in will be a legal behavior of the system. \nI'm still wrapping my head around this vision, but I think it's ignoring the essential complexity of programming. On a fundamental level programmers deal with non-linear building blocks; interactions between constraints can be hard to imagine ahead of time. How would you gain confidence that you've \"played-in\" a project sufficiently to work out possible constraints?\n\nAdmittedly we have trouble doing this with existing systems. But surely we need to pay _more_ attention to constraints, not less. Representing actions physically makes it more difficult to survey all actions entered so far, the scenarios they apply in, etc.\n\nCheck/test/verify is the _fundamental_, irreducible core of programming. Trying to eliminate it is a fool's errand.\n\nLSC (the original Behavioral Programming system) introduces the notion of \"play-in\" to describe scenarios and how the system should react to them. So there'll be a natural tendency for the number of scenarios and handlers to grow. It's unclear to me how the opposite dynamic of _generalizing scenarios_ happens. How does the system encourage noticing that two scenarios are special cases of a single one and may be coalesced? How does the programmer/user replace two played-in scenarios with a single new one? Without supporting this countervailing operation, the whole system will descend into monotonically complexifying spaghetti.\n\n---\n\nBased on this quote, I don't think BP started out envisioning model-checking. If they've since started to do so, I'd appreciate recent papers.",
        "user": "UCUSW7WVD",
        "ts": "1581288917.060400",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UCUSW7WVD",
            "ts": "1581292163.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "zUFe",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UFEQUBNNT"
                            },
                            {
                                "type": "text",
                                "text": " It would be a great breakthrough if we discovered that decomposing problems into behaviors aided in creating verified models for them. I haven't seen this yet, but it seems worth exploring.\n\nAlso, you're right that BP can seem quite useful if you imagine the best possible scenario. But that doesn't seem how it's being sold. It seems to be sold as a methodogical silver bullet. Just use it and all problems become easy. If they instead said, \"if used well it will help\" I'd be much more amenable.\n\n"
                            },
                            {
                                "type": "text",
                                "text": "Exhibit A",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " "
                            },
                            {
                                "type": "text",
                                "text": "\"What if we could make changes or understand how complex systems work without having to read and maintain an artifact.\"",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " (OP, 3:34) This seems wildly overblown. You still have to maintain the artifact. Especially if you want the desired model to be a linear/affine combination of the input behaviors. Because there are certainly many more combinations of behaviors that lead to spaghetti than not.\n\nI had a conversation with Luca Matteis a month ago ("
                            },
                            {
                                "type": "link",
                                "url": "https://twitter.com/lmatteis/status/1204862635537252352"
                            },
                            {
                                "type": "text",
                                "text": ") where we chatted a bit about my layers as compared to BP. I'm careful not to claim my layers always help. It takes taste to decompose programs into layers the right way. Even so, BP seems to lack one thing layers provide: intermediate combinations are useful, and functionality grows in a monotonic way. What happens to a BP program if you take out one behavior? Is it still legal? Easy to reason about? Useful? I haven't seen anybody answer these questions.\n\n"
                            },
                            {
                                "type": "text",
                                "text": "Exhibit B",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " Here's a less technical description of BP by the creator: "
                            },
                            {
                                "type": "link",
                                "url": "http://www.wisdom.weizmann.ac.il/~harel/papers/LiberatingProgramming.pdf"
                            },
                            {
                                "type": "text",
                                "text": ". It seems "
                            },
                            {
                                "type": "text",
                                "text": "incredibly",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " overblown. We discussed it back in Dec 2018, but that's way beyond the visible window of this forum. Here's a comment I wrote there about it.\n\n---\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "...current methods for dealing with programming the dynamics of reactivity, however powerful and convenient, suffer from the same woes: We sit in front of a screen and write (or draw) programs that prescribe the behavior for each of the relevant parts of the system over time. Then we must check/test/verify that the combined behavior of all the parts satisfies a separately specified set of requirements or constraints. ... There is no need for separate specifications for the operational tasks and the requirements thereof. Anything that falls inside the total sum of what has been played-in will be a legal behavior of the system. "
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'm still wrapping my head around this vision, but I think it's ignoring the essential complexity of programming. On a fundamental level programmers deal with non-linear building blocks; interactions between constraints can be hard to imagine ahead of time. How would you gain confidence that you've \"played-in\" a project sufficiently to work out possible constraints?\n\nAdmittedly we have trouble doing this with existing systems. But surely we need to pay "
                            },
                            {
                                "type": "text",
                                "text": "more",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " attention to constraints, not less. Representing actions physically makes it more difficult to survey all actions entered so far, the scenarios they apply in, etc.\n\nCheck/test/verify is the "
                            },
                            {
                                "type": "text",
                                "text": "fundamental",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ", irreducible core of programming. Trying to eliminate it is a fool's errand.\n\nLSC (the original Behavioral Programming system) introduces the notion of \"play-in\" to describe scenarios and how the system should react to them. So there'll be a natural tendency for the number of scenarios and handlers to grow. It's unclear to me how the opposite dynamic of "
                            },
                            {
                                "type": "text",
                                "text": "generalizing scenarios",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " happens. How does the system encourage noticing that two scenarios are special cases of a single one and may be coalesced? How does the programmer/user replace two played-in scenarios with a single new one? Without supporting this countervailing operation, the whole system will descend into monotonically complexifying spaghetti.\n\n---\n\nBased on this quote, I don't think BP started out envisioning model-checking. If they've since started to do so, I'd appreciate recent papers."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1580955499.046800",
        "parent_user_id": "USUMN6XLH"
    }
]