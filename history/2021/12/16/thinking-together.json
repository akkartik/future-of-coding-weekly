[
    {
        "client_msg_id": "21c07827-4efe-424b-a079-e6d0bbb82cac",
        "type": "message",
        "text": "#language-design-philosophy\nA data structure that\u2019s orthogonal at its core? Why is that so hard to think of? Why is there such a strong tradition in CS/PLD to think in composition by nesting but not of orthogonal composition? What if we (language designers, at least) are missing something here?\n\nWhy do I post such an underspecified topic? I think there is little doubt that perceiving orthogonally is a fundamental feature of human cognition, and that current language design fails to support this.\n\nAnd, yes, I don\u2019t even know how to argue for this. This may be frustrating to try to think of. I must admit; I\u2019ve learned to appreciate the feeling that there does exist something, that it must exist, but I can only just almost try and grasp it.\n\nWhat do you do in similar mental configurations? Grab a whiteboard? Begin writing an essay? Write some code that assumes the `thing` exists in order to reach your intuition for it (\u201cair coding\u201d)?\n\nYour..\n+ thoughts on this experience\n+ ideas for an attack on this problem\n.. are welcome! :slightly_smiling_face: :heart:",
        "user": "U02M6PM725T",
        "ts": "1639646202.271700",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "U02M6PM725T",
            "ts": "1639647208.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "H5nzc",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "#language-design-philosophy\nA data structure that\u2019s orthogonal at its core? Why is that so hard to think of? Why is there such a strong tradition in CS/PLD to think in composition by nesting but not of orthogonal composition? What if we (language designers, at least) are missing something here?\n\nWhy do I post such an underspecified topic? I think there is little doubt that perceiving orthogonally is a fundamental feature of human cognition, and that current language design fails to support this.\n\nAnd, yes, I don\u2019t even know how to argue for this. This may be frustrating to try to think of. I must admit; I\u2019ve learned to appreciate the feeling that there does exist something, that it must exist, but I can only just almost try and grasp it.\n\nWhat do you do in similar mental configurations? Grab a whiteboard? Begin writing an essay? Write some code that assumes the "
                            },
                            {
                                "type": "text",
                                "text": "thing",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " exists in order to reach your intuition for it (\u201cair coding\u201d)?\n\nYour..\n+ thoughts on this experience\n+ ideas for an attack on this problem\n.. are welcome! "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face"
                            },
                            {
                                "type": "text",
                                "text": " "
                            },
                            {
                                "type": "emoji",
                                "name": "heart"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1639646202.271700",
        "reply_count": 10,
        "reply_users_count": 4,
        "latest_reply": "1639755918.278100",
        "reply_users": [
            "U02E4DAQGSZ",
            "U02M6PM725T",
            "U9C92716C",
            "U016VUZGUUQ"
        ],
        "is_locked": false,
        "subscribed": false
    },
    {
        "client_msg_id": "c1672094-3b53-4e2a-8a2e-28a51d5f1358",
        "type": "message",
        "text": "If by orthogonality you mean cross product kind of things, I think Concurrent Hierarchical State Machines / UML statecharts can represent orthogonality well with a closed form PARALLEL operator for two state machines.\n\nBut this is orthogonal in the sense the two things are independant, the state of the system is the cross product. In the simplest form they do not interact, though it does have mechanisms for communicating.\n\n<https://link.springer.com/content/pdf/10.1007/3-540-44929-9_24.pdf>\n\nIs this the right lines of thinking?",
        "user": "U02E4DAQGSZ",
        "ts": "1639646991.271800",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "6FM7",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "If by orthogonality you mean cross product kind of things, I think Concurrent Hierarchical State Machines / UML statecharts can represent orthogonality well with a closed form PARALLEL operator for two state machines.\n\nBut this is orthogonal in the sense the two things are independant, the state of the system is the cross product. In the simplest form they do not interact, though it does have mechanisms for communicating.\n\n"
                            },
                            {
                                "type": "link",
                                "url": "https://link.springer.com/content/pdf/10.1007/3-540-44929-9_24.pdf"
                            },
                            {
                                "type": "text",
                                "text": "\n\nIs this the right lines of thinking?"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1639646202.271700",
        "parent_user_id": "U02M6PM725T"
    },
    {
        "client_msg_id": "208296aa-e831-4a20-b40c-1a4cf83c77a9",
        "type": "message",
        "text": "<@U02E4DAQGSZ> You are reading my thoughts!",
        "user": "U02M6PM725T",
        "ts": "1639647323.272100",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "3Kv3",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U02E4DAQGSZ"
                            },
                            {
                                "type": "text",
                                "text": " You are reading my thoughts!"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1639646202.271700",
        "parent_user_id": "U02M6PM725T"
    },
    {
        "client_msg_id": "6aa3be42-bd1d-4aca-8884-7b951e74d7af",
        "type": "message",
        "text": "cool, so the root of these machines is the ragular language thingys. So maybe a regex can be considered a representation with orthogonality at its core too (you can concatenate and | regex expressions). I like HSM formalisms though because they play well with formal verification and somewhat resemble normal programming if you squint really hard.",
        "user": "U02E4DAQGSZ",
        "ts": "1639647680.272300",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "V5y",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "cool, so the root of these machines is the ragular language thingys. So maybe a regex can be considered a representation with orthogonality at its core too (you can concatenate and | regex expressions). I like HSM formalisms though because they play well with formal verification and somewhat resemble normal programming if you squint really hard."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1639646202.271700",
        "parent_user_id": "U02M6PM725T",
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "U02M6PM725T"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "11493f8c-bc86-43ad-a043-620b878aeebc",
        "type": "message",
        "text": "<@U02E4DAQGSZ> Yes, I think HSM takes state machines in a great direction! I am pondering the following way to perceive orthogonality in HSM\u2019s. Traditionally we would look at is as the typical concrete representation invites: `{ a: { b: { c: ... } }, d: ..., e: ...}` .  So I consider the idea that this is more concrete  than it need be philosophically. Here is an attack: Let\u2019s define two operators: `&amp;` for combining values into and-states, and `:` for combining values into hierarchies. Then we write `a:b:c  &amp; d &amp; e` . Traditionally, the CS practitioner and programmer would ask for precedence rules or brackets to disambiguate the expression:\n `{(a:b:c), d, e}` or  `{a:(b:c) , d , e }` . Here is the point where an alternative orthogonal model might be possible and might be valuable from a language-design point-of-view: In stead of nesting we lay out the values in a two-dimensional grid, e.g. drawing the  `&amp;` relation horizontally, and the `:` vertically upwards. Then, a noteworthy thing can be observed: _The `a` value is now both an element in the and-state (horizontal relation) and the first element in the hierarchy (vertical relation)._ This is my criteria for detecting of orthogonality, as I meant it in the OP.\n\n_Wow thanks!, it was kind of cool to actually write it down._ \n\nFollow-up question: So, while this evidently is drawable; does it map well to cognition, implementation? Is it view-point in the eye of the beholder, or does it open up them HSM model for e.g. generalization/deeper understanding?",
        "user": "U02M6PM725T",
        "ts": "1639649195.272600",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "U02M6PM725T",
            "ts": "1639649505.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "7DP",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U02E4DAQGSZ"
                            },
                            {
                                "type": "text",
                                "text": " Yes, I think HSM takes state machines in a great direction! I am pondering the following way to perceive orthogonality in HSM\u2019s. Traditionally we would look at is as the typical concrete representation invites: "
                            },
                            {
                                "type": "text",
                                "text": "{ a: { b: { c: ... } }, d: ..., e: ...}",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " .  So I consider the idea that this is more concrete  than it need be philosophically. Here is an attack: Let\u2019s define two operators: "
                            },
                            {
                                "type": "text",
                                "text": "&",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " for combining values into and-states, and "
                            },
                            {
                                "type": "text",
                                "text": ":",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " for combining values into hierarchies. Then we write "
                            },
                            {
                                "type": "text",
                                "text": "a:b:c  & d & e",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " . Traditionally, the CS practitioner and programmer would ask for precedence rules or brackets to disambiguate the expression:\n "
                            },
                            {
                                "type": "text",
                                "text": "{(a:b:c), d, e}",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " or  "
                            },
                            {
                                "type": "text",
                                "text": "{a:(b:c) , d , e }",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " . Here is the point where an alternative orthogonal model might be possible and might be valuable from a language-design point-of-view: In stead of nesting we lay out the values in a two-dimensional grid, e.g. drawing the  "
                            },
                            {
                                "type": "text",
                                "text": "&",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " relation horizontally, and the "
                            },
                            {
                                "type": "text",
                                "text": ":",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " vertically upwards. Then, a noteworthy thing can be observed: "
                            },
                            {
                                "type": "text",
                                "text": "The ",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "a",
                                "style": {
                                    "italic": true,
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " value is now both an element in the and-state (horizontal relation) and the first element in the hierarchy (vertical relation).",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " This is my criteria for detecting of orthogonality, as I meant it in the OP.\n\n"
                            },
                            {
                                "type": "text",
                                "text": "Wow thanks!, it was kind of cool to actually write it down. ",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\n\nFollow-up question: So, while this evidently is drawable; does it map well to cognition, implementation? Is it view-point in the eye of the beholder, or does it open up them HSM model for e.g. generalization/deeper understanding?"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1639646202.271700",
        "parent_user_id": "U02M6PM725T"
    },
    {
        "client_msg_id": "aa992db3-ed7c-4952-a40d-35914b36f1f6",
        "type": "message",
        "text": "My own experience is that HSMs are hard to program, but they are amenable to machine verification because their state space is enumerable. So thats useful, and in practice the paxos protocol is a runner for state machines, so they are used in technical domains for real (not sure about flavour of state machiens though, maybe not HSM).\n\nI also see them in realtime systems (<https://www.state-machine.com/>) again, coz they are complex enough to be useful, but simple enough to really figure out and trace symbolically.\n\nThe QP frameworks people make a strong argument that HSM is necessary to avoid the state space explosion problem that basic state machines suffer from. This is directly because of the orthogonality. When you can express things as two orthogonal basis vectors you avoid having to flatten them into their non orthogonal space (the cross product). So yeah, I would say orthogonality has made state machine scale to the realtime systems domain. Of course, HSM are still less expressive than turing machines so they clearly are not used much when we have access to higher level languages and want to move fast and break things.",
        "user": "U02E4DAQGSZ",
        "ts": "1639649913.273100",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "from_url": "https://www.state-machine.com/",
                "ts": 1598264356,
                "image_url": "https://www.state-machine.com/wp-content/uploads/bg_emb-e1609363629666.jpg",
                "image_width": 313,
                "image_height": 250,
                "image_bytes": 55617,
                "service_icon": "https://www.state-machine.com/wp-content/uploads/cropped-icon_ql-180x180.png",
                "id": 1,
                "original_url": "https://www.state-machine.com/",
                "fallback": "Modern Embedded Software | Quantum Leaps: Modern Embedded Software - Quantum Leaps",
                "text": "QP real-time embedded frameworks (RTEFs) and QM visual modeling tool based on finite state machines and active objects. Ideal for ARM Cortex-M and other MCUs.",
                "title": "Modern Embedded Software - Quantum Leaps",
                "title_link": "https://www.state-machine.com/",
                "service_name": "Modern Embedded Software | Quantum Leaps"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "3B7TI",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "My own experience is that HSMs are hard to program, but they are amenable to machine verification because their state space is enumerable. So thats useful, and in practice the paxos protocol is a runner for state machines, so they are used in technical domains for real (not sure about flavour of state machiens though, maybe not HSM).\n\nI also see them in realtime systems ("
                            },
                            {
                                "type": "link",
                                "url": "https://www.state-machine.com/"
                            },
                            {
                                "type": "text",
                                "text": ") again, coz they are complex enough to be useful, but simple enough to really figure out and trace symbolically.\n\nThe QP frameworks people make a strong argument that HSM is necessary to avoid the state space explosion problem that basic state machines suffer from. This is directly because of the orthogonality. When you can express things as two orthogonal basis vectors you avoid having to flatten them into their non orthogonal space (the cross product). So yeah, I would say orthogonality has made state machine scale to the realtime systems domain. Of course, HSM are still less expressive than turing machines so they clearly are not used much when we have access to higher level languages and want to move fast and break things."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1639646202.271700",
        "parent_user_id": "U02M6PM725T",
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "U02M6PM725T"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "240e3d1f-fe5a-454c-b01f-fa36e2b258cb",
        "type": "message",
        "text": "This page expresses it much better and I think it is about orthogonality <https://www.state-machine.com/fsm>",
        "user": "U02E4DAQGSZ",
        "ts": "1639650012.273400",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "U02E4DAQGSZ",
            "ts": "1639650035.000000"
        },
        "attachments": [
            {
                "from_url": "https://www.state-machine.com/fsm",
                "ts": 1610150797,
                "image_url": "https://www.state-machine.com/wp-content/uploads/key-concept.png",
                "image_width": 250,
                "image_height": 250,
                "image_bytes": 33407,
                "service_icon": "https://www.state-machine.com/wp-content/uploads/cropped-icon_ql-180x180.png",
                "id": 1,
                "original_url": "https://www.state-machine.com/fsm",
                "fallback": "Modern Embedded Software | Quantum Leaps: Key concept: Finite State Machine (FSM)",
                "text": "Finite State Machine (FSM) is a very powerful and effective technique of designing event-driven software.",
                "title": "Key concept: Finite State Machine (FSM)",
                "title_link": "https://www.state-machine.com/fsm",
                "service_name": "Modern Embedded Software | Quantum Leaps"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "S4M/",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "This page expresses it much better and I think it is about orthogonality "
                            },
                            {
                                "type": "link",
                                "url": "https://www.state-machine.com/fsm"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1639646202.271700",
        "parent_user_id": "U02M6PM725T",
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "U02M6PM725T"
                ],
                "count": 1
            }
        ]
    },
    {
        "type": "message",
        "text": "(yes I agree with your orthogonality picture, except that the H itself is an orthogonal, so we don't really need the concurrency bit for HSM to add orthogonality to FSMs). I think in this diagram the edges are dimension in your orthogonal space diagram",
        "files": [
            {
                "id": "F02QK4D4PDM",
                "created": 1639651400,
                "timestamp": 1639651400,
                "name": "image.png",
                "title": "image.png",
                "mimetype": "image/png",
                "filetype": "png",
                "pretty_type": "PNG",
                "user": "U02E4DAQGSZ",
                "editable": false,
                "size": 169029,
                "mode": "hosted",
                "is_external": false,
                "external_type": "",
                "is_public": true,
                "public_url_shared": false,
                "display_as_bot": false,
                "username": "",
                "url_private": "https://files.slack.com/files-pri/T5TCAFTA9-F02QK4D4PDM/image.png",
                "url_private_download": "https://files.slack.com/files-pri/T5TCAFTA9-F02QK4D4PDM/download/image.png",
                "media_display_type": "unknown",
                "thumb_64": "https://files.slack.com/files-tmb/T5TCAFTA9-F02QK4D4PDM-bc9e5d547a/image_64.png",
                "thumb_80": "https://files.slack.com/files-tmb/T5TCAFTA9-F02QK4D4PDM-bc9e5d547a/image_80.png",
                "thumb_360": "https://files.slack.com/files-tmb/T5TCAFTA9-F02QK4D4PDM-bc9e5d547a/image_360.png",
                "thumb_360_w": 360,
                "thumb_360_h": 177,
                "thumb_480": "https://files.slack.com/files-tmb/T5TCAFTA9-F02QK4D4PDM-bc9e5d547a/image_480.png",
                "thumb_480_w": 480,
                "thumb_480_h": 236,
                "thumb_160": "https://files.slack.com/files-tmb/T5TCAFTA9-F02QK4D4PDM-bc9e5d547a/image_160.png",
                "thumb_720": "https://files.slack.com/files-tmb/T5TCAFTA9-F02QK4D4PDM-bc9e5d547a/image_720.png",
                "thumb_720_w": 720,
                "thumb_720_h": 354,
                "thumb_800": "https://files.slack.com/files-tmb/T5TCAFTA9-F02QK4D4PDM-bc9e5d547a/image_800.png",
                "thumb_800_w": 800,
                "thumb_800_h": 394,
                "thumb_960": "https://files.slack.com/files-tmb/T5TCAFTA9-F02QK4D4PDM-bc9e5d547a/image_960.png",
                "thumb_960_w": 960,
                "thumb_960_h": 472,
                "original_w": 1012,
                "original_h": 498,
                "thumb_tiny": "AwAXADDRK5PWjaM/ep1GOetADQB70ALng/rRzu5Ipe9ABtH+TQABQv4YpaACg57UUUAJz6ikCkHPFOooAPrRRRQB/9k=",
                "permalink": "https://futureofcoding.slack.com/files/U02E4DAQGSZ/F02QK4D4PDM/image.png",
                "permalink_public": "https://slack-files.com/T5TCAFTA9-F02QK4D4PDM-2a5042f3bd",
                "is_starred": false,
                "has_rich_preview": false
            }
        ],
        "upload": false,
        "user": "U02E4DAQGSZ",
        "display_as_bot": false,
        "ts": "1639651415.274000",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "QC0dw",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "(yes I agree with your orthogonality picture, except that the H itself is an orthogonal, so we don't really need the concurrency bit for HSM to add orthogonality to FSMs). I think in this diagram the edges are dimension in your orthogonal space diagram"
                            }
                        ]
                    }
                ]
            }
        ],
        "client_msg_id": "81a69253-cf49-40a2-ab4d-996baa4467c9",
        "thread_ts": "1639646202.271700",
        "parent_user_id": "U02M6PM725T"
    },
    {
        "client_msg_id": "7404e650-0d06-4e81-ba29-caa23b44d372",
        "type": "message",
        "text": "two, maybe three axes of orthogonality is nice for cognition. nesting is one way to manage more dimensions than that. seems to me you want to make it easy to navigate a variety of representations without losing context. <https://www.quantamagazine.org/the-brain-maps-out-ideas-and-memories-like-spaces-20190114/>",
        "user": "U9C92716C",
        "ts": "1639719263.275800",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "from_url": "https://www.quantamagazine.org/the-brain-maps-out-ideas-and-memories-like-spaces-20190114/",
                "ts": 1547481300,
                "image_url": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/01/GridCells_1200_social.jpg",
                "image_width": 476,
                "image_height": 250,
                "image_bytes": 76050,
                "service_icon": "https://www.quantamagazine.org/favicon.png",
                "id": 1,
                "original_url": "https://www.quantamagazine.org/the-brain-maps-out-ideas-and-memories-like-spaces-20190114/",
                "fallback": "Quanta Magazine: The Brain Maps Out Ideas and Memories Like Spaces | Quanta Magazine",
                "text": "Emerging evidence suggests that the brain encodes abstract knowledge in the same way that it represents positions in space, which hints at a more universal theory of cognition.",
                "title": "The Brain Maps Out Ideas and Memories Like Spaces | Quanta Magazine",
                "title_link": "https://www.quantamagazine.org/the-brain-maps-out-ideas-and-memories-like-spaces-20190114/",
                "service_name": "Quanta Magazine"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "BFfA",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "two, maybe three axes of orthogonality is nice for cognition. nesting is one way to manage more dimensions than that. seems to me you want to make it easy to navigate a variety of representations without losing context. "
                            },
                            {
                                "type": "link",
                                "url": "https://www.quantamagazine.org/the-brain-maps-out-ideas-and-memories-like-spaces-20190114/"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1639646202.271700",
        "parent_user_id": "U02M6PM725T",
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "U02M6PM725T",
                    "U02E4DAQGSZ"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "a4fb24af-3583-4d8c-9ac6-bb19972df8f7",
        "type": "message",
        "text": "So many interesting ideas! There may be many features that is prevalent in perception, but under-supported in the PL tradition for mundane reasons; e.g. Regular Expressions/ matching on pure text; I see at least two perceptual features that could be nice to support: Context/Refinement and Othogonality of Horizontal/Vertical directions (2D): Refinement of selections are described e.g. in Structural Regular Expressions by Rob Pike [ <http://9p.io/sources/contrib/steve/other-docs/struct-regex.pdf|pdf> ]. But I\u2019m not aware of Regexp\u2019s that do 2D matching. It\u2019s pretty clear programmers make use of the vertical dimension e.g. by the tradition to align similar lines of code (pervasively done in Haskell and similar languages.)",
        "user": "U02M6PM725T",
        "ts": "1639730813.277600",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "T1NF",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "So many interesting ideas! There may be many features that is prevalent in perception, but under-supported in the PL tradition for mundane reasons; e.g. Regular Expressions/ matching on pure text; I see at least two perceptual features that could be nice to support: Context/Refinement and Othogonality of Horizontal/Vertical directions (2D): Refinement of selections are described e.g. in Structural Regular Expressions by Rob Pike [ "
                            },
                            {
                                "type": "link",
                                "url": "http://9p.io/sources/contrib/steve/other-docs/struct-regex.pdf",
                                "text": "pdf"
                            },
                            {
                                "type": "text",
                                "text": " ]. But I\u2019m not aware of Regexp\u2019s that do 2D matching. It\u2019s pretty clear programmers make use of the vertical dimension e.g. by the tradition to align similar lines of code (pervasively done in Haskell and similar languages.)"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1639646202.271700",
        "parent_user_id": "U02M6PM725T"
    },
    {
        "client_msg_id": "2f75a0b1-8617-486d-ab50-00663f6b543a",
        "type": "message",
        "text": "&gt; The a _value is now both an element in the and-state (horizontal relation) and the first element in the hierarchy (vertical relation)._ This is my criteria for detecting of orthogonality...\n&gt; \nIs this not satisfied any time the stuff nested under a is fully contained inside it?\n\nI'm having trouble seeing this as anything other than a syntactic change. Nesting is still going to crop up in the semantics, or at least, it will cause a lot more trouble to get rid of it than you could possibly benefit from. Syntax should clearly express that.\n\nI do think things that don't explicitly depend on each other should be allowed to be going independent. For instance, finding all the natural concurrency in a program. I don't know if this is exactly what you're saying, but I think it's related.\n\nSomewhat aside: I've come to think of nesting and sequencing as being different sides of the same concept, namely dependency. I think this is supported by the way nesting-based encodings of sequences, like linked lists and fixed points, keep cropping up.",
        "user": "U016VUZGUUQ",
        "ts": "1639755918.278100",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "mm8H",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The a"
                            },
                            {
                                "type": "text",
                                "text": " value is now both an element in the and-state (horizontal relation) and the first element in the hierarchy (vertical relation).",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " This is my criteria for detecting of orthogonality...\n"
                            }
                        ],
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nIs this not satisfied any time the stuff nested under a is fully contained inside it?\n\nI'm having trouble seeing this as anything other than a syntactic change. Nesting is still going to crop up in the semantics, or at least, it will cause a lot more trouble to get rid of it than you could possibly benefit from. Syntax should clearly express that.\n\nI do think things that don't explicitly depend on each other should be allowed to be going independent. For instance, finding all the natural concurrency in a program. I don't know if this is exactly what you're saying, but I think it's related.\n\nSomewhat aside: I've come to think of nesting and sequencing as being different sides of the same concept, namely dependency. I think this is supported by the way nesting-based encodings of sequences, like linked lists and fixed points, keep cropping up."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1639646202.271700",
        "parent_user_id": "U02M6PM725T"
    }
]