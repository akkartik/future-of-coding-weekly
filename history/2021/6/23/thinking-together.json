[
    {
        "client_msg_id": "7fd08576-5ce2-4c93-b034-d5f148d3088f",
        "type": "message",
        "text": "All modern programming languages apart from Rust (and I guess Swift, with its reference-counting) rely on garbage collection: a \"background thread\" locates memory the process has _forgotten about_ and marks it as available for re-use. However, this doesn't seem to be a sensible scheme in a distributed system where multiple processing devices each have local memories. That begs the question: if you want to design a programming language that can be transparently distributed over multiple devices, does it need to have a fancy type system (like Rust's) that enforces correct manual memory management?\n\nOne reason I'm thinking about this: most upcoming AI chips are using a \"network-on-chip\" architecture, which could also be called a \"distributed system on a chip\". A garbage collection algorithm on these chips would have to involve a message-passing protocol wherein different parts of the chip communicate to identify _forgotten_ memory. This seems like an unnecessarily complicated and expensive approach to memory management.\n\nThoughts? :unicorn_face:",
        "user": "UCGAK10LS",
        "ts": "1624437161.147900",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UCGAK10LS",
            "ts": "1624440273.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "HLJCj",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "All modern programming languages apart from Rust (and I guess Swift, with its reference-counting) rely on garbage collection: a \"background thread\" locates memory the process has "
                            },
                            {
                                "type": "text",
                                "text": "forgotten about",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " and marks it as available for re-use. However, this doesn't seem to be a sensible scheme in a distributed system where multiple processing devices each have local memories. That begs the question: if you want to design a programming language that can be transparently distributed over multiple devices, does it need to have a fancy type system (like Rust's) that enforces correct manual memory management?\n\nOne reason I'm thinking about this: most upcoming AI chips are using a \"network-on-chip\" architecture, which could also be called a \"distributed system on a chip\". A garbage collection algorithm on these chips would have to involve a message-passing protocol wherein different parts of the chip communicate to identify "
                            },
                            {
                                "type": "text",
                                "text": "forgotten",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " memory. This seems like an unnecessarily complicated and expensive approach to memory management.\n\nThoughts? "
                            },
                            {
                                "type": "emoji",
                                "name": "unicorn_face"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "reply_count": 16,
        "reply_users_count": 9,
        "latest_reply": "1624747824.171900",
        "reply_users": [
            "U5STGTB3J",
            "UBN9AFS0N",
            "U01PGQQEU2Z",
            "UA14TGLTC",
            "UT60XSVCN",
            "UCGAK10LS",
            "U025PBD75TM",
            "U013ZLJARC7",
            "U01T2EYBH0T"
        ],
        "is_locked": false,
        "subscribed": true,
        "last_read": "1624747824.171900"
    },
    {
        "client_msg_id": "3bc5b5af-b16f-4d83-9f77-b95c3cc83433",
        "type": "message",
        "text": "Like the sentiment and think Rust and Swift are on a better path, mainly because they manage memory deterministically, but if people don't find garbage collection wasteful today in basic single-threaded CPU-bound scenarios, I doubt it'll stop anybody from bringing it to a distributed environment.\n\nClassic garbage collection makes a lot of sense for a simpler, centralized memory model, like a heap. I don't know how to adapt it to a massively parallel execution environment, but I'm sure it can be done somehow, likely involving an order-of-magnitude increase in (wasted) memory along the way, but it'll be much more convenient to use I'm sure.\n\nI don't know much about \"AI chips\", but if they are optimizing for parallel execution and work anything like modern GPUs they probably already manage memory quite differently from CPUs with explicit descriptors (a form of type system), buffer hierarchies, and thread grouping with localized access to buffers. That way memory gets bound to certain computations (shaders) and freed once these computations are finished. Well, it's a little more complex as these are subdivided into workgroups, thread groups, and subgroups, but you'll get the idea.\n\nIf you squint your eyes you might see some parallels to Rust's ownership model and why deterministic memory management is so attractive, even in languages that mainly target CPUs. The future is more value (move/copy) and fewer reference semantics (\"objects\") with clear ownership to help avoid, or at least minimize, shared state, so we can reap the benefits of parallel processing. That's a promising approach to keep complexity in check, even though it might not quite feel like that yet when you're trying to configure a shader execution pipeline today.",
        "user": "U5STGTB3J",
        "ts": "1624441675.148100",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "yGF",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Like the sentiment and think Rust and Swift are on a better path, mainly because they manage memory deterministically, but if people don't find garbage collection wasteful today in basic single-threaded CPU-bound scenarios, I doubt it'll stop anybody from bringing it to a distributed environment.\n\nClassic garbage collection makes a lot of sense for a simpler, centralized memory model, like a heap. I don't know how to adapt it to a massively parallel execution environment, but I'm sure it can be done somehow, likely involving an order-of-magnitude increase in (wasted) memory along the way, but it'll be much more convenient to use I'm sure.\n\nI don't know much about \"AI chips\", but if they are optimizing for parallel execution and work anything like modern GPUs they probably already manage memory quite differently from CPUs with explicit descriptors (a form of type system), buffer hierarchies, and thread grouping with localized access to buffers. That way memory gets bound to certain computations (shaders) and freed once these computations are finished. Well, it's a little more complex as these are subdivided into workgroups, thread groups, and subgroups, but you'll get the idea.\n\nIf you squint your eyes you might see some parallels to Rust's ownership model and why deterministic memory management is so attractive, even in languages that mainly target CPUs. The future is more value (move/copy) and fewer reference semantics (\"objects\") with clear ownership to help avoid, or at least minimize, shared state, so we can reap the benefits of parallel processing. That's a promising approach to keep complexity in check, even though it might not quite feel like that yet when you're trying to configure a shader execution pipeline today."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "f319d932-0b7e-4660-91cb-fef086b68fc4",
        "type": "message",
        "text": "Pony's Garbage Collection sounds the closest I can think of: <https://tutorial.ponylang.io/appendices/garbage-collection.html>",
        "user": "UBN9AFS0N",
        "ts": "1624451568.148300",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "z5nd",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Pony's Garbage Collection sounds the closest I can think of: "
                            },
                            {
                                "type": "link",
                                "url": "https://tutorial.ponylang.io/appendices/garbage-collection.html"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U019CPED6T1",
                    "U01T2EYBH0T"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "d3e0ff80-e2a8-41d7-b985-6b8c1d6bf7ef",
        "type": "message",
        "text": "There are some papers and talks about it",
        "user": "UBN9AFS0N",
        "ts": "1624451663.148500",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "BV3Z",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "There are some papers and talks about it"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "75dd45a6-6cd9-4252-a039-52e8af4fec7a",
        "type": "message",
        "text": "Nim &amp; ATS do this as well.",
        "user": "U01PGQQEU2Z",
        "ts": "1624457980.148800",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "GUj",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Nim & ATS do this as well."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "ea46e8d6-6ebc-46a5-a157-f01ae078123d",
        "type": "message",
        "text": "In my limited (yet significant) experience making a distributed system, the challenge wasn't so much garbage as ferrying relevant partial results between compute nodes.  So an ownership model may match bandwidth constraints better than potentially costly deferences.\n\nI guess it's an eager/lazy distinction.  I mean GC is certainly a performance win if you never need to actually collect it.  Granularity matters.  A lot of programs operate in a sort of loop with a lot of objects allocated per frame or per request.  So then it makes sense to have an allocator that only tracks when references cross the boundary.  Squint and you can think of that as an eager generational collector.",
        "user": "UA14TGLTC",
        "ts": "1624463680.149000",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ebhBc",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "In my limited (yet significant) experience making a distributed system, the challenge wasn't so much garbage as ferrying relevant partial results between compute nodes.  So an ownership model may match bandwidth constraints better than potentially costly deferences.\n\nI guess it's an eager/lazy distinction.  I mean GC is certainly a performance win if you never need to actually collect it.  Granularity matters.  A lot of programs operate in a sort of loop with a lot of objects allocated per frame or per request.  So then it makes sense to have an allocator that only tracks when references cross the boundary.  Squint and you can think of that as an eager generational collector."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UCGAK10LS"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "a9f5a686-ef71-4b77-aa63-7ee06ccd8727",
        "type": "message",
        "text": "I'm not sure I understand the problem\u2014you can have actor-local heaps and run gc independently while communicating via message-passing. Erlang does this",
        "user": "UT60XSVCN",
        "ts": "1624473008.149300",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "how",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'm not sure I understand the problem\u2014you can have actor-local heaps and run gc independently while communicating via message-passing. Erlang does this"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "60d964d4-a6e9-4cc1-8843-867410203f67",
        "type": "message",
        "text": "<@UT60XSVCN> That's a solution if your programming model is the actor model. By \"transparent distribution\" I mean something more implicit: your programming language doesn't have a means to talk about \"nodes\" and \"messages\", so there are no clear boundaries for a garbage collector.\n\nNote that in Erlang, you essentially have automatic memory management (GC) _within_ an actor, and manual memory management _between_ actors. If you have an actor that is holding data that will later be queried by other actors, you need to know when it is safe to delete the data (or even the entire actor), i.e. you need to know when other actors are no longer holding \"references\" to it (of some kind).\n\nIt seems like Pony has an approach for inter-actor memory management. Thanks <@UBN9AFS0N> for the link. Though as I said before, the distribution model is still not quite as implicit as I had in mind :slightly_smiling_face:. I don't think you want to program a 1000-core AI chip with the actor model. ML models don't want to be written as actor systems, and general-purpose programs even less-so.\n\nI'm bringing up AI chips because some of them will be capable of running general-purpose programs. Think of them as the next step beyond GPGPU. <https://www.tenstorrent.com/|Tenstorrent> is an example. From their FAQ:\n\u2022 \"Our computers are optimized for neural network inference and training. They can also execute other types of parallel computation.\"\n\u2022 \"Network communication hardware is present in each processor, and they talk with one another directly over (on-chip) networks, instead of through DRAM.\"\n\u2022 [Compared to GPUs] \"Our computers are easier to program, scale better, and are excellent at handling run-time sparsity and conditional computation.\"\nHopefully that answers your question <@U5STGTB3J>: the programming model is very different to that of GPUs.\n\nNote the irony that Tenstorrent's chips are an actor model at the hardware level, yet you're unlikely to want to program them using the actor model because of the sheer number of cores. What is our programming model for these machines? As stated in my original post, I think memory management needs to be explicit in the language (Rust-style), because you don't want all 1000+ cores to be running a distributed garbage collection scheme alongside the primary computation. It becomes less and less feasible the more cores you add. Tenstorrent is planning to have their chips plug directly together using high-bandwidth &amp; low-latency interconnects so that you can have 100,000 cores or more. Imagine running a garbage collector on that. Seems very much the wrong direction to go in.",
        "user": "UCGAK10LS",
        "ts": "1624496233.149800",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "mBLM",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UT60XSVCN"
                            },
                            {
                                "type": "text",
                                "text": " That's a solution if your programming model is the actor model. By \"transparent distribution\" I mean something more implicit: your programming language doesn't have a means to talk about \"nodes\" and \"messages\", so there are no clear boundaries for a garbage collector.\n\nNote that in Erlang, you essentially have automatic memory management (GC) "
                            },
                            {
                                "type": "text",
                                "text": "within",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " an actor, and manual memory management "
                            },
                            {
                                "type": "text",
                                "text": "between",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " actors. If you have an actor that is holding data that will later be queried by other actors, you need to know when it is safe to delete the data (or even the entire actor), i.e. you need to know when other actors are no longer holding \"references\" to it (of some kind).\n\nIt seems like Pony has an approach for inter-actor memory management. Thanks "
                            },
                            {
                                "type": "user",
                                "user_id": "UBN9AFS0N"
                            },
                            {
                                "type": "text",
                                "text": " for the link. Though as I said before, the distribution model is still not quite as implicit as I had in mind "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face"
                            },
                            {
                                "type": "text",
                                "text": ". I don't think you want to program a 1000-core AI chip with the actor model. ML models don't want to be written as actor systems, and general-purpose programs even less-so.\n\nI'm bringing up AI chips because some of them will be capable of running general-purpose programs. Think of them as the next step beyond GPGPU. "
                            },
                            {
                                "type": "link",
                                "url": "https://www.tenstorrent.com/",
                                "text": "Tenstorrent"
                            },
                            {
                                "type": "text",
                                "text": " is an example. From their FAQ:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "\"Our computers are optimized for neural network inference and training. They can also execute other types of parallel computation.\""
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "\"Network communication hardware is present in each processor, and they talk with one another directly over (on-chip) networks, instead of through DRAM.\""
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "[Compared to GPUs] \"Our computers are easier to program, scale better, and are excellent at handling run-time sparsity and conditional computation.\""
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nHopefully that answers your question "
                            },
                            {
                                "type": "user",
                                "user_id": "U5STGTB3J"
                            },
                            {
                                "type": "text",
                                "text": ": the programming model is very different to that of GPUs.\n\nNote the irony that Tenstorrent's chips are an actor model at the hardware level, yet you're unlikely to want to program them using the actor model because of the sheer number of cores. What is our programming model for these machines? As stated in my original post, I think memory management needs to be explicit in the language (Rust-style), because you don't want all 1000+ cores to be running a distributed garbage collection scheme alongside the primary computation. It becomes less and less feasible the more cores you add. Tenstorrent is planning to have their chips plug directly together using high-bandwidth & low-latency interconnects so that you can have 100,000 cores or more. Imagine running a garbage collector on that. Seems very much the wrong direction to go in."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "26D275A7-4AAA-45BB-915C-E34CBF7FE112",
        "type": "message",
        "text": "<@UCGAK10LS> Oh, interesting! Do you have any other pointers to more technical resources from them or about other \u201cAI chips\u201d? Their FAQ isn\u2019t going very deep and the website strikes me as very marketing/VC oriented.\n\nI don\u2019t get the sense that their programming model is \u201cvery different\u201d to that of GPUs, more like they\u2019re building on top of that model, but maybe that\u2019s what you mean? And they clearly know about what makes GPU programming complicated and try to differentiate themselves from it \u2014 I\u2019m vary of their marketing lingo\u2026\n\nAs they mention PyTorch one way to leverage multiple independent units could be <https://pytorch.org/docs/stable/notes/ddp.html|https://pytorch.org/docs/stable/notes/ddp.html>.\n\nThis also points towards things like <https://mlir.llvm.org/|https://mlir.llvm.org/>. In other words, more power to the compiler (and yes, fancy type systems)! :) ",
        "user": "U5STGTB3J",
        "ts": "1624518279.165800",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "title": "MLIR",
                "title_link": "https://mlir.llvm.org/",
                "text": "Multi-Level IR Compiler Framework",
                "fallback": "MLIR",
                "from_url": "https://mlir.llvm.org/",
                "service_icon": "https://mlir.llvm.org/favicon.ico",
                "service_name": "mlir.llvm.org",
                "id": 1,
                "original_url": "https://mlir.llvm.org/"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "MYG3g",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UCGAK10LS"
                            },
                            {
                                "type": "text",
                                "text": " Oh, interesting! Do you have any other pointers to more technical resources from them or about other \u201cAI chips\u201d? Their FAQ isn\u2019t going very deep and the website strikes me as very marketing/VC oriented.\n\nI don\u2019t get the sense that their programming model is \u201cvery different\u201d to that of GPUs, more like they\u2019re building on top of that model, but maybe that\u2019s what you mean? And they clearly know about what makes GPU programming complicated and try to differentiate themselves from it \u2014 I\u2019m vary of their marketing lingo\u2026\n\nAs they mention PyTorch one way to leverage multiple independent units could be "
                            },
                            {
                                "type": "link",
                                "url": "https://pytorch.org/docs/stable/notes/ddp.html",
                                "text": "https://pytorch.org/docs/stable/notes/ddp.html"
                            },
                            {
                                "type": "text",
                                "text": ".\n\nThis also points towards things like "
                            },
                            {
                                "type": "link",
                                "url": "https://mlir.llvm.org/",
                                "text": "https://mlir.llvm.org/"
                            },
                            {
                                "type": "text",
                                "text": ". In other words, more power to the compiler (and yes, fancy type systems)! :) "
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "a4732edf-0d46-4ded-bc62-f0c4482c418d",
        "type": "message",
        "text": "Do you have an example application in mind? For instance if you want a generally responsive language, memory use efficiency, perhaps some convenience routines for objects going out of scope (e.g. automatic closing of file descriptors, sockets), predictable runtime and memory use, then reference counting seems like a better fit. OTOH:: scope exit becomes slower, and is potentially unbounded (imagine reclaiming a giant graph of data), overall runtime is higher because of all the accounting busywork and cpu cache disruption (can be as much as ~30% slower but it's complicated), and concurrency becomes harder: child processes will trigger copy on write (you can minimize the impact by storing the refcount in a small object header and storing all headers in a contiguous memory block), refcounts are also a contention issue for POSIX threads.",
        "user": "U025PBD75TM",
        "ts": "1624541626.166500",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "U025PBD75TM",
            "ts": "1624541793.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "A1n",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Do you have an example application in mind? For instance if you want a generally responsive language, memory use efficiency, perhaps some convenience routines for objects going out of scope (e.g. automatic closing of file descriptors, sockets), predictable runtime and memory use, then reference counting seems like a better fit. OTOH:: scope exit becomes slower, and is potentially unbounded (imagine reclaiming a giant graph of data), overall runtime is higher because of all the accounting busywork and cpu cache disruption (can be as much as ~30% slower but it's complicated), and concurrency becomes harder: child processes will trigger copy on write (you can minimize the impact by storing the refcount in a small object header and storing all headers in a contiguous memory block), refcounts are also a contention issue for POSIX threads."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "7c3a9a60-025a-4bd7-816e-bd7cd51017f5",
        "type": "message",
        "text": "You might want to read up on the various languages designed for the <https://en.wikipedia.org/wiki/Thinking_Machines_Corporation|Thinking Machines> CM series, including *Lisp and CM Lisp. I worked on one of these with 768 cores, but the top models had 65,000+ cores running in a parallel machine with perfectly pleasant high level language support.",
        "user": "U013ZLJARC7",
        "ts": "1624545723.167300",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "lNO2N",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "You might want to read up on the various languages designed for the "
                            },
                            {
                                "type": "link",
                                "url": "https://en.wikipedia.org/wiki/Thinking_Machines_Corporation",
                                "text": "Thinking Machines"
                            },
                            {
                                "type": "text",
                                "text": " CM series, including *Lisp and CM Lisp. I worked on one of these with 768 cores, but the top models had 65,000+ cores running in a parallel machine with perfectly pleasant high level language support."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS",
        "reactions": [
            {
                "name": "bulb",
                "users": [
                    "U025PBD75TM"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "53163e44-2380-4037-bd39-55e4cecb73cf",
        "type": "message",
        "text": "<@U5STGTB3J> There are some interviews and videos of Tenstorrent online. Here's a recent one <https://www.anandtech.com/show/16709/an-interview-with-tenstorrent-ceo-ljubisa-bajic-and-cto-jim-keller|with Anandtech>. Here's a long <https://www.youtube.com/watch?v=G4hL5Om4IJ4|podcast episode with the CTO> where he talks about a bunch of computing-related stuff, including hardware architectures for AI. Here's <https://www.youtube.com/watch?v=Uls3-UWm-sY|a short technical presentation> on how their chips work.",
        "user": "UCGAK10LS",
        "ts": "1624575554.167800",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "title": "An Interview with Tenstorrent: CEO Ljubisa Bajic and CTO Jim Keller",
                "title_link": "https://www.anandtech.com/show/16709/an-interview-with-tenstorrent-ceo-ljubisa-bajic-and-cto-jim-keller",
                "fallback": "An Interview with Tenstorrent: CEO Ljubisa Bajic and CTO Jim Keller",
                "image_url": "https://images.anandtech.com/doci/16709/a3_678x452.png",
                "from_url": "https://www.anandtech.com/show/16709/an-interview-with-tenstorrent-ceo-ljubisa-bajic-and-cto-jim-keller",
                "image_width": 569,
                "image_height": 250,
                "image_bytes": 176867,
                "service_icon": "https://www.anandtech.com/content/images/podcast_a_huge.png",
                "service_name": "AnandTech",
                "id": 1,
                "original_url": "https://www.anandtech.com/show/16709/an-interview-with-tenstorrent-ceo-ljubisa-bajic-and-cto-jim-keller"
            },
            {
                "service_name": "YouTube",
                "service_url": "https://www.youtube.com/",
                "title": "Jim Keller: The Future of Computing, AI, Life, and Consciousness | Lex Fridman Podcast #162",
                "title_link": "https://www.youtube.com/watch?v=G4hL5Om4IJ4",
                "author_name": "Lex Fridman",
                "author_link": "https://www.youtube.com/c/lexfridman",
                "thumb_url": "https://i.ytimg.com/vi/G4hL5Om4IJ4/hqdefault.jpg",
                "thumb_width": 480,
                "thumb_height": 360,
                "fallback": "YouTube Video: Jim Keller: The Future of Computing, AI, Life, and Consciousness | Lex Fridman Podcast #162",
                "video_html": "<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/G4hL5Om4IJ4?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>",
                "video_html_width": 400,
                "video_html_height": 225,
                "from_url": "https://www.youtube.com/watch?v=G4hL5Om4IJ4",
                "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png",
                "id": 2,
                "original_url": "https://www.youtube.com/watch?v=G4hL5Om4IJ4"
            },
            {
                "service_name": "YouTube",
                "service_url": "https://www.youtube.com/",
                "title": "Tenstorrent: Relegating the Important Stuff to the Compiler",
                "title_link": "https://www.youtube.com/watch?v=Uls3-UWm-sY",
                "author_name": "The Linley Group",
                "author_link": "https://www.youtube.com/c/LinleygroupVideos",
                "thumb_url": "https://i.ytimg.com/vi/Uls3-UWm-sY/hqdefault.jpg",
                "thumb_width": 480,
                "thumb_height": 360,
                "fallback": "YouTube Video: Tenstorrent: Relegating the Important Stuff to the Compiler",
                "video_html": "<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/Uls3-UWm-sY?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>",
                "video_html_width": 400,
                "video_html_height": 225,
                "from_url": "https://www.youtube.com/watch?v=Uls3-UWm-sY",
                "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png",
                "id": 3,
                "original_url": "https://www.youtube.com/watch?v=Uls3-UWm-sY"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "3TBl",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U5STGTB3J"
                            },
                            {
                                "type": "text",
                                "text": " There are some interviews and videos of Tenstorrent online. Here's a recent one "
                            },
                            {
                                "type": "link",
                                "url": "https://www.anandtech.com/show/16709/an-interview-with-tenstorrent-ceo-ljubisa-bajic-and-cto-jim-keller",
                                "text": "with Anandtech"
                            },
                            {
                                "type": "text",
                                "text": ". Here's a long "
                            },
                            {
                                "type": "link",
                                "url": "https://www.youtube.com/watch?v=G4hL5Om4IJ4",
                                "text": "podcast episode with the CTO"
                            },
                            {
                                "type": "text",
                                "text": " where he talks about a bunch of computing-related stuff, including hardware architectures for AI. Here's "
                            },
                            {
                                "type": "link",
                                "url": "https://www.youtube.com/watch?v=Uls3-UWm-sY",
                                "text": "a short technical presentation"
                            },
                            {
                                "type": "text",
                                "text": " on how their chips work."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U5STGTB3J"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "4dd70ed7-a2cf-4acc-8fe0-a65bf6275a64",
        "type": "message",
        "text": "<@U025PBD75TM> You're mentioning a lot of issues on conventional hardware architectures (cache and thread contention) and sure, there are some trade-offs when choosing between reference counting and tracing GCs in that context. But I'm focusing more on massively-parallel architectures, which I think changes the rules a bit. For example, Tenstorrent's chips have no shared memory, no caches, and no threads. Instead they have a grid of compute units, each with a dedicated SRAM (not a cache) and capable of doing parallel matrix/tensor operations. This is my \"application\" if you like: writing programs that can run on this type of machine. Why? Because they're going to offer up 100x the compute power of CPUs and are more suited to heterogeneous workloads than GPUs. From what I can see, they have a chance at obsoleting the whole idea of a CPU, as long as we can program them. There is insane amounts of money pouring into these companies (for their applications to AI), and some of these chips are going to become widely-deployed in data centers and (eventually) consumer devices.",
        "user": "UCGAK10LS",
        "ts": "1624576469.168200",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "2lZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U025PBD75TM"
                            },
                            {
                                "type": "text",
                                "text": " You're mentioning a lot of issues on conventional hardware architectures (cache and thread contention) and sure, there are some trade-offs when choosing between reference counting and tracing GCs in that context. But I'm focusing more on massively-parallel architectures, which I think changes the rules a bit. For example, Tenstorrent's chips have no shared memory, no caches, and no threads. Instead they have a grid of compute units, each with a dedicated SRAM (not a cache) and capable of doing parallel matrix/tensor operations. This is my \"application\" if you like: writing programs that can run on this type of machine. Why? Because they're going to offer up 100x the compute power of CPUs and are more suited to heterogeneous workloads than GPUs. From what I can see, they have a chance at obsoleting the whole idea of a CPU, as long as we can program them. There is insane amounts of money pouring into these companies (for their applications to AI), and some of these chips are going to become widely-deployed in data centers and (eventually) consumer devices."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U025PBD75TM",
                    "U019CPED6T1"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "de445f3f-273f-487e-8125-148077ec0905",
        "type": "message",
        "text": "<@U013ZLJARC7> I'll look them up, thank you :slightly_smiling_face:",
        "user": "UCGAK10LS",
        "ts": "1624576618.168400",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "bqm",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U013ZLJARC7"
                            },
                            {
                                "type": "text",
                                "text": " I'll look them up, thank you "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U013ZLJARC7"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "aac7b7af-1c2f-4ad2-8436-2fc2f7465462",
        "type": "message",
        "text": "<@UCGAK10LS> fyi the successor to Pony is a microsoft research project called \"Project Verona\". I think it's one of the most interesting research projects in the more traditional PL world right now. It might not be what you're looking for but I think the heap model it uses is a lot more generalised and flexible than the actor model.",
        "user": "U01T2EYBH0T",
        "ts": "1624746824.171400",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "fNspY",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UCGAK10LS"
                            },
                            {
                                "type": "text",
                                "text": " fyi the successor to Pony is a microsoft research project called \"Project Verona\". I think it's one of the most interesting research projects in the more traditional PL world right now. It might not be what you're looking for but I think the heap model it uses is a lot more generalised and flexible than the actor model."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "44af4c1a-c47d-4dc6-8490-4b81a7652774",
        "type": "message",
        "text": "<https://www.microsoft.com/en-us/research/project/project-verona/|https://www.microsoft.com/en-us/research/project/project-verona/>\n\nthere's not much information up yet, but i think there are some talks explaining the memory model a bit, if you're interested.",
        "user": "U01T2EYBH0T",
        "ts": "1624747117.171600",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "service_name": "Microsoft Research",
                "title": "Project Verona - Microsoft Research",
                "title_link": "https://www.microsoft.com/en-us/research/project/project-verona/",
                "text": "Project Verona: a programming language for the modern cloud Adoption of the cloud requires trust, but software vulnerabilities can quickly erode that trust. There is a real drive in the industry to make memory safety vulnerabilities a thing of the past. Project Verona is a highly ambitious research project to make that a reality for [\u2026]",
                "fallback": "Microsoft Research: Project Verona - Microsoft Research",
                "thumb_url": "https://www.microsoft.com/en-us/research/uploads/prod/2020/05/Verona.jpg",
                "from_url": "https://www.microsoft.com/en-us/research/project/project-verona/",
                "thumb_width": 1920,
                "thumb_height": 720,
                "service_icon": "https://www.microsoft.com/favicon.ico",
                "id": 1,
                "original_url": "https://www.microsoft.com/en-us/research/project/project-verona/"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ZrFL8",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "link",
                                "url": "https://www.microsoft.com/en-us/research/project/project-verona/",
                                "text": "https://www.microsoft.com/en-us/research/project/project-verona/"
                            },
                            {
                                "type": "text",
                                "text": "\n\nthere's not much information up yet, but i think there are some talks explaining the memory model a bit, if you're interested."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS"
    },
    {
        "client_msg_id": "c2e8b2ad-96ee-45c3-98d8-36e5a1522a5e",
        "type": "message",
        "text": "in reference to your original question, I would say that both Pony and Verona have type systems that are comparable to Rust's in fanciness (they also rely on concepts like linearity), but they aim to find a sweet spot in usability by permitting a more free-form programming style within regions.",
        "user": "U01T2EYBH0T",
        "ts": "1624747824.171900",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "hz=VR",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "in reference to your original question, I would say that both Pony and Verona have type systems that are comparable to Rust's in fanciness (they also rely on concepts like linearity), but they aim to find a sweet spot in usability by permitting a more free-form programming style within regions."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1624437161.147900",
        "parent_user_id": "UCGAK10LS"
    }
]