[
    {
        "client_msg_id": "867fda48-e89d-4772-b831-1908042be8dd",
        "type": "message",
        "text": "I might throw relational logic down towards the bottom?",
        "user": "UD3AK9JRF",
        "ts": "1586570996.221100",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "XqmO",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I might throw relational logic down towards the bottom?"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586462800.208000",
        "parent_user_id": "UC2A2ARPT"
    },
    {
        "client_msg_id": "bd801d6b-4bbc-4d51-b16c-87fcf9fccb17",
        "type": "message",
        "text": "Nobody's found anything in the currently accepted laws of physics which would allow you to build a computing device more powerful than a Turing machine. I would further argue that the laws of physics, or at least the physical limitations imposed on human buildable technology, don't allow you to build a computer that is even as powerful as a Turing machine, since that requires unlimited memory. Physically buildable computers are only as powerful as finite state automata, due to the finite memory restriction. A Turing machine cannot solve the halting problem, in general, for another Turing machine. But, a Turing machine *can* solve the halting problem for a finite state automaton (ie, for a physically buildable computer).",
        "user": "UJN1TAYEQ",
        "ts": "1586571391.221300",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "F8Zu",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Nobody's found anything in the currently accepted laws of physics which would allow you to build a computing device more powerful than a Turing machine. I would further argue that the laws of physics, or at least the physical limitations imposed on human buildable technology, don't allow you to build a computer that is even as powerful as a Turing machine, since that requires unlimited memory. Physically buildable computers are only as powerful as finite state automata, due to the finite memory restriction. A Turing machine cannot solve the halting problem, in general, for another Turing machine. But, a Turing machine "
                            },
                            {
                                "type": "text",
                                "text": "can",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " solve the halting problem for a finite state automaton (ie, for a physically buildable computer)."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586462800.208000",
        "parent_user_id": "UC2A2ARPT"
    },
    {
        "client_msg_id": "9e9eba29-8746-477a-89b1-1058a656277a",
        "type": "message",
        "text": "The study of models of computation more powerful than the Turing machine is called Hypercomputation. <https://en.wikipedia.org/wiki/Hypercomputation>",
        "user": "UJN1TAYEQ",
        "ts": "1586572568.221500",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "title": "Hypercomputation",
                "title_link": "https://en.wikipedia.org/wiki/Hypercomputation",
                "from_url": "https://en.wikipedia.org/wiki/Hypercomputation",
                "author_name": "Wikipedia",
                "author_link": "https://en.wikipedia.org/",
                "text": "Hypercomputation or super-Turing computation refers to models of computation that can provide outputs that are not Turing-computable. For example, a machine that could solve the halting problem would be a hypercomputer; so too would one that can correctly evaluate every statement in Peano arithmetic.\nThe Church\u2013Turing thesis states that any \"computable\" function that can be computed by a mathematician with a pen and paper using a finite set of simple algorithms, can be computed by a Turing machine. Hypercomputers compute functions that a Turing machine cannot and which are, hence, not computable in the Church\u2013Turing sense.\nTechnically, the output of a random Turing machine is uncomputable; however, most hypercomputing literature focuses instead on the computation of useful, rather than random, uncomputable functions.",
                "fallback": "wikipedia: Hypercomputation",
                "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/wikipedia.png",
                "id": 1,
                "original_url": "https://en.wikipedia.org/wiki/Hypercomputation"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "nha",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The study of models of computation more powerful than the Turing machine is called Hypercomputation. "
                            },
                            {
                                "type": "link",
                                "url": "https://en.wikipedia.org/wiki/Hypercomputation"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586462800.208000",
        "parent_user_id": "UC2A2ARPT",
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "UDKTZSD6H"
                ],
                "count": 1
            },
            {
                "name": "eyes",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "358425a7-3da9-421f-8d1a-f0214ef5a069",
        "type": "message",
        "text": "There are various proposals for hypothetical \"physical constructions\" that are claimed to be compatible with the laws of physics, but which aren't physically realizable. One example is the Alcubierre warp drive, which would supposedly allow the construction of faster-than-light space craft. Another is the Malament\u2013Hogarth spacetime, which would supposedly allow hypercomputation. <https://en.wikipedia.org/wiki/Malament%E2%80%93Hogarth_spacetime>",
        "user": "UJN1TAYEQ",
        "ts": "1586573390.221800",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "title": "Malament\u2013Hogarth spacetime",
                "title_link": "https://en.wikipedia.org/wiki/Malament%E2%80%93Hogarth_spacetime",
                "from_url": "https://en.wikipedia.org/wiki/Malament%E2%80%93Hogarth_spacetime",
                "author_name": "Wikipedia",
                "author_link": "https://en.wikipedia.org/",
                "text": "A Malament\u2013Hogarth (M-H) spacetime, named after David B. Malament and Mark Hogarth, is a relativistic spacetime that possesses the following property: there exists a worldline \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   and an event p such that all events along \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   are a finite interval in the past of p, but the proper time along \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   is infinite. The event p is known as an M-H event. The significance of M-H spacetimes is that they allow for the implementation of certain non-Turing computable tasks (hypercomputation). The idea is for an observer at some event in p's past to set a computer (Turing machine) to work on some task and then have the Turing machine travel on \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n  , computing for all eternity. Since \n  \n    \n      \n        \u03bb\n      \n    \n    {\\displaystyle \\lambda }\n   lies in p's past, the Turing machine can signal (a solution) to p at any stage of this never-ending task. Meanwhile, the observer takes a quick trip (finite proper time) through spacetime to p, to pick up the solution. The set-up can be used to decide the halting problem, which is known to be undecidable by an ordinary Turing machine. All the observer needs to do is to prime the Turing machine to signal to p if and only if the Turing machine halts.\nThe Kerr metric, which describes empty spacetime around a rotating black hole, possesses these features: a computer can orbit the black hole indefinitely, while an observer falling into the black hole experiences an M-H event as they cross the inner event horizon. (This, however, neglects the effects of black hole evaporation.)",
                "fallback": "wikipedia: Malament\u2013Hogarth spacetime",
                "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/wikipedia.png",
                "id": 1,
                "original_url": "https://en.wikipedia.org/wiki/Malament%E2%80%93Hogarth_spacetime"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "CcB",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "There are various proposals for hypothetical \"physical constructions\" that are claimed to be compatible with the laws of physics, but which aren't physically realizable. One example is the Alcubierre warp drive, which would supposedly allow the construction of faster-than-light space craft. Another is the Malament\u2013Hogarth spacetime, which would supposedly allow hypercomputation. "
                            },
                            {
                                "type": "link",
                                "url": "https://en.wikipedia.org/wiki/Malament%E2%80%93Hogarth_spacetime"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586462800.208000",
        "parent_user_id": "UC2A2ARPT",
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "UDKTZSD6H"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "825761e5-4962-4452-8c10-758752d4dc93",
        "type": "message",
        "text": "Think we are getting into the highly controversial science territory. I am out of depth again, but I think Martin Davis have been beating the drum that Hypercomputation is a myth: 1/ <https://www.researchgate.net/publication/243784599_The_Myth_of_Hypercomputation>\n2/ <http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.83.9917&amp;rep=rep1&amp;type=pdf>\n\nwhich means I think as my reading suggest he thinks Turing has bounded the problem of computation forever. But I like to err on the other side that there are other kinds of intriguing stuff going on than just state change / bit flipping. I think Rosen/Process Theory people et al. have a very different perspective on this coming from a very different philosophical slant which reminds me, I need to read that Life Itself book soon.",
        "user": "UDKTZSD6H",
        "ts": "1586573564.222100",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "AGqui",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Think we are getting into the highly controversial science territory. I am out of depth again, but I think Martin Davis have been beating the drum that Hypercomputation is a myth: 1/ "
                            },
                            {
                                "type": "link",
                                "url": "https://www.researchgate.net/publication/243784599_The_Myth_of_Hypercomputation"
                            },
                            {
                                "type": "text",
                                "text": "\n2/ "
                            },
                            {
                                "type": "link",
                                "url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.83.9917&rep=rep1&type=pdf"
                            },
                            {
                                "type": "text",
                                "text": "\n\nwhich means I think as my reading suggest he thinks Turing has bounded the problem of computation forever. But I like to err on the other side that there are other kinds of intriguing stuff going on than just state change / bit flipping. I think Rosen/Process Theory people et al. have a very different perspective on this coming from a very different philosophical slant which reminds me, I need to read that Life Itself book soon."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586462800.208000",
        "parent_user_id": "UC2A2ARPT"
    },
    {
        "client_msg_id": "d0e45fb6-b576-4e30-880f-a8b709bb03c1",
        "type": "message",
        "text": "Has anyone thought about the practicality of a (general-purpose) language without floating-point numbers? I've always been skeptical of floats, but in the language I'm designing in particular, computations don't have a total ordering, and so the most natural way to sum/multiply numbers is a SUM() or PRODUCT() function that accepts an unordered set (rather than looping through an ordered list). You can't use these functions for floats, because neither summation nor multiplication of floats is associative. I want my language to use BigInts (arbitrary precision) anyway, so I think I should just go ahead and have *rational numbers* (fractions) as the built-in type for fractional numbers. This would present some new design challenges, such as defining some ergonomic \"round-off\" functions that can be used alongside multiplication (and sin/cos/sqrt etc) to prevent unbounded growth of numerator and denominator sizes.",
        "user": "UCGAK10LS",
        "ts": "1586587006.229500",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UCGAK10LS",
            "ts": "1586588806.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "XmBi",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Has anyone thought about the practicality of a (general-purpose) language without floating-point numbers? I've always been skeptical of floats, but in the language I'm designing in particular, computations don't have a total ordering, and so the most natural way to sum/multiply numbers is a SUM() or PRODUCT() function that accepts an unordered set (rather than looping through an ordered list). You can't use these functions for floats, because neither summation nor multiplication of floats is associative. I want my language to use BigInts (arbitrary precision) anyway, so I think I should just go ahead and have "
                            },
                            {
                                "type": "text",
                                "text": "rational numbers",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " (fractions) as the built-in type for fractional numbers. This would present some new design challenges, such as defining some ergonomic \"round-off\" functions that can be used alongside multiplication (and sin/cos/sqrt etc) to prevent unbounded growth of numerator and denominator sizes."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "client_msg_id": "dbe6f3dc-1806-4718-9be6-365b10781567",
        "type": "message",
        "text": "Surely someone has made a language with this design choice before (rationals and *no* *floats*)? I don't know of any examples.\n(Floats could be hidden in an \"advanced menu\" for backwards-compatibility and special needs only)\n\nEdit: I guess Scheme and Racket have \"exact numbers\" (rationals), though they have floats as well, and transcendental functions like sin() and cos() will return floats instead of approximated rationals, so you can't really escape using floats.",
        "user": "UCGAK10LS",
        "ts": "1586587116.230700",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UCGAK10LS",
            "ts": "1586588711.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "WWe8t",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Surely someone has made a language with this design choice before (rationals and "
                            },
                            {
                                "type": "text",
                                "text": "no",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " "
                            },
                            {
                                "type": "text",
                                "text": "floats",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ")? I don't know of any examples.\n(Floats could be hidden in an \"advanced menu\" for backwards-compatibility and special needs only)\n\nEdit: I guess Scheme and Racket have \"exact numbers\" (rationals), though they have floats as well, and transcendental functions like sin() and cos() will return floats instead of approximated rationals, so you can't really escape using floats."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "client_msg_id": "9EB39C24-F838-44CE-8717-BD6AF5F103B7",
        "type": "message",
        "text": "Floats are a subset of rationals (except for Inf and Nan) that can be represented in constant memory space and processed in constant time. If you go for rationals only, you will have to deal with resource issues. Rationals as a default with floats as an opt-in optimization technique looks like an interesting design choice that I haven\u2019t seen so far (but which I am considering myself for Leibniz).",
        "user": "UJBAJNFLK",
        "ts": "1586592131.237600",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "zzwG",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Floats are a subset of rationals (except for Inf and Nan) that can be represented in constant memory space and processed in constant time. If you go for rationals only, you will have to deal with resource issues. Rationals as a default with floats as an opt-in optimization technique looks like an interesting design choice that I haven\u2019t seen so far (but which I am considering myself for Leibniz)."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "client_msg_id": "9e959cee-9fe0-441d-8702-3805abaa61e9",
        "type": "message",
        "text": "Floats might be rational, but float + and float * are not rational + and rational *. That's the main problem.",
        "user": "UCGAK10LS",
        "ts": "1586592205.238700",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "sk2y",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Floats might be rational, but float + and float * are not rational + and rational *. That's the main problem."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "client_msg_id": "7E75E69C-EC19-4A22-9582-0353F543AA5D",
        "type": "message",
        "text": "Right. Float arithmetic has built-in rounding after each step and that\u2019s what makes it non-associative.",
        "user": "UJBAJNFLK",
        "ts": "1586592272.241200",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "tAPf",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Right. Float arithmetic has built-in rounding after each step and that\u2019s what makes it non-associative."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "client_msg_id": "7372604d-3c5d-4926-93d9-fb401a07f9fa",
        "type": "message",
        "text": "Yeah that :slightly_smiling_face: And yeah, rationals will take more resources to process, but my language isn't focused on C-like performance, so as long as I can prevent unbounded numerator/denominator growth through rules about where the programmer must accept a round-off step, then I think it would work quite nicely.",
        "user": "UCGAK10LS",
        "ts": "1586592333.242200",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UCGAK10LS",
            "ts": "1586592668.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Tt4",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah that "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face"
                            },
                            {
                                "type": "text",
                                "text": " And yeah, rationals will take more resources to process, but my language isn't focused on C-like performance, so as long as I can prevent unbounded numerator/denominator growth through rules about where the programmer must accept a round-off step, then I think it would work quite nicely."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "client_msg_id": "35976757-f9cd-439f-9a2f-430bbc092370",
        "type": "message",
        "text": "Also you can \"optimize away\" the denominators of rationals if they're statically known, effectively giving you fixed-point arithmetic, which will be a bit faster.",
        "user": "UCGAK10LS",
        "ts": "1586592403.243000",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "IsNOq",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Also you can \"optimize away\" the denominators of rationals if they're statically known, effectively giving you fixed-point arithmetic, which will be a bit faster."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "client_msg_id": "e6f6d093-ab31-42d0-9e81-a56c25bba5f1",
        "type": "message",
        "text": "And if the maximum size of the numerator is known as well, then you can optimize all the way to 32/64 bit Ints.",
        "user": "UCGAK10LS",
        "ts": "1586592510.244800",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "N+7qY",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "And if the maximum size of the numerator is known as well, then you can optimize all the way to 32/64 bit Ints."
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "client_msg_id": "da5ed75f-5c62-4073-aee7-0d95e95eb6df",
        "type": "message",
        "text": "Fixed-point is often a good alternative, but rarely well supported in languages. But there are important cases where it fails, and it's those you need to look at. Example: Generate random points in a sphere or a square, and sum 1/d^2 over all pairs of points, where d is the distance between the points in a pair. That's a cartoon version of computing gravitational or electrostatic interactions in physics. 1/d^2 is very large for short distances but very small for long ones, which however make up the majority of pairs. Doing this with rationals is prohibitively expensive.",
        "user": "UJBAJNFLK",
        "ts": "1586593050.248600",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "+oFW",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Fixed-point is often a good alternative, but rarely well supported in languages. But there are important cases where it fails, and it's those you need to look at. Example: Generate random points in a sphere or a square, and sum 1/d^2 over all pairs of points, where d is the distance between the points in a pair. That's a cartoon version of computing gravitational or electrostatic interactions in physics. 1/d^2 is very large for short distances but very small for long ones, which however make up the majority of pairs. Doing this with rationals is prohibitively expensive."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586593050.248600",
        "reply_count": 18,
        "reply_users_count": 7,
        "latest_reply": "1586675903.336800",
        "reply_users": [
            "UCGAK10LS",
            "UDQBTJ211",
            "UT60XSVCN",
            "UNCP67JSK",
            "UJBAJNFLK",
            "UEQ6M68H0",
            "UCUSW7WVD"
        ],
        "subscribed": false,
        "reactions": [
            {
                "name": "bulb",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "d953b8d2-1a55-4902-af4b-d15060cd45bb",
        "type": "message",
        "text": "This is one of those cases where my language should force a round-off to occur, but I would still want to preserve the associativity of addition. I *think* that's still possible: instead of computing the product (or least common multiple) of all denominators here (yielding an exact result), I would pick a \"sufficiently large denominator\" (2^63 would suffice), and normalize each fraction to have that denominator (rounding the numerator to the nearest integer). Would that suffice for a precise and performant fixed-point solution?",
        "user": "UCGAK10LS",
        "ts": "1586593708.248700",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "jk=Wd",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "This is one of those cases where my language should force a round-off to occur, but I would still want to preserve the associativity of addition. I "
                            },
                            {
                                "type": "text",
                                "text": "think",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " that's still possible: instead of computing the product (or least common multiple) of all denominators here (yielding an exact result), I would pick a \"sufficiently large denominator\" (2^63 would suffice), and normalize each fraction to have that denominator (rounding the numerator to the nearest integer). Would that suffice for a precise and performant fixed-point solution?"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586593050.248600",
        "parent_user_id": "UJBAJNFLK"
    },
    {
        "client_msg_id": "6bf2d631-fe7b-4fe4-bdf7-a9ca09e4a550",
        "type": "message",
        "text": "Such cases (iterative/recursive summation of fractions with different denominators) would just need to be statically detected and have such an algorithm applied. The user can pick the denominator or it can be auto-suggested.",
        "user": "UCGAK10LS",
        "ts": "1586593777.248900",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UCGAK10LS",
            "ts": "1586593802.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "B4s",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Such cases (iterative/recursive summation of fractions with different denominators) would just need to be statically detected and have such an algorithm applied. The user can pick the denominator or it can be auto-suggested."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586593050.248600",
        "parent_user_id": "UJBAJNFLK"
    },
    {
        "client_msg_id": "b66bca40-ea45-4d40-a4fe-967b23fd10ca",
        "type": "message",
        "text": "Yes I think that would work. The key design distinction is at what point you do the rounding step, as this is what breaks associativity. If you round all numbers to something computationally tractable before your SUM() then this will work I think.\n\nAnother method would be to say that all arithmetic operations are performed in a particular order. e.g. sort the set before SUM(), sort a, b before a + b. I would go with this probably because I reckon it would simplify implementation a lot.",
        "user": "UDQBTJ211",
        "ts": "1586594970.249200",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UDQBTJ211",
            "ts": "1586594999.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "/nBaM",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yes I think that would work. The key design distinction is at what point you do the rounding step, as this is what breaks associativity. If you round all numbers to something computationally tractable before your SUM() then this will work I think.\n\nAnother method would be to say that all arithmetic operations are performed in a particular order. e.g. sort the set before SUM(), sort a, b before a + b. I would go with this probably because I reckon it would simplify implementation a lot."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586593050.248600",
        "parent_user_id": "UJBAJNFLK"
    },
    {
        "client_msg_id": "ca7e178b-f18b-413d-92d4-9e309eab6b45",
        "type": "message",
        "text": "Yeah I've thought about the sorting approach before too! But I've decided I don't want to go down that route, because it affects the time complexity of basic operations (which can cause unacceptable slowdown, as an aside), and I'd have to explain how all that works to the user. I want them to know what the time complexity of their code is, and the rounding behaviour of the operations performed, and I want the explanation to be intuitive.\n\nIf we're just normalizing the denominators, it's all intuitive: you can only sum a set of numbers if the numbers have the same denominator. If the denominators aren't the same you have to pick a denominator to normalize them to.",
        "user": "UCGAK10LS",
        "ts": "1586595364.249500",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UCGAK10LS",
            "ts": "1586613376.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "a5R",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah I've thought about the sorting approach before too! But I've decided I don't want to go down that route, because it affects the time complexity of basic operations (which can cause unacceptable slowdown, as an aside), and I'd have to explain how all that works to the user. I want them to know what the time complexity of their code is, and the rounding behaviour of the operations performed, and I want the explanation to be intuitive.\n\nIf we're just normalizing the denominators, it's all intuitive: you can only sum a set of numbers if the numbers have the same denominator. If the denominators aren't the same you have to pick a denominator to normalize them to."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586593050.248600",
        "parent_user_id": "UJBAJNFLK"
    },
    {
        "client_msg_id": "b4c4d774-90c2-45fd-9431-8afbabfe7de3",
        "type": "message",
        "text": "Thinking further: The technique I mentioned maintains the associativity of an approximated SUM(), but I'm not sure if there's any smart way to maintain the associativity of an approximated PRODUCT().",
        "user": "UCGAK10LS",
        "ts": "1586597375.250800",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "xGOA",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thinking further: The technique I mentioned maintains the associativity of an approximated SUM(), but I'm not sure if there's any smart way to maintain the associativity of an approximated PRODUCT()."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586593050.248600",
        "parent_user_id": "UJBAJNFLK"
    },
    {
        "client_msg_id": "06600a61-c735-451b-8cec-ec819ede6dfc",
        "type": "message",
        "text": "Has anyone here experimented with interval arithmetic and built in error analysis in a language? It's something I've wanted to do for a while but haven't got around to yet",
        "user": "UT60XSVCN",
        "ts": "1586602967.277100",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "aFu0",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Has anyone here experimented with interval arithmetic and built in error analysis in a language? It's something I've wanted to do for a while but haven't got around to yet"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586593050.248600",
        "parent_user_id": "UJBAJNFLK"
    },
    {
        "client_msg_id": "f1c9f3e5-774d-4a16-b9ac-56528a8e0a44",
        "type": "message",
        "text": "I've looked into interval arithmetic before but concluded that it's pretty useless since the error bounds grow quickly with each operation, for most operations. Also, most apps don't care about error bounds, they just want a single number. It would take a new spin on the topic to change my mind.",
        "user": "UCGAK10LS",
        "ts": "1586603193.277300",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "YHX",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I've looked into interval arithmetic before but concluded that it's pretty useless since the error bounds grow quickly with each operation, for most operations. Also, most apps don't care about error bounds, they just want a single number. It would take a new spin on the topic to change my mind."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586593050.248600",
        "parent_user_id": "UJBAJNFLK"
    },
    {
        "client_msg_id": "1f610684-2563-4882-9007-8e78fe88a5fa",
        "type": "message",
        "text": "Many languages have implementations of this <http://speleotrove.com/decimal/decarith.html> for example python <https://docs.python.org/3.8/library/decimal.html>",
        "user": "UBN9AFS0N",
        "ts": "1586606048.277800",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "mxU",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Many languages have implementations of this "
                            },
                            {
                                "type": "link",
                                "url": "http://speleotrove.com/decimal/decarith.html"
                            },
                            {
                                "type": "text",
                                "text": " for example python "
                            },
                            {
                                "type": "link",
                                "url": "https://docs.python.org/3.8/library/decimal.html"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586606048.277800",
        "reply_count": 7,
        "reply_users_count": 4,
        "latest_reply": "1586682680.337400",
        "reply_users": [
            "UCGAK10LS",
            "UBN9AFS0N",
            "U8A5MS6R1",
            "UJBAJNFLK"
        ],
        "subscribed": true,
        "last_read": "1586682680.337400"
    },
    {
        "client_msg_id": "00d023f1-2e28-4518-b71e-129f248bf008",
        "type": "message",
        "text": "Libraries are good, but don't give you a \"language without floats\". When you have the float escape hatch, you don't have to design your fixed/rational numbers to work well for computations such as the one Konrad mentioned.",
        "user": "UCGAK10LS",
        "ts": "1586606366.277900",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "gg3j",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Libraries are good, but don't give you a \"language without floats\". When you have the float escape hatch, you don't have to design your fixed/rational numbers to work well for computations such as the one Konrad mentioned."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586606048.277800",
        "parent_user_id": "UBN9AFS0N"
    },
    {
        "client_msg_id": "0cfe82e6-2926-465c-bf9f-844c2588e24e",
        "type": "message",
        "text": "Hmm, yeah I can see where you are coming from, it's not something I've investigated in depth",
        "user": "UT60XSVCN",
        "ts": "1586606864.278100",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "1Put",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Hmm, yeah I can see where you are coming from, it's not something I've investigated in depth"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586593050.248600",
        "parent_user_id": "UJBAJNFLK"
    },
    {
        "client_msg_id": "19fa8e79-96ab-48fb-bf39-50f5819588a9",
        "type": "message",
        "text": "I mentioned as a design and interface to implement the core decimal type in your language, not that you should implement it as a library",
        "user": "UBN9AFS0N",
        "ts": "1586606879.278300",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "/YbX",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I mentioned as a design and interface to implement the core decimal type in your language, not that you should implement it as a library"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586606048.277800",
        "parent_user_id": "UBN9AFS0N",
        "reactions": [
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UCKRZS3DZ"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "93cdffdd-1151-4f8a-8890-7052c00c2ec9",
        "type": "message",
        "text": "the idea would be that the decimal type in python (and in that spec) is your core decimal type",
        "user": "UBN9AFS0N",
        "ts": "1586606906.278500",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "jGk0",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "the idea would be that the decimal type in python (and in that spec) is your core decimal type"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586606048.277800",
        "parent_user_id": "UBN9AFS0N"
    },
    {
        "client_msg_id": "bf64f043-abce-414c-90e6-93d7196d374c",
        "type": "message",
        "text": "Sure, that would be useful. I wouldn't put a Decimal type in my language though, because a Decimal is just a Rational (fraction) where the denominator can only be a power of 10. Rationals subsume Decimals.",
        "user": "UCGAK10LS",
        "ts": "1586608320.278700",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UCGAK10LS",
            "ts": "1586608386.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "WSU+",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Sure, that would be useful. I wouldn't put a Decimal type in my language though, because a Decimal is just a Rational (fraction) where the denominator can only be a power of 10. Rationals subsume Decimals."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586606048.277800",
        "parent_user_id": "UBN9AFS0N"
    },
    {
        "client_msg_id": "18720bf0-ff5b-48de-afcd-8384b18de86a",
        "type": "message",
        "text": "To do physical hypercomputation, you need to represent an infinite amount of information in a finite volume, and process the information in parallel. This is prohibited by quantum mechanics, but it isn't prohibited by the general theory of relativity, which is what the Malament\u2013Hogarth spacetime solution relies on. Relativity by itself is not a complete description of reality, so you shouldn't take M-H seriously.",
        "user": "UJN1TAYEQ",
        "ts": "1586610324.279100",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "vr3iE",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "To do physical hypercomputation, you need to represent an infinite amount of information in a finite volume, and process the information in parallel. This is prohibited by quantum mechanics, but it isn't prohibited by the general theory of relativity, which is what the Malament\u2013Hogarth spacetime solution relies on. Relativity by itself is not a complete description of reality, so you shouldn't take M-H seriously."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586462800.208000",
        "parent_user_id": "UC2A2ARPT"
    },
    {
        "client_msg_id": "52130016-6cc3-4b47-9654-75f1a658e803",
        "type": "message",
        "text": "Some philosophers have a different perspective. They think about the problem like this: Physical law prevents any physical assembly of atoms from performing any computation more powerful than a Turing machine. Computers are Turing machines. This leads to the unacceptable doctrine of \"physicalism\", where the human brain has no more powers than a computer. Obviously we are more than just computers! What about Qualia and The Hard Problem of Consciousness? (eg, Chalmers) Obviously computers cannot possess Qualia and cannot possess Consciousness by their very nature. Therefore there is something wrong with Physicalism. Roger Penrose took a different path leading to the same result in The Emperor's New Mind. G\u00f6del's Incompleteness Theorum put hard limits on the powers of formal systems to deduce the truth of mathematical statements. Human mathematicians transcend these limits, therefore human brains are more powerful than formal systems. Just because physicalism is abhorent, upsetting, unacceptable, doesn't mean it is untrue. The metaphorical idea that physicalism equates the human brain with an IBM PC is also quite misleading, since brains have an entirely different organization and quite different computational powers *in practice*. The visceral emotional response that some people have to physicalism results, I think, from fallacious thinking. The formal mathematical equivalence of the computational power of two physical objects means a whole lot less in the real world than people think it does. As I mentioned before, we can't build a physical Turing machine, but we still get a lot done with our brains and computers.",
        "user": "UJN1TAYEQ",
        "ts": "1586611415.279300",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UJN1TAYEQ",
            "ts": "1586612120.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "nfWI",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Some philosophers have a different perspective. They think about the problem like this: Physical law prevents any physical assembly of atoms from performing any computation more powerful than a Turing machine. Computers are Turing machines. This leads to the unacceptable doctrine of \"physicalism\", where the human brain has no more powers than a computer. Obviously we are more than just computers! What about Qualia and The Hard Problem of Consciousness? (eg, Chalmers) Obviously computers cannot possess Qualia and cannot possess Consciousness by their very nature. Therefore there is something wrong with Physicalism. Roger Penrose took a different path leading to the same result in The Emperor's New Mind. G\u00f6del's Incompleteness Theorum put hard limits on the powers of formal systems to deduce the truth of mathematical statements. Human mathematicians transcend these limits, therefore human brains are more powerful than formal systems. Just because physicalism is abhorent, upsetting, unacceptable, doesn't mean it is untrue. The metaphorical idea that physicalism equates the human brain with an IBM PC is also quite misleading, since brains have an entirely different organization and quite different computational powers "
                            },
                            {
                                "type": "text",
                                "text": "in practice",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". The visceral emotional response that some people have to physicalism results, I think, from fallacious thinking. The formal mathematical equivalence of the computational power of two physical objects means a whole lot less in the real world than people think it does. As I mentioned before, we can't build a physical Turing machine, but we still get a lot done with our brains and computers."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586462800.208000",
        "parent_user_id": "UC2A2ARPT",
        "reactions": [
            {
                "name": "thinking_face",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            },
            {
                "name": "+1",
                "users": [
                    "UDKTZSD6H"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "2D695EE2-E801-4117-A138-41F47321EBCE",
        "type": "message",
        "text": "I'm planning to have precision/error info as a core part of the type info, would be happy to hear any reason to why that could be not amazing!\n\nUsually: input with precision(s) -&gt; calculation -&gt; output with different precision(s)\n\nThe input is provided, the calculation/logic is defined, then an output is requested at a certain min precision, at which point the computation is optimized to reach it. Thus, the logic may be precision-agnostic/generic.\n\nHaving the precision info+requirements would not only allow for many optimizations, but also allow for more robust software and inspection (eg. everything from game collision errors bc of edge case velocity/frame rate combination, to fatal money software compounding issues).",
        "user": "UNCP67JSK",
        "ts": "1586618697.288700",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "H30",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'm planning to have precision/error info as a core part of the type info, would be happy to hear any reason to why that could be not amazing!\n\n"
                            },
                            {
                                "type": "text",
                                "text": "Usually: input with precision(s) -> calculation -> output with different precision(s)\n"
                            },
                            {
                                "type": "text",
                                "text": "\n"
                            },
                            {
                                "type": "text",
                                "text": "The input is provided, the calculation/logic is defined, then an output is requested at a certain min precision, at which point the computation is optimized to reach it. Thus, the logic may be precision-agnostic/generic.\n"
                            },
                            {
                                "type": "text",
                                "text": "\nHaving the precision info+requirements would not only allow for many optimizations, but also allow for more robust software and inspection (eg. everything from game collision errors bc of edge case velocity/frame rate combination, to fatal money software compounding issues)."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586593050.248600",
        "parent_user_id": "UJBAJNFLK",
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "604517BC-900C-4D07-A864-A85D3FAF3FF7",
        "type": "message",
        "text": "<@UCGAK10LS> What you propose is basically compulsory conversion to fixed point before summing more than two numbers. That would make algorithms like my example a bit more cumbersome to write, but since it also forces what would be a good habit anyway (arranging the sum by orders of magnitude), it looks acceptable.",
        "user": "UJBAJNFLK",
        "ts": "1586619537.292300",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Bjm1c",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UCGAK10LS"
                            },
                            {
                                "type": "text",
                                "text": " What you propose is basically compulsory conversion to fixed point before summing more than two numbers. That would make algorithms like my example a bit more cumbersome to write, but since it also forces what would be a good habit anyway (arranging the sum by orders of magnitude), it looks acceptable."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586593050.248600",
        "parent_user_id": "UJBAJNFLK",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UCGAK10LS"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "85703151-E681-40D6-868A-8386893C35D9",
        "type": "message",
        "text": "<@UT60XSVCN> Interval arithmetic is a tool for analyzing the robustness of numerical algorithms. It\u2019s almost useless for production runs. The same holds for exact real arithmetic.",
        "user": "UJBAJNFLK",
        "ts": "1586619668.295100",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "j9b",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UT60XSVCN"
                            },
                            {
                                "type": "text",
                                "text": " Interval arithmetic is a tool for analyzing the robustness of numerical algorithms. It\u2019s almost useless for production runs. The same holds for exact real arithmetic."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586593050.248600",
        "parent_user_id": "UJBAJNFLK",
        "reactions": [
            {
                "name": "bulb",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "9D4CAD64-3709-4037-8248-967F0F0D3038",
        "type": "message",
        "text": "What if the info is used to select the \"best suited\" representation during compilation? Eg. if you make interest rate calc, you might want output to be correct +/- 0.4 cent, after 0-200yrs (+/- 0.4). With eg. js, I have to do a bit of digging to be sure, same for C (to figure out correct data type etc), but here, I could just write the plain formula, and specify the input/output error intervals (or just confirm the defaults) and be done and confident with it.",
        "user": "UNCP67JSK",
        "ts": "1586620089.303600",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UNCP67JSK",
            "ts": "1586620140.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "VKD",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "What if the info is used to select the \"best suited\" representation during compilation? Eg. if you make interest rate calc, you might want output to be correct +/- 0.4 cent, after 0-200yrs (+/- 0.4). With eg. js, I have to do a bit of digging to be sure, same for C (to figure out correct data type etc), but here, I could just write the plain formula, and specify the input/output error intervals (or just confirm the defaults) and be done and confident with it."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586593050.248600",
        "parent_user_id": "UJBAJNFLK"
    },
    {
        "client_msg_id": "6BF2F402-460D-4424-811A-4C9AAACF6B73",
        "type": "message",
        "text": "I feel like \"precision\" and \"robustness\" is quite lacking in the software field I've been exposed to. Would be happy to be shown otherwise.",
        "user": "UNCP67JSK",
        "ts": "1586620254.306200",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "FvcbZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I feel like \"precision\" and \"robustness\" is quite lacking in the software field I've been exposed to. Would be happy to be shown otherwise."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586593050.248600",
        "parent_user_id": "UJBAJNFLK"
    },
    {
        "client_msg_id": "AD14602D-88DA-4E9E-9096-0A1BD1CD9900",
        "type": "message",
        "text": "Mathematica is a Very commonly use language that does not use floating-point. It is a symbolic language and can generate computations to arbitrate precision. Others symbolic math languages like maple can do the same thing\ufffc. The old language SPITBOL\ufffc Which was a continuation of Griswolds SNOBOL Also had arbitrary precision\ufffc, Not sure if the final version which is called icon offered that same feature.\ufffc myself I am planning to useDEC64 arithmetic as outlined by the very smart Douglas Crockford. IEEE Floating-point is indeed fraught with problems\ufffc\ufffc\ufffc, And I believe it is one of the reasons COBOL still exists is that it offered BCD arithmetic\ufffc With specified Percision so that you could control the rounding very deliberately. It\u2019s actually one of the only features in COBOL That Fortran didn\u2019t have. There was a long ago battle Between those two languages and COBOL won (unfortunately)",
        "user": "UEQ6M68H0",
        "ts": "1586622738.311000",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "LYOLQ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Mathematica is a Very commonly use language that does not use floating-point. It is a symbolic language and can generate computations to arbitrate precision. Others symbolic math languages like maple can do the same thing\ufffc. The old language SPITBOL\ufffc Which was a continuation of Griswolds SNOBOL Also had arbitrary precision\ufffc, Not sure if the final version which is called icon offered that same feature.\ufffc myself I am planning to useDEC64 arithmetic as outlined by the very smart Douglas Crockford. IEEE Floating-point is indeed fraught with problems\ufffc\ufffc\ufffc, And I believe it is one of the reasons COBOL still exists is that it offered BCD arithmetic\ufffc With specified Percision so that you could control the rounding very deliberately. It\u2019s actually one of the only features in COBOL That Fortran didn\u2019t have. There was a long ago battle Between those two languages and COBOL won (unfortunately)"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586593050.248600",
        "parent_user_id": "UJBAJNFLK",
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "UNCP67JSK"
                ],
                "count": 1
            },
            {
                "name": "+1",
                "users": [
                    "UCGAK10LS"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "5827D2EA-7D36-4010-A0B7-FE452BB65DA4",
        "type": "message",
        "text": "<@UNCP67JSK> That\u2019s how exact real arithmetic works. Arithmetic operations return functions that you can call with the desired precision as its argument.",
        "user": "UJBAJNFLK",
        "ts": "1586630274.313900",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "JSM",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UNCP67JSK"
                            },
                            {
                                "type": "text",
                                "text": " That\u2019s how exact real arithmetic works. Arithmetic operations return functions that you can call with the desired precision as its argument."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586593050.248600",
        "parent_user_id": "UJBAJNFLK"
    },
    {
        "client_msg_id": "db3cdaf1-38fb-4e9b-86e2-950ec3769f55",
        "type": "message",
        "text": "This morning I find myself (re?)reading the documentation on the command language for the Sam editor from Plan9: <http://doc.cat-v.org/bell_labs/sam_lang_tutorial/sam_tut.pdf>\n\nIt's interesting to think of these command languages from the 70's as a necessarily linguistic way to describe _gestural_ operations, purely because of the technical limitations of the time. For example, I think editors with multiple cursors may find something to crib from Sam.",
        "user": "UCUSW7WVD",
        "ts": "1586630542.315700",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "6Kbv",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "This morning I find myself (re?)reading the documentation on the command language for the Sam editor from Plan9: "
                            },
                            {
                                "type": "link",
                                "url": "http://doc.cat-v.org/bell_labs/sam_lang_tutorial/sam_tut.pdf"
                            },
                            {
                                "type": "text",
                                "text": "\n\nIt's interesting to think of these command languages from the 70's as a necessarily linguistic way to describe "
                            },
                            {
                                "type": "text",
                                "text": "gestural",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " operations, purely because of the technical limitations of the time. For example, I think editors with multiple cursors may find something to crib from Sam."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586630542.315700",
        "reply_count": 1,
        "reply_users_count": 1,
        "latest_reply": "1586648128.327900",
        "reply_users": [
            "UFEQUBNNT"
        ],
        "subscribed": false
    },
    {
        "client_msg_id": "bd932f92-cc81-4e86-aa63-433e1e443780",
        "type": "message",
        "text": "Clojure has a built in Ratio type,  no? I thought many lisps have this.",
        "user": "U8A5MS6R1",
        "ts": "1586630579.315800",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "U8A5MS6R1",
            "ts": "1586630590.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "3cYJ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Clojure has a built in Ratio type,  no? I thought many lisps have this."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586606048.277800",
        "parent_user_id": "UBN9AFS0N"
    },
    {
        "client_msg_id": "5596c59a-79d7-4c77-803d-ca61d4ce4bba",
        "type": "message",
        "text": "This thread is really going places :smile:. One of the assumptions about qualia is that there are clear cut boundaries in the vast physical ocean. Consider the ripples of physical reactions - they just flow through different materials via chains of cause-effect reactions. This is kind of like data flow in a spreadsheet through an 'ocean of physical particles'. First we mentally impose partitioning in this space - a subset of cells - and then say when the ripple passes through this subset, it is associated with some qualia (taste, hearing, pain, whatever..). But the physical ocean has no natural partitioning - so how do we decide the boundaries of 'a person' or 'a computer'? Anyway, what I really want to know is if there is a name for this partitioning idea.",
        "user": "U8A5MS6R1",
        "ts": "1586634209.321100",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "zmY",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "This thread is really going places "
                            },
                            {
                                "type": "emoji",
                                "name": "smile"
                            },
                            {
                                "type": "text",
                                "text": ". One of the assumptions about qualia is that there are clear cut boundaries in the vast physical ocean. Consider the ripples of physical reactions - they just flow through different materials via chains of cause-effect reactions. This is kind of like data flow in a spreadsheet through an 'ocean of physical particles'. First we mentally impose partitioning in this space - a subset of cells - and then say when the ripple passes through this subset, it is associated with some qualia (taste, hearing, pain, whatever..). But the physical ocean has no natural partitioning - so how do we decide the boundaries of 'a person' or 'a computer'? Anyway, what I really want to know is if there is a name for this partitioning idea."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586462800.208000",
        "parent_user_id": "UC2A2ARPT"
    },
    {
        "client_msg_id": "a71e644d-fa9f-47e2-a140-4da8f903b4c3",
        "type": "message",
        "text": "Fixed point is rubbish for a general purpose language. It has its place, especially on embedded processors with no floating point hardware, but in general you get worse numeric results, so you have to be much more careful in designing your code than you do with floating point. Rational arithmetic is so crazy expensive in both time and space that numerically intensive algorithms can become infeasible, thus forcing users to rewrite their programs in another language that supports floating point. There are many languages where computations don't have a total ordering: any purely functional language that uses data parallelism for performance (eg, using GPU hardware) has this characteristic. The serious ones used for real work use floating point. For example, Tensor Flow. There is actually no way to design a number system for a programming language that is \"perfect\". There are only engineering tradeoffs. For a general purpose language, floating point represents a local optimum that is hard to beat.",
        "user": "UJN1TAYEQ",
        "ts": "1586634570.322400",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "aqH",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Fixed point is rubbish for a general purpose language. It has its place, especially on embedded processors with no floating point hardware, but in general you get worse numeric results, so you have to be much more careful in designing your code than you do with floating point. Rational arithmetic is so crazy expensive in both time and space that numerically intensive algorithms can become infeasible, thus forcing users to rewrite their programs in another language that supports floating point. There are many languages where computations don't have a total ordering: any purely functional language that uses data parallelism for performance (eg, using GPU hardware) has this characteristic. The serious ones used for real work use floating point. For example, Tensor Flow. There is actually no way to design a number system for a programming language that is \"perfect\". There are only engineering tradeoffs. For a general purpose language, floating point represents a local optimum that is hard to beat."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586634570.322400",
        "reply_count": 8,
        "reply_users_count": 5,
        "latest_reply": "1586683009.337600",
        "reply_users": [
            "UCUSW7WVD",
            "U6FKVSVCK",
            "UJN1TAYEQ",
            "UCGAK10LS",
            "UJBAJNFLK"
        ],
        "subscribed": false
    },
    {
        "client_msg_id": "9375696c-cf12-4d15-8ca4-c0a202818f99",
        "type": "message",
        "text": "Pretty relevant for this community <https://www.gwern.net/Turing-complete|https://www.gwern.net/Turing-complete>",
        "user": "UBSMEUXAA",
        "ts": "1586636363.322900",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "title": "Surprisingly Turing-Complete",
                "title_link": "https://www.gwern.net/Turing-complete",
                "text": "A catalogue of software constructs, languages, or APIs which are unexpectedly Turing-complete; implications for security and reliability",
                "fallback": "Surprisingly Turing-Complete",
                "image_url": "https://www.gwern.net/images/logo-whitebg-large-border.png",
                "from_url": "https://www.gwern.net/Turing-complete",
                "image_width": 221,
                "image_height": 250,
                "image_bytes": 62702,
                "service_icon": "https://www.gwern.net/./images/logo-smooth-appletouch.png",
                "service_name": "gwern.net",
                "id": 1,
                "original_url": "https://www.gwern.net/Turing-complete"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "VN5",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Pretty relevant for this community "
                            },
                            {
                                "type": "link",
                                "url": "https://www.gwern.net/Turing-complete",
                                "text": "https://www.gwern.net/Turing-complete"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586636363.322900",
        "reply_count": 4,
        "reply_users_count": 1,
        "latest_reply": "1586641073.327500",
        "reply_users": [
            "UJN1TAYEQ"
        ],
        "subscribed": false
    },
    {
        "client_msg_id": "a44a038c-b283-41b4-99b3-9371d8c1dc2e",
        "type": "message",
        "text": "What do you think of Unums? <https://en.wikipedia.org/wiki/Unum_(number_format)|https://en.wikipedia.org/wiki/Unum_(number_format)>",
        "user": "UCUSW7WVD",
        "ts": "1586636429.324700",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "title": "Unum (number format)",
                "title_link": "https://en.wikipedia.org/wiki/Unum_(number_format)",
                "from_url": "https://en.wikipedia.org/wiki/Unum_(number_format)",
                "author_name": "Wikipedia",
                "author_link": "https://en.wikipedia.org/",
                "text": "Unums (universal numbers) are an arithmetic and a binary representation format for real numbers analogous to floating point, proposed by John L. Gustafson as an alternative to the now ubiquitous IEEE 754 arithmetic. The first version of unums, now officially known as Type I unum, was introduced in his book The End of Error. Gustafson has since created two newer revisions of the unum format, Type II and Type III, in late 2016. Type III unum is also known as posits and valids; posits present arithmetic for single real values and valids present the interval arithmetic version. This data type can serve as a replacement for IEEE 754 floats for programs which do not depend on specific features of IEEE 754. Details of valids have yet to be officially articulated by Gustafson.",
                "fallback": "wikipedia: Unum (number format)",
                "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/wikipedia.png",
                "id": 1,
                "original_url": "https://en.wikipedia.org/wiki/Unum_(number_format)"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "pmILq",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "What do you think of Unums? "
                            },
                            {
                                "type": "link",
                                "url": "https://en.wikipedia.org/wiki/Unum_(number_format)",
                                "text": "https://en.wikipedia.org/wiki/Unum_(number_format)"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586634570.322400",
        "parent_user_id": "UJN1TAYEQ"
    },
    {
        "client_msg_id": "cb933381-0dcd-43fd-97b3-8e349b3750af",
        "type": "message",
        "text": "I like the idea of accidental Turing completeness, it's actually something that scares me a little bit when designing sufficiently complex that might benefit from not being Turing complete (for security, performance and general complexity reasons)",
        "user": "UBSMEUXAA",
        "ts": "1586636455.325700",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ajY",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I like the idea of accidental Turing completeness, it's actually something that scares me a little bit when designing sufficiently complex that might benefit from not being Turing complete (for security, performance and general complexity reasons)"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "client_msg_id": "6a81a5a4-cc8d-4bef-a2da-ce4eea1829f0",
        "type": "message",
        "text": "<@UJBAJNFLK> regarding interval arithmetic in production, what do you think of Unums? <https://en.wikipedia.org/wiki/Unum_(number_format)|https://en.wikipedia.org/wiki/Unum_(number_format)>",
        "user": "UCUSW7WVD",
        "ts": "1586636578.325800",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "+=pE4",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UJBAJNFLK"
                            },
                            {
                                "type": "text",
                                "text": " regarding interval arithmetic in production, what do you think of Unums? "
                            },
                            {
                                "type": "link",
                                "url": "https://en.wikipedia.org/wiki/Unum_(number_format)",
                                "text": "https://en.wikipedia.org/wiki/Unum_(number_format)"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586593050.248600",
        "parent_user_id": "UJBAJNFLK"
    },
    {
        "client_msg_id": "63b9045c-0259-4cbe-a301-deeee440bdef",
        "type": "message",
        "text": "DEC64 is also pretty decent, particularly for financial calculations. <http://www.dec64.com/|http://www.dec64.com/>",
        "user": "U6FKVSVCK",
        "ts": "1586637094.326000",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "pWE/C",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "DEC64 is also pretty decent, particularly for financial calculations. "
                            },
                            {
                                "type": "link",
                                "url": "http://www.dec64.com/",
                                "text": "http://www.dec64.com/"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586634570.322400",
        "parent_user_id": "UJN1TAYEQ",
        "reactions": [
            {
                "name": "100",
                "users": [
                    "UCUSW7WVD",
                    "ULM3U6275"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "da892073-ce2f-41f2-b1b7-4af7aa3df41a",
        "type": "message",
        "text": "Ah, we've discussed this!",
        "user": "UCUSW7WVD",
        "ts": "1586637345.326300",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "FNYI",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Ah, we've discussed this!"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586634570.322400",
        "parent_user_id": "UJN1TAYEQ"
    },
    {
        "client_msg_id": "102712e3-227d-4fa6-b2f0-819c89390c74",
        "type": "message",
        "text": "I like Posits. I didn't study the older Unum proposals. I have long had opinions about what I consider to be bugs in the design of IEEE floats, and I was delighted to see that the Unum author agreed with me and fixed the things I thought were broken. Note that I am not a numerical analyst, and that my opinions are based on ideas about symmetry, which may or may not have practical value in numerical algorithms.\n\nThe unsymmetrical treatment of +0, -0 has always bugged me. I figured that there should be a true 0, that very small numbers should underflow to '+epsilon', not to 0, and that very small negative numbers should underflow to '-epsilon', not to 0. I agree with the idea that very large positive numbers should overflow to '+infinity' and very large negative numbers should overflow to '-infinity', which happens in both number systems. Posits work this way, except that the Posit standard uses the term \"infinity\" to describe \"NaN\". 1/0 is NaN (what Posits call \"Infinity\"), not \"+infinity\", as it is in IEEE floats, because true 0 does not have a sign, so there is no way to choose between the results +infinity and -infinity. In IEEE floats, there is no true 0, and the value 0 behaves like +epsilon in some contexts. So in IEEE floats, 1-1 is +0, not true 0.\n\nThat said, William Kahan's rationale for the behaviour of +0/-0 in IEEE floats sounds superficially plausible. Since I've never tried to implement transcendental functions in both IEEE floats and posits and compared the difficulty, I can't say who is right. \"Branch cuts for complex elementary\nfunctions, or much ado about nothing\u2019s sign bit\" by William Kahan.\n<https://homes.cs.washington.edu/~ztatlock/599z-17sp/papers/branch-cuts-kahan-87.pdf>",
        "user": "UJN1TAYEQ",
        "ts": "1586638459.326500",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "GGZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I like Posits. I didn't study the older Unum proposals. I have long had opinions about what I consider to be bugs in the design of IEEE floats, and I was delighted to see that the Unum author agreed with me and fixed the things I thought were broken. Note that I am not a numerical analyst, and that my opinions are based on ideas about symmetry, which may or may not have practical value in numerical algorithms.\n\nThe unsymmetrical treatment of +0, -0 has always bugged me. I figured that there should be a true 0, that very small numbers should underflow to '+epsilon', not to 0, and that very small negative numbers should underflow to '-epsilon', not to 0. I agree with the idea that very large positive numbers should overflow to '+infinity' and very large negative numbers should overflow to '-infinity', which happens in both number systems. Posits work this way, except that the Posit standard uses the term \"infinity\" to describe \"NaN\". 1/0 is NaN (what Posits call \"Infinity\"), not \"+infinity\", as it is in IEEE floats, because true 0 does not have a sign, so there is no way to choose between the results +infinity and -infinity. In IEEE floats, there is no true 0, and the value 0 behaves like +epsilon in some contexts. So in IEEE floats, 1-1 is +0, not true 0.\n\nThat said, William Kahan's rationale for the behaviour of +0/-0 in IEEE floats sounds superficially plausible. Since I've never tried to implement transcendental functions in both IEEE floats and posits and compared the difficulty, I can't say who is right. \"Branch cuts for complex elementary\nfunctions, or much ado about nothing\u2019s sign bit\" by William Kahan.\n"
                            },
                            {
                                "type": "link",
                                "url": "https://homes.cs.washington.edu/~ztatlock/599z-17sp/papers/branch-cuts-kahan-87.pdf"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586634570.322400",
        "parent_user_id": "UJN1TAYEQ"
    },
    {
        "client_msg_id": "b2958574-dc48-44a6-be20-34eadc1ff240",
        "type": "message",
        "text": "What drives me crazy about this kind of blog post is the term \"Turing complete\" has a perfectly precise meaning in computability theory, which has nothing to do with security. Now we are seeing bloggers misuse the term to mean whatever they want it to mean, and every author means something slightly different.",
        "user": "UJN1TAYEQ",
        "ts": "1586639234.326800",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "BNZt",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "What drives me crazy about this kind of blog post is the term \"Turing complete\" has a perfectly precise meaning in computability theory, which has nothing to do with security. Now we are seeing bloggers misuse the term to mean whatever they want it to mean, and every author means something slightly different."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586636363.322900",
        "parent_user_id": "UBSMEUXAA"
    },
    {
        "client_msg_id": "7c60280c-4cc8-4ffd-a05b-381bd47a5d6b",
        "type": "message",
        "text": "The authors of the Dhall configuration language claim that their language is not Turing complete. They aren't confused about the meaning, they are using the same definition as computability theory. Then they claim that not being Turing complete makes their language more secure, which is highly debateable, if not false.",
        "user": "UJN1TAYEQ",
        "ts": "1586639310.327000",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UJN1TAYEQ",
            "ts": "1586639377.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "XXv",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The authors of the Dhall configuration language claim that their language is not Turing complete. They aren't confused about the meaning, they are using the same definition as computability theory. Then they claim that not being Turing complete makes their language more secure, which is highly debateable, if not false."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586636363.322900",
        "parent_user_id": "UBSMEUXAA",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UP6G25H35"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "8b2d0b4b-b00a-4ea4-bba6-f968b90d301b",
        "type": "message",
        "text": "This author has latched onto the idea, but is very loose about the meaning of \"Turing complete\". At one point he claims it means that the language has side effects that can be used to interfere with or take over the host (that's not what it means).\n\nAt another point he claims that Turing completeness allows Row Hammer attacks (and implies that \"total functional programming\" somehow prevents writing such attacks). The reality is different. Security vulnerabilities can be present in any kind of interpreter. Rowhammer requires the ability to trick the interpreter into repeatly hammering on the same contiguous array of memory, which doesn't require Turing completeness. A Turing complete language need not be vulnerable to this, if the run time data structures and interpreter are carefully designed.",
        "user": "UJN1TAYEQ",
        "ts": "1586640697.327300",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "+Icv",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "This author has latched onto the idea, but is very loose about the meaning of \"Turing complete\". At one point he claims it means that the language has side effects that can be used to interfere with or take over the host (that's not what it means).\n\nAt another point he claims that Turing completeness allows Row Hammer attacks (and implies that \"total functional programming\" somehow prevents writing such attacks). The reality is different. Security vulnerabilities can be present in any kind of interpreter. Rowhammer requires the ability to trick the interpreter into repeatly hammering on the same contiguous array of memory, which doesn't require Turing completeness. A Turing complete language need not be vulnerable to this, if the run time data structures and interpreter are carefully designed."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586636363.322900",
        "parent_user_id": "UBSMEUXAA"
    },
    {
        "client_msg_id": "5966bc18-2f12-4933-9905-8b7d811c5a3c",
        "type": "message",
        "text": "In a Turing complete language, you can write a program that loops forever, and attempts to allocate an infinite amount of memory. The \"total functional programming\" model of Dhall prevents you from doing these things, and that's supposed to be a big win. But Dhall does not prevent you from allocating all of the memory in the machine, and it doesn't prevent you from writing a loop that iterates for billions of years. So there's no benefit at all, in terms of protecting you from malicious code.",
        "user": "UJN1TAYEQ",
        "ts": "1586641073.327500",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "VCr",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "In a Turing complete language, you can write a program that loops forever, and attempts to allocate an infinite amount of memory. The \"total functional programming\" model of Dhall prevents you from doing these things, and that's supposed to be a big win. But Dhall does not prevent you from allocating all of the memory in the machine, and it doesn't prevent you from writing a loop that iterates for billions of years. So there's no benefit at all, in terms of protecting you from malicious code."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586636363.322900",
        "parent_user_id": "UBSMEUXAA"
    },
    {
        "client_msg_id": "329c03f3-e865-4005-91f8-d7136716b2d8",
        "type": "message",
        "text": "For sure. I think it's not just about wanting gestures, though. <http://texteditors.org/cgi-bin/wiki.pl?Jim|The letter you posted recently> laid it out: terminal and host were still separate, and they wanted the language to provide \"direct help with large or repetitive editing tasks.\"\n\nMultiple cursors let you see what's going for interactive editing tasks, but extending them to batch operations is messy in comparison. Like, vim supports a lot of the same commands and range operations as Sam, but the way you use them for batch editing is essentially replaying your keypresses over and over, which introduces edge conditions that don't exist in Sam's language.",
        "user": "UFEQUBNNT",
        "ts": "1586648128.327900",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "title": "TextEditors Wiki: Jim",
                "title_link": "http://texteditors.org/cgi-bin/wiki.pl?Jim",
                "text": "A website about selecting and classifying text editors used in programming systems. These are the programming text editors such as Emacs, VI, Multiedit, slick, Slickedit, ISPF, Notepad, VI and VIM that are used by the vast majority of programmers on UNIX, Windows, VAX, and Mainframe systems. The structure of the website allows any vistor to leave their opinions, knowledge, and mark on the website for others to enjoy.",
                "fallback": "TextEditors Wiki: Jim",
                "from_url": "http://texteditors.org/cgi-bin/wiki.pl?Jim",
                "service_name": "texteditors.org",
                "id": 1,
                "original_url": "http://texteditors.org/cgi-bin/wiki.pl?Jim"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "f9fJU",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "For sure. I think it's not just about wanting gestures, though. "
                            },
                            {
                                "type": "link",
                                "url": "http://texteditors.org/cgi-bin/wiki.pl?Jim",
                                "text": "The letter you posted recently"
                            },
                            {
                                "type": "text",
                                "text": " laid it out: terminal and host were still separate, and they wanted the language to provide \"direct help with large or repetitive editing tasks.\"\n\nMultiple cursors let you see what's going for interactive editing tasks, but extending them to batch operations is messy in comparison. Like, vim supports a lot of the same commands and range operations as Sam, but the way you use them for batch editing is essentially replaying your keypresses over and over, which introduces edge conditions that don't exist in Sam's language."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586630542.315700",
        "parent_user_id": "UCUSW7WVD",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "6ce9a15f-fe63-437a-adb2-1781aa6f9fd7",
        "type": "message",
        "text": "<https://twitter.com/wcrichton/status/1248733099996766210>",
        "user": "UFEQUBNNT",
        "ts": "1586648787.328300",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "fallback": "<https://twitter.com/wcrichton|@wcrichton>: <https://twitter.com/sliminality|@sliminality> \"Messenger used to receive bugs reports on a daily basis; since the introduction of Reason, there have been a total of 10 bugs (that's during the whole year, not per week)! ... Refactoring speed went from days to hours to dozens of minutes.\"\n\n<https://reasonml.github.io/blog/2017/09/08/messenger-50-reason>",
                "ts": 1586556146,
                "author_name": "Will Crichton",
                "author_link": "https://twitter.com/wcrichton/status/1248733099996766210",
                "author_icon": "https://pbs.twimg.com/profile_images/1127803031708246016/gUAyYE2i_normal.png",
                "author_subname": "@wcrichton",
                "text": "<https://twitter.com/sliminality|@sliminality> \"Messenger used to receive bugs reports on a daily basis; since the introduction of Reason, there have been a total of 10 bugs (that's during the whole year, not per week)! ... Refactoring speed went from days to hours to dozens of minutes.\"\n\n<https://reasonml.github.io/blog/2017/09/08/messenger-50-reason>",
                "service_name": "twitter",
                "service_url": "https://twitter.com/",
                "from_url": "https://twitter.com/wcrichton/status/1248733099996766210",
                "id": 1,
                "original_url": "https://twitter.com/wcrichton/status/1248733099996766210",
                "footer": "Twitter",
                "footer_icon": "https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "PEAUn",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "link",
                                "url": "https://twitter.com/wcrichton/status/1248733099996766210"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586648787.328300",
        "reply_count": 5,
        "reply_users_count": 3,
        "latest_reply": "1586680764.337200",
        "reply_users": [
            "UFEQUBNNT",
            "UFB8STN7K",
            "U8A5MS6R1"
        ],
        "subscribed": false
    },
    {
        "client_msg_id": "492f5536-7dd4-4500-b435-8f93b1eec6fa",
        "type": "message",
        "text": "Also from the article: ~2s builds, &lt;100ms incremental builds.",
        "user": "UFEQUBNNT",
        "ts": "1586648817.328700",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "wH1Ph",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Also from the article: ~2s builds, <100ms incremental builds."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1586648787.328300",
        "parent_user_id": "UFEQUBNNT"
    }
]