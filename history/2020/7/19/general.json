[
    {
        "client_msg_id": "099F8CD7-F426-423E-9DE3-0FD40FB49E60",
        "type": "message",
        "text": "GPT-3 is amazing to me",
        "user": "UC2A2ARPT",
        "ts": "1595111074.467900",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "DOp2F",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "GPT-3 is amazing to me"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595090645.460700",
        "parent_user_id": "UBSMEUXAA"
    },
    {
        "client_msg_id": "17399bef-6a01-4ef7-ab88-acce2dac1180",
        "type": "message",
        "text": "Oh, that's an excellent article <@U013ZLJARC7>, though I'm not sure if it qualifies as a book review... Thanks for sharing!\nI didn't know Cosma wrote outside his own website\u2014I spent quite a bit of time reading through a lot of his notes on his website a while back, very interesting guy. Thinking about it, he appears to have been ahead of the curve when it comes to the \"digital garden\" thing that's become a trend here as of recent.",
        "user": "UT60XSVCN",
        "ts": "1595116841.468600",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "XRO",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Oh, that's an excellent article "
                            },
                            {
                                "type": "user",
                                "user_id": "U013ZLJARC7"
                            },
                            {
                                "type": "text",
                                "text": ", though I'm not sure if it qualifies as a book review... Thanks for sharing!\nI didn't know Cosma wrote outside his own website\u2014I spent quite a bit of time reading through a lot of his notes on his website a while back, very interesting guy. Thinking about it, he appears to have been ahead of the curve when it comes to the \"digital garden\" thing that's become a trend here as of recent."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595017818.433700",
        "parent_user_id": "U015902ESJC"
    },
    {
        "client_msg_id": "37cb9215-b27e-4700-9256-428f75e0d5d9",
        "type": "message",
        "text": "A link to the aforementioned, if anyone is interested: <http://www.bactra.org/notebooks/|http://www.bactra.org/notebooks/>",
        "user": "UT60XSVCN",
        "ts": "1595116902.468800",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "s+4",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "A link to the aforementioned, if anyone is interested: "
                            },
                            {
                                "type": "link",
                                "url": "http://www.bactra.org/notebooks/",
                                "text": "http://www.bactra.org/notebooks/"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595017818.433700",
        "parent_user_id": "U015902ESJC"
    },
    {
        "client_msg_id": "e0836692-fdf7-4d03-9276-af6fd3942db4",
        "type": "message",
        "text": "I'm also on the latter end of the spectrum.\n\nI want to provide means for whatever the programmer (or user) is making to be represented in whatever form (e.g. visual or otherwise) is desired, with whatever semantics, and even editor-behaviors. And all the same for the tool itself, as it's its own live-editor.\n\nI'll do this by providing *a* model (e.g. direct manipulation entities), and having the live code of the tool itself exposed for direct manipulation within that same model, so that anything about it (down to the metal if desired) *could* be altered (the rendering, the execution model, the data model, etc.).\n\nThe point is to bootstrap the incredible power of programming, onto programming itself, with immediate turn around / feedback. And if the initial tool for doing so sucks (e.g. if only I could just drag like this to change that), then change it. If the means for changing how you change that sucks ... well there's no endless tower because it's all live implemented in itself; it's a closed loop.",
        "user": "UAVCC2X70",
        "ts": "1595119543.469400",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UAVCC2X70",
            "ts": "1595133962.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "00rn",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'm also on the latter end of the spectrum.\n\nI want to provide means for whatever the programmer (or user) is making to be represented in whatever form (e.g. visual or otherwise) is desired, with whatever semantics, and even editor-behaviors. And all the same for the tool itself, as it's its own live-editor.\n\nI'll do this by providing "
                            },
                            {
                                "type": "text",
                                "text": "a",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " model (e.g. direct manipulation entities), and having the live code of the tool itself exposed for direct manipulation within that same model, so that anything about it (down to the metal if desired) "
                            },
                            {
                                "type": "text",
                                "text": "could",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " be altered (the rendering, the execution model, the data model, etc.).\n\nThe point is to bootstrap the incredible power of programming, onto programming itself, with immediate turn around / feedback. And if the initial tool for doing so sucks (e.g. if only I could just drag like this to change that), then change it. If the means for changing how you change that sucks ... well there's no endless tower because it's all live implemented in itself; it's a closed loop."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1594276999.116700",
        "parent_user_id": "UC2A2ARPT",
        "reactions": [
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UJ6LDMMN0"
                ],
                "count": 1
            },
            {
                "name": "+1",
                "users": [
                    "UJ6LDMMN0"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "74461ed9-f593-49c2-b940-a5ed073b74c4",
        "type": "message",
        "text": "Here are some of my motivations:\n\nSo much effort goes into making a tool or language, which is repeated over and over ... Can we bootstrap all this work on itself? It's like repeatedly building lever-making-levers _by hand_. The ignored potential is just painful!\n\nExtend the \"power of programming\" to the end user; make computers _actually be_ a bicycle for the mind and for interacting with the modern world.\n\nProgramming by direct interaction: We want to call *this* API (click) and take the result (drag), fish out this field (right click), transform it *like so* (drop it into a function entity, or type an equation) and send the result (click &amp; drag) over to there (drop). And hey look, you can \"see the work\" (like math homework) and edit it, substitute values, etc. Making the line between programming and using very thin, leads to my next point:\n\nI think this could be a new kind of literacy, and we won't have it until we can bootstrap programming out of source code. How powerful is that smartphone in your hand? What does that even mean if it's inaccessible to you though? All the power of software in your hand, but none of the power of software in your hand. To me, closing that loop / bootstrapping that power, is the computer revolution that hasn't happened yet.",
        "user": "UAVCC2X70",
        "ts": "1595126486.470100",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UAVCC2X70",
            "ts": "1595143587.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "prb+",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Here are some of my motivations:\n\nSo much effort goes into making a tool or language, which is repeated over and over ... Can we bootstrap all this work on itself? It's like repeatedly building lever-making-levers "
                            },
                            {
                                "type": "text",
                                "text": "by hand",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". The ignored potential is just painful!\n\nExtend the \"power of programming\" to the end user; make computers "
                            },
                            {
                                "type": "text",
                                "text": "actually be",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " a bicycle for the mind and for interacting with the modern world.\n\nProgramming by direct interaction: We want to call "
                            },
                            {
                                "type": "text",
                                "text": "this",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " API (click) and take the result (drag), fish out this field (right click), transform it "
                            },
                            {
                                "type": "text",
                                "text": "like so ",
                                "style": {
                                    "bold": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "(drop it into a function entity, or type an equation) and send the result (click & drag) over to there (drop). And hey look, you can \"see the work\" (like math homework) and edit it, substitute values, etc. Making the line between programming and using very thin, leads to my next point:\n\nI think this could be a new kind of literacy, and we won't have it until we can bootstrap programming out of source code. How powerful is that smartphone in your hand? What does that even mean if it's inaccessible to you though? All the power of software in your hand, but none of the power of software in your hand. To me, closing that loop / bootstrapping that power, is the computer revolution that hasn't happened yet."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1594276999.116700",
        "parent_user_id": "UC2A2ARPT",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UC2A2ARPT",
                    "UJ6LDMMN0",
                    "U5STGTB3J"
                ],
                "count": 3
            },
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UJ6LDMMN0",
                    "UHWC9PXBL"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "004b7fc6-e2d2-457b-8c5d-740a1588eaa2",
        "type": "message",
        "text": "<https://citrine-lang.org/|https://citrine-lang.org/> seems like this'll lead to an interesting discussion.\nNot sure about\n&gt; \tCitrine does not support comments, forcing authors to write self-documenting code. ",
        "user": "U0136G8R8KG",
        "ts": "1595138454.472900",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "title": "Localized Programming Language Citrine",
                "title_link": "https://citrine-lang.org/",
                "text": "Citrine, the world's first localized programming language. Write code in your native language.",
                "fallback": "Localized Programming Language Citrine",
                "from_url": "https://citrine-lang.org/",
                "service_icon": "https://citrine-lang.org/favicon.ico",
                "service_name": "citrine-lang.org",
                "id": 1,
                "original_url": "https://citrine-lang.org/"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ROa",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "link",
                                "url": "https://citrine-lang.org/",
                                "text": "https://citrine-lang.org/"
                            },
                            {
                                "type": "text",
                                "text": " seems like this'll lead to an interesting discussion.\nNot sure about\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\tCitrine does not support comments, forcing authors to write self-documenting code. "
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595138454.472900",
        "reply_count": 2,
        "reply_users_count": 2,
        "latest_reply": "1595304600.055800",
        "reply_users": [
            "UP28ETUSE",
            "UC6997THT"
        ],
        "subscribed": false
    },
    {
        "client_msg_id": "004BFDAD-ABC7-4A44-B0D8-F63FAECFD292",
        "type": "message",
        "text": "Spot on <@UKP3B2J5D> - fantastic share",
        "user": "USH01JEDQ",
        "ts": "1595139027.473600",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "VYs",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Spot on "
                            },
                            {
                                "type": "user",
                                "user_id": "UKP3B2J5D"
                            },
                            {
                                "type": "text",
                                "text": " - fantastic share"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595084421.458800",
        "parent_user_id": "UKP3B2J5D",
        "reactions": [
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UJ6LDMMN0",
                    "UKP3B2J5D"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "ae158c49-3194-415c-8d26-0d2cf49c87de",
        "type": "message",
        "text": "<@UT60XSVCN> He's grand! If you enjoy his writing, don't miss out on his blog: <http://www.bactra.org/weblog/> :slightly_smiling_face:",
        "user": "U013ZLJARC7",
        "ts": "1595140467.473900",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ZXiC",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UT60XSVCN"
                            },
                            {
                                "type": "text",
                                "text": " He's grand! If you enjoy his writing, don't miss out on his blog: "
                            },
                            {
                                "type": "link",
                                "url": "http://www.bactra.org/weblog/"
                            },
                            {
                                "type": "text",
                                "text": " "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595017818.433700",
        "parent_user_id": "U015902ESJC"
    },
    {
        "client_msg_id": "1c9804ec-bac4-4567-baf9-42cf70da758f",
        "type": "message",
        "text": "(The essay in question was ~originally~ also published at <http://bactra.org/weblog/918.html>)",
        "user": "U013ZLJARC7",
        "ts": "1595140523.474100",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "U013ZLJARC7",
            "ts": "1595140736.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "SH=",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "(The essay in question was "
                            },
                            {
                                "type": "text",
                                "text": "originally",
                                "style": {
                                    "strike": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " also published at "
                            },
                            {
                                "type": "link",
                                "url": "http://bactra.org/weblog/918.html"
                            },
                            {
                                "type": "text",
                                "text": ")"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595017818.433700",
        "parent_user_id": "U015902ESJC"
    },
    {
        "client_msg_id": "d13c014e-eca3-4093-b266-6530e6008505",
        "type": "message",
        "text": "Pulumi is fantastic for infrastructure-as-code. It's declarative, even though it uses general purpose PLs to declare the infrastructure.",
        "user": "UP28ETUSE",
        "ts": "1595141079.474700",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UP28ETUSE",
            "ts": "1595141088.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "DBiN",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Pulumi is fantastic for infrastructure-as-code. It's declarative, even though it uses general purpose PLs to declare the infrastructure."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595084421.458800",
        "parent_user_id": "UKP3B2J5D",
        "reactions": [
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UJ6LDMMN0",
                    "UKP3B2J5D"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "691cc9f6-3df6-4bf2-ac43-c79c2f153be3",
        "type": "message",
        "text": "Interesting perspective on GPT-3:\n<https://twitter.com/sh_reya/status/1284545976892403714?s=09|https://twitter.com/sh_reya/status/1284545976892403714?s=09>",
        "user": "U0136G8R8KG",
        "ts": "1595144410.477000",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "U0136G8R8KG",
            "ts": "1595144426.000000"
        },
        "attachments": [
            {
                "fallback": "<https://twitter.com/sh_reya|@sh_reya>: Got my invite to the <https://twitter.com/OpenAI|@OpenAI> GPT-3 API from <https://twitter.com/gdb|@gdb>. I actually think it deserves more hype than it\u2019s getting, but not necessarily for the magical reasons Twitter touts. Why? My quick thoughts and impressions: (1/11)",
                "ts": 1595094601,
                "author_name": "Shreya Shankar",
                "author_link": "https://twitter.com/sh_reya/status/1284545976892403714",
                "author_icon": "https://pbs.twimg.com/profile_images/1277419831197724672/j9zhyq1P_normal.jpg",
                "author_subname": "@sh_reya",
                "text": "Got my invite to the <https://twitter.com/OpenAI|@OpenAI> GPT-3 API from <https://twitter.com/gdb|@gdb>. I actually think it deserves more hype than it\u2019s getting, but not necessarily for the magical reasons Twitter touts. Why? My quick thoughts and impressions: (1/11)",
                "service_name": "twitter",
                "service_url": "https://twitter.com/",
                "from_url": "https://twitter.com/sh_reya/status/1284545976892403714?s=09",
                "id": 1,
                "original_url": "https://twitter.com/sh_reya/status/1284545976892403714?s=09",
                "footer": "Twitter",
                "footer_icon": "https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "VXP8v",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Interesting perspective on GPT-3:\n"
                            },
                            {
                                "type": "link",
                                "url": "https://twitter.com/sh_reya/status/1284545976892403714?s=09",
                                "text": "https://twitter.com/sh_reya/status/1284545976892403714?s=09"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "reply_count": 33,
        "reply_users_count": 7,
        "latest_reply": "1595254963.053200",
        "reply_users": [
            "U5STGTB3J",
            "UKP3B2J5D",
            "UNBPP291C",
            "UP28ETUSE",
            "UK3LH8CF5",
            "UC2A2ARPT",
            "UBSMEUXAA"
        ],
        "subscribed": false,
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UJ6LDMMN0",
                    "UHWC9PXBL",
                    "UBSMEUXAA",
                    "UA14TGLTC"
                ],
                "count": 4
            }
        ]
    },
    {
        "client_msg_id": "395490a3-82a2-4ac8-8b1e-633a4a72123b",
        "type": "message",
        "text": "Re: Shared library version problem:\nCheck out the Nix Package Manager and NixOS:\n<https://nixos.org/|https://nixos.org/>\nThey solve it very nicely!",
        "user": "U0136G8R8KG",
        "ts": "1595144785.477500",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "7KKP",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Re: Shared library version problem:\nCheck out the Nix Package Manager and NixOS:\n"
                            },
                            {
                                "type": "link",
                                "url": "https://nixos.org/",
                                "text": "https://nixos.org/"
                            },
                            {
                                "type": "text",
                                "text": "\nThey solve it very nicely!"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1594581007.318600",
        "parent_user_id": "UT60XSVCN"
    },
    {
        "client_msg_id": "a1d11c47-37f0-4aec-926f-89699af3a196",
        "type": "message",
        "text": "Very interesting read, thanks for sharing <@UKP3B2J5D>! I wonder how to transpose these ideas in a visual way. Maybe, as a toy project, one can try to implement a basic Desire/Fact/Relations paradigm into Pulumi, and implement a basic mapping that into some visual representations?",
        "user": "UJ6LDMMN0",
        "ts": "1595154076.478300",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Wbehs",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Very interesting read, thanks for sharing "
                            },
                            {
                                "type": "user",
                                "user_id": "UKP3B2J5D"
                            },
                            {
                                "type": "text",
                                "text": "! I wonder how to transpose these ideas in a visual way. Maybe, as a toy project, one can try to implement a basic Desire/Fact/Relations paradigm into Pulumi, and implement a basic mapping that into some visual representations?"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595084421.458800",
        "parent_user_id": "UKP3B2J5D",
        "reactions": [
            {
                "name": "clap",
                "users": [
                    "UKP3B2J5D"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "dd9a119c-4879-4100-b631-832abf608042",
        "type": "message",
        "text": "<@UAVCC2X70> I fully agree with you!",
        "user": "UJ6LDMMN0",
        "ts": "1595154713.478900",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "e2kja",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UAVCC2X70"
                            },
                            {
                                "type": "text",
                                "text": " I fully agree with you!"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1594276999.116700",
        "parent_user_id": "UC2A2ARPT"
    },
    {
        "client_msg_id": "101F8DCD-22C1-443D-BAA3-D15583BA1003",
        "type": "message",
        "text": "Funny, I was just forwarding this thread to a friend: <https://twitter.com/vgr/status/1284684717359419394?s=10|https://twitter.com/vgr/status/1284684717359419394?s=10>",
        "user": "U5STGTB3J",
        "ts": "1595155104.479600",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "fallback": "<https://twitter.com/vgr|@vgr>: Subprime text crisis. I\u2019m amused but not impressed by the evolution of GPT.  Once I saw the ways in which it was failing, the spell broke. <https://twitter.com/atthatmatt/status/1284682407270969344>",
                "ts": 1595127679,
                "author_name": "Venkatesh Rao",
                "author_link": "https://twitter.com/vgr/status/1284684717359419394",
                "author_icon": "https://pbs.twimg.com/profile_images/1266600883380342785/1OFJtU3I_normal.jpg",
                "author_subname": "@vgr",
                "text": "Subprime text crisis. I\u2019m amused but not impressed by the evolution of GPT.  Once I saw the ways in which it was failing, the spell broke. <https://twitter.com/atthatmatt/status/1284682407270969344>",
                "service_name": "twitter",
                "service_url": "https://twitter.com/",
                "from_url": "https://twitter.com/vgr/status/1284684717359419394?s=10",
                "id": 1,
                "original_url": "https://twitter.com/vgr/status/1284684717359419394?s=10",
                "footer": "Twitter",
                "footer_icon": "https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"
            },
            {
                "fallback": "<https://twitter.com/atthatmatt|@atthatmatt>: The feedback loop of AI's getting really good at writing, and polluting the world with AI generated text, which trains the next generation of AIs, is going to be weird.",
                "ts": 1595127128,
                "author_name": "\ud83e\udd27\ud83c\udf0e",
                "author_link": "https://twitter.com/atthatmatt/status/1284682407270969344",
                "author_icon": "https://pbs.twimg.com/profile_images/1163674514506436608/_gjOlClu_normal.jpg",
                "author_subname": "@atthatmatt",
                "text": "The feedback loop of AI's getting really good at writing, and polluting the world with AI generated text, which trains the next generation of AIs, is going to be weird.",
                "service_name": "twitter",
                "service_url": "https://twitter.com/",
                "from_url": "https://twitter.com/atthatmatt/status/1284682407270969344",
                "indent": true,
                "color": "32BBF3",
                "id": 2,
                "footer": "Twitter",
                "footer_icon": "https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Wtiuf",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Funny, I was just forwarding this thread to a friend: "
                            },
                            {
                                "type": "link",
                                "url": "https://twitter.com/vgr/status/1284684717359419394?s=10",
                                "text": "https://twitter.com/vgr/status/1284684717359419394?s=10"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UJ6LDMMN0",
                    "UC2A2ARPT"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "EC586003-891A-48A4-8BAE-7D956CD96C15",
        "type": "message",
        "text": "I think both threads are excellent and the fact that we see such opposite opinions by arguably well-informed people is probably foreshadowing another huge divide in the making.",
        "user": "U5STGTB3J",
        "ts": "1595155288.482900",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "z7BpP",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I think both threads are excellent and the fact that we see such opposite opinions by arguably well-informed people is probably foreshadowing another huge divide in the making."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG",
        "reactions": [
            {
                "name": "white_check_mark",
                "users": [
                    "UKP3B2J5D"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "4E687B23-FDF8-4BD5-9E7E-E58AE240E625",
        "type": "message",
        "text": "I don\u2019t know enough AI but my friend after reading the paper is like there isn\u2019t a fundamental breakthrough, just a bigger model + concerns it doesn\u2019t scale past what it currently is. And comments like <https://twitter.com/Jon_Ayre/status/1284417918260981760?s=20|https://twitter.com/Jon_Ayre/status/1284417918260981760?s=20> . AI hype is to me like the boy the cried wolf tbh. Doesn\u2019t mean this won\u2019t be useful but I guess like they say time will tell :slightly_smiling_face:",
        "user": "UKP3B2J5D",
        "ts": "1595156708.487200",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "fallback": "<https://twitter.com/Jon_Ayre|@Jon_Ayre>: Also this :point_down:\nGPT-3 is basically Eliza, but with the whole internet to plagiarise from.\nAsk any conversation generator a moral question and watch it expose its inner workings.\n\nPeople with poor understanding of machines are easily fooled by convincing automata. <https://twitter.com/Grady_Booch/status/1284196434078650368>",
                "ts": 1595064069,
                "author_name": "Jon Ayre",
                "author_link": "https://twitter.com/Jon_Ayre/status/1284417918260981760",
                "author_icon": "https://pbs.twimg.com/profile_images/1087453167908982784/zvhGHV4X_normal.jpg",
                "author_subname": "@Jon_Ayre",
                "text": "Also this :point_down:\nGPT-3 is basically Eliza, but with the whole internet to plagiarise from.\nAsk any conversation generator a moral question and watch it expose its inner workings.\n\nPeople with poor understanding of machines are easily fooled by convincing automata. <https://twitter.com/Grady_Booch/status/1284196434078650368>",
                "service_name": "twitter",
                "service_url": "https://twitter.com/",
                "from_url": "https://twitter.com/Jon_Ayre/status/1284417918260981760?s=20",
                "id": 1,
                "original_url": "https://twitter.com/Jon_Ayre/status/1284417918260981760?s=20",
                "footer": "Twitter",
                "footer_icon": "https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"
            },
            {
                "fallback": "<https://twitter.com/Grady_Booch|@Grady_Booch>: <https://twitter.com/mckaywrigley|@mckaywrigley> So was Eliza. Fifty years ago.",
                "ts": 1595011263,
                "author_name": "Grady Booch",
                "author_link": "https://twitter.com/Grady_Booch/status/1284196434078650368",
                "author_icon": "https://pbs.twimg.com/profile_images/956424432553046016/eHxjBbEw_normal.jpg",
                "author_subname": "@Grady_Booch",
                "text": "<https://twitter.com/mckaywrigley|@mckaywrigley> So was Eliza. Fifty years ago.",
                "service_name": "twitter",
                "service_url": "https://twitter.com/",
                "from_url": "https://twitter.com/Grady_Booch/status/1284196434078650368",
                "indent": true,
                "color": "32BBF3",
                "id": 2,
                "footer": "Twitter",
                "footer_icon": "https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "71IqU",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I don\u2019t know enough AI but my friend after reading the paper is like there isn\u2019t a fundamental breakthrough, just a bigger model + concerns it doesn\u2019t scale past what it currently is. And comments like "
                            },
                            {
                                "type": "link",
                                "url": "https://twitter.com/Jon_Ayre/status/1284417918260981760?s=20",
                                "text": "https://twitter.com/Jon_Ayre/status/1284417918260981760?s=20"
                            },
                            {
                                "type": "text",
                                "text": " . AI hype is to me like the boy the cried wolf tbh. Doesn\u2019t mean this won\u2019t be useful but I guess like they say time will tell "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG",
        "reactions": [
            {
                "name": "cake",
                "users": [
                    "UC2A2ARPT",
                    "UA14TGLTC",
                    "UU45NNMHT"
                ],
                "count": 3
            }
        ]
    },
    {
        "client_msg_id": "f06c0082-18e4-4760-ae89-dc9bfe3d2c14",
        "type": "message",
        "text": "Exactly, it\u2019s just generating from trained tokens and relationships, it doesn\u2019t have an understanding of anything it\u2019s writing.",
        "user": "UNBPP291C",
        "ts": "1595159554.487500",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UNBPP291C",
            "ts": "1595159670.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "lIHtn",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Exactly, it\u2019s just generating from trained tokens and relationships, it doesn\u2019t have an understanding of anything it\u2019s writing."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "9a3cc8e4-59d1-4cae-9bfa-6da73f8ee3f6",
        "type": "message",
        "text": "&gt; [...] it doesn\u2019t have an understanding of anything it\u2019s writing.\nThat's an _exceptionally_ high bar to set. We have no clue where to start from in building an artificial consciousness. Alan Turing attempted this and while his result was not artificial consciousness (as far as we know :P), he still gave us computers.",
        "user": "UP28ETUSE",
        "ts": "1595162634.487800",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UP28ETUSE",
            "ts": "1595162652.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "fEyp",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "[...] it doesn\u2019t have an understanding of anything it\u2019s writing."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "That's an "
                            },
                            {
                                "type": "text",
                                "text": "exceptionally",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " high bar to set. We have no clue where to start from in building an artificial consciousness. Alan Turing attempted this and while his result was not artificial consciousness (as far as we know :P), he still gave us computers."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "3692E8E8-28D0-4FA3-96D8-98B7B5C82D2D",
        "type": "message",
        "text": "Can somebody explain to me what \u201cunderstanding\u201d means? So machines are basically just trained on patterns\u2026 how exactly are humans different\u2026?",
        "user": "U5STGTB3J",
        "ts": "1595166896.491300",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "WOu",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Can somebody explain to me what \u201cunderstanding\u201d means? So machines are basically just trained on patterns\u2026 how exactly are humans different\u2026?"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG",
        "reactions": [
            {
                "name": "joy",
                "users": [
                    "UA14TGLTC"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "B14358D1-C41A-42CD-B87F-55EFBC3B0568",
        "type": "message",
        "text": "That\u2019s half meant as a funny remark and half as a serious question.",
        "user": "U5STGTB3J",
        "ts": "1595166939.492000",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Kndn",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "That\u2019s half meant as a funny remark and half as a serious question."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "175a4d3f-71db-437e-ae15-d71dbc9b767a",
        "type": "message",
        "text": "This will get philosophical, but so is your question. So, for me, understanding is just a sensation, a quale (<https://en.wikipedia.org/wiki/Qualia>). Some people have the sensation of understanding something, but they don't; some don't have it but they do. This already begs the question how do we know that they actually understand the right thing? How can anyone be a judge of that, and I presume the answer is Popper's scientific method \u2014 unless otherwise proven false, it's probably true (things can get more complicated than that, but I guess that's the gist of it). So in the end understanding is part of qualia, which we really don't know what they're made of.",
        "user": "UP28ETUSE",
        "ts": "1595168861.492200",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "fQdGF",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "This will get philosophical, but so is your question. So, for me, understanding is just a sensation, a quale ("
                            },
                            {
                                "type": "link",
                                "url": "https://en.wikipedia.org/wiki/Qualia"
                            },
                            {
                                "type": "text",
                                "text": "). Some people have the sensation of understanding something, but they don't; some don't have it but they do. This already begs the question how do we know that they actually understand the right thing? How can anyone be a judge of that, and I presume the answer is Popper's scientific method \u2014 unless otherwise proven false, it's probably true (things can get more complicated than that, but I guess that's the gist of it). So in the end understanding is part of qualia, which we really don't know what they're made of."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U8A5MS6R1"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "a5f2cb48-1762-4d1e-9c79-6965b2637f3f",
        "type": "message",
        "text": "Just to give a bit more detail for people unfamiliar with qualia, the typical example given is the sensation of seeing red. That's a quale. We can have computers recognize red, but we _presume_ they don't actually have a _sensation_ of seeing red. My point is that it's the same for understanding.",
        "user": "UP28ETUSE",
        "ts": "1595168986.492400",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UP28ETUSE",
            "ts": "1595169208.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "x0LZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Just to give a bit more detail for people unfamiliar with qualia, the typical example given is the sensation of seeing red. That's a quale. We can have computers recognize red, but we "
                            },
                            {
                                "type": "text",
                                "text": "presume",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " they don't actually have a "
                            },
                            {
                                "type": "text",
                                "text": "sensation",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " of seeing red. My point is that it's the same for understanding."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "1b931eb4-f043-4cf3-8f4a-6ce77f92c84b",
        "type": "message",
        "text": "Python docstrings are smirking at this :D",
        "user": "UP28ETUSE",
        "ts": "1595169165.492600",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "=VimO",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Python docstrings are smirking at this :D"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595138454.472900",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "8e3510e9-a5ad-4331-9296-baade029c60e",
        "type": "message",
        "text": "This is something that is explored extensively in philosophy of mind, obvious with lots of different opinions on the issue. I think one useful starting point is Searle's Chinese Room argument. I'd really recommend actually reading the paper if you are interested in the topic. <http://cogprints.org/7150/1/10.1.1.83.5248.pdf|http://cogprints.org/7150/1/10.1.1.83.5248.pdf>",
        "user": "UK3LH8CF5",
        "ts": "1595169217.492900",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "8ylJ7",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "This is something that is explored extensively in philosophy of mind, obvious with lots of different opinions on the issue. I think one useful starting point is Searle's Chinese Room argument. I'd really recommend actually reading the paper if you are interested in the topic. "
                            },
                            {
                                "type": "link",
                                "url": "http://cogprints.org/7150/1/10.1.1.83.5248.pdf",
                                "text": "http://cogprints.org/7150/1/10.1.1.83.5248.pdf"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "26af6619-e80c-4d05-bbd2-2f3f9fdccf22",
        "type": "message",
        "text": "I haven't read Searle's paper yet, but I found Scott Aaronson's discussion around it, and other similar ideas, facinating: Why Philosophers Should Care About Computational Complexity <https://www.scottaaronson.com/papers/philos.pdf>",
        "user": "UP28ETUSE",
        "ts": "1595169459.493100",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "70oEj",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I haven't read Searle's paper yet, but I found Scott Aaronson's discussion around it, and other similar ideas, facinating: Why Philosophers Should Care About Computational Complexity "
                            },
                            {
                                "type": "link",
                                "url": "https://www.scottaaronson.com/papers/philos.pdf"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "c55cb07e-308c-463f-a6f2-cb875bcb005f",
        "type": "message",
        "text": "Uh, I didn't want to derail this thread, but I do see that that's on me, as my question clearly was too philosophical.\n\nMy intention was to point out that while GPT-3 seems \"obviously inferior\" in its current incarnation, things like that are often said just looking at the technology, but not looking at ourselves. We don't really know how understanding works. And I don't mean the philosophical angle (what understanding is), but the cognitive science perspective.\n\nOur theories about how the brain works have evolved quite a bit, even though there's still lots more left to discover, but I'm not so sure that our cognitive processes are so \"obviously superior\" to what GTP-3 does. That doesn't mean that I believe we're close to AGI either, I'm just trying to raise awareness that to compare machine capabilities to our own, we can't just look at technology alone, but also need to advance the understanding of ourselves.",
        "user": "U5STGTB3J",
        "ts": "1595175436.493600",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "koJrI",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Uh, I didn't want to derail this thread, but I do see that that's on me, as my question clearly was too philosophical.\n\nMy intention was to point out that while GPT-3 seems \"obviously inferior\" in its current incarnation, things like that are often said just looking at the technology, but not looking at ourselves. We don't really know how understanding works. And I don't mean the philosophical angle (what understanding is), but the cognitive science perspective.\n\nOur theories about how the brain works have evolved quite a bit, even though there's still lots more left to discover, but I'm not so sure that our cognitive processes are so \"obviously superior\" to what GTP-3 does. That doesn't mean that I believe we're close to AGI either, I'm just trying to raise awareness that to compare machine capabilities to our own, we can't just look at technology alone, but also need to advance the understanding of ourselves."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "c2a9cd16-a50a-420a-8185-9bf38e769e52",
        "type": "message",
        "text": "I'm not sure what contrast you are making between the philosophical angle and the cognitive science angle. Those are rather connected. \n\nUnderstanding how the brain works more does not necessarily get us to understand how understanding works. Even if it did though, translating from the brains neural circuits with their causal mechanisms to software based syntatic simulation doesn't guarantee there is understanding.\n\nSearle's view is that those neuronal causal firing are necessary. In other words hardware based AI is possible, but not software. Or put anything way, no amount of syntatic manipulation gives you semantics. Of course others disagree. Lots of cognitive scientist/philosophers just don't believe there is anything like understanding at all. \n\nYou might not be interested in any of this and that is okay. But I think these crucial if we want to create some ai with actual understanding.",
        "user": "UK3LH8CF5",
        "ts": "1595176096.494000",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "8vjnX",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'm not sure what contrast you are making between the philosophical angle and the cognitive science angle. Those are rather connected. \n\nUnderstanding how the brain works more does not necessarily get us to understand how understanding works. Even if it did though, translating from the brains neural circuits with their causal mechanisms to software based syntatic simulation doesn't guarantee there is understanding.\n\nSearle's view is that those neuronal causal firing are necessary. In other words hardware based AI is possible, but not software. Or put anything way, no amount of syntatic manipulation gives you semantics. Of course others disagree. Lots of cognitive scientist/philosophers just don't believe there is anything like understanding at all. \n\nYou might not be interested in any of this and that is okay. But I think these crucial if we want to create some ai with actual understanding."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG",
        "reactions": [
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UP28ETUSE"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "aee5a052-c1ee-40ea-ade1-7893c7c61431",
        "type": "message",
        "text": "When I look at GPT-3, I don't see a big step toward AGI. As ever, people are tripping over the fact that \"AI\" is a tragically poor term for this kind of technology, and are (IMO) wasting a lot of time asking what this _means_. Rather, what I see in GPT-2/3, and large-scale ML models generally, is an interesting new kind of tool that we have yet to find all the various uses for. It joins an esteemed family of breakthrough enabling technologies like the mouse+GUI, the internet, the GPU, GPS, etc. (though perhaps not quite at that tier). The philosophical implications of it are interesting, but very much in the same way that the philosophical implications of the mouse + GUI, or long-distance communication, are interesting. What _is_ exciting about it is that we now get to collectively discover all the neat new things we can do with it. We're going to find how it is a tool. Maybe we also find how it reflects on our own minds, but as others have said, I think likening one to the other is a category error.\n\nTo further what Ian said,\n\n&gt; it doesn\u2019t have an understanding of anything it\u2019s writing.\nI would say: Nobody should expect it to have anything that could be described as _understanding_. It doesn't need to have understanding to be interesting.\n\n/2\u00a2",
        "user": "UC2A2ARPT",
        "ts": "1595176751.494300",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UC2A2ARPT",
            "ts": "1595177216.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "FRV",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "When I look at GPT-3, I don't see a big step toward AGI. As ever, people are tripping over the fact that \"AI\" is a tragically poor term for this kind of technology, and are (IMO) wasting a lot of time asking what this "
                            },
                            {
                                "type": "text",
                                "text": "means",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". Rather, what I see in GPT-2/3, and large-scale ML models generally, is an interesting new kind of tool that we have yet to find all the various uses for. It joins an esteemed family of breakthrough enabling technologies like the mouse+GUI, the internet, the GPU, GPS, etc. (though perhaps not quite at that tier). The philosophical implications of it are interesting, but very much in the same way that the philosophical implications of the mouse + GUI, or long-distance communication, are interesting. What "
                            },
                            {
                                "type": "text",
                                "text": "is",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " exciting about it is that we now get to collectively discover all the neat new things we can do with it. We're going to find how it is a tool. Maybe we also find how it reflects on our own minds, but as others have said, I think likening one to the other is a category error.\n\nTo further what Ian said,\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "it doesn\u2019t have an understanding of anything it\u2019s writing."
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nI would say: Nobody should expect it to have anything that could be described as "
                            },
                            {
                                "type": "text",
                                "text": "understanding",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". It doesn't need to have understanding to be interesting.\n\n/2\u00a2"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UKP3B2J5D",
                    "UETJZ9V0T",
                    "UHWC9PXBL",
                    "UJ6LDMMN0",
                    "UA14TGLTC"
                ],
                "count": 5
            },
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UJ6LDMMN0",
                    "ULK0Z4MPV"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "c665de63-04f3-42e0-9f2e-f4a1f3a642ac",
        "type": "message",
        "text": "As an addendum \u2014 I find GPT-3 _fascinating_ and I'm very excited to see what people do with it. It feels bursting with potential.",
        "user": "UC2A2ARPT",
        "ts": "1595177301.495500",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "N/m8",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "As an addendum \u2014 I find GPT-3 "
                            },
                            {
                                "type": "text",
                                "text": "fascinating",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " and I'm very excited to see what people do with it. It feels bursting with potential."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "6A154714-D584-4B57-88A8-4C25A6690678",
        "type": "message",
        "text": "on the treecology metaphors, how about a tree colony: <https://www.atlasobscura.com/places/pando-the-trembling-giant|https://www.atlasobscura.com/places/pando-the-trembling-giant> ",
        "user": "UHWC9PXBL",
        "ts": "1595183667.497200",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "service_name": "Atlas Obscura",
                "title": "Pando, the Trembling Giant",
                "title_link": "https://www.atlasobscura.com/places/pando-the-trembling-giant",
                "text": "One of the world's oldest and most massive living organisms is a grove of quaking aspens.",
                "fallback": "Atlas Obscura: Pando, the Trembling Giant",
                "image_url": "https://assets.atlasobscura.com/media/W1siZiIsInVwbG9hZHMvcGxhY2VfaW1hZ2VzLzg1MmY3MGYzNTI4YjhkOGNkM19wYW5kb3RyZWUxLmpwZyJdLFsicCIsImNvbnZlcnQiLCIiXSxbInAiLCJjb252ZXJ0IiwiLXF1YWxpdHkgODEgLWF1dG8tb3JpZW50Il0sWyJwIiwidGh1bWIiLCI2MDB4PiJdXQ",
                "from_url": "https://www.atlasobscura.com/places/pando-the-trembling-giant",
                "image_width": 378,
                "image_height": 250,
                "image_bytes": 122333,
                "service_icon": "https://assets.atlasobscura.com/media/W1siZnUiLCJodHRwczovL3MzLmFtYXpvbmF3cy5jb20vYXRsYXMtZGV2L21pc2MvaWNvbnMvYXBwbGUtdG91Y2gtaWNvbi5wbmciXSxbInAiLCJjb252ZXJ0IiwiLXF1YWxpdHkgODEgLXN0cmlwIl1d/apple-touch-icon.png",
                "id": 1,
                "original_url": "https://www.atlasobscura.com/places/pando-the-trembling-giant"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "upGaf",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "on the treecology metaphors, how about a tree colony: "
                            },
                            {
                                "type": "link",
                                "url": "https://www.atlasobscura.com/places/pando-the-trembling-giant",
                                "text": "https://www.atlasobscura.com/places/pando-the-trembling-giant"
                            },
                            {
                                "type": "text",
                                "text": " "
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595017818.433700",
        "parent_user_id": "U015902ESJC"
    },
    {
        "client_msg_id": "EAAD1414-25F1-4868-ADD7-5300A0CEAD5F",
        "type": "message",
        "text": "<@UT9TWSZB5> in case you didn\u2019t see this",
        "user": "UHWC9PXBL",
        "ts": "1595183706.498200",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "EsF",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UT9TWSZB5"
                            },
                            {
                                "type": "text",
                                "text": " in case you didn\u2019t see this"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595084261.455800",
        "parent_user_id": "USH01JEDQ"
    },
    {
        "client_msg_id": "bac5f87c-5a06-451d-ba9c-f4d6e7cf2588",
        "type": "message",
        "text": "Max Woolfe has a good blog post about tempered expectations <https://minimaxir.com/2020/07/gpt3-expectations/|https://minimaxir.com/2020/07/gpt3-expectations/>",
        "user": "UBSMEUXAA",
        "ts": "1595188557.499200",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "service_name": "Max Woolf's Blog",
                "title": "Tempering Expectations for GPT-3 and OpenAI\u2019s API",
                "title_link": "https://minimaxir.com/2020/07/gpt3-expectations/",
                "text": "GPT-3 is indeed a large step forward for AI text-generation, but there are very many caveats with the popular demos and use cases.",
                "fallback": "Max Woolf's Blog: Tempering Expectations for GPT-3 and OpenAI\u2019s API",
                "image_url": "https://minimaxir.com/2020/07/gpt3-expectations/featured.png",
                "ts": 1595093400,
                "from_url": "https://minimaxir.com/2020/07/gpt3-expectations/",
                "image_width": 582,
                "image_height": 250,
                "image_bytes": 90327,
                "id": 1,
                "original_url": "https://minimaxir.com/2020/07/gpt3-expectations/"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "+qd",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Max Woolfe has a good blog post about tempered expectations "
                            },
                            {
                                "type": "link",
                                "url": "https://minimaxir.com/2020/07/gpt3-expectations/",
                                "text": "https://minimaxir.com/2020/07/gpt3-expectations/"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "d9b3582b-723b-43d4-919c-d1b2aacde273",
        "type": "message",
        "text": "A lot of the GPT-3 criticisms are that it's \"just\" a generative text model with a lot of data, but I think it also minimizes the usefulness and th interesting properties of generative text models",
        "user": "UBSMEUXAA",
        "ts": "1595189012.499500",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "X6o",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "A lot of the GPT-3 criticisms are that it's \"just\" a generative text model with a lot of data, but I think it also minimizes the usefulness and th interesting properties of generative text models"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UKP3B2J5D",
                    "UC2A2ARPT"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "adcd8ac1-7d64-44bd-bd9e-cbfc6d72a8a5",
        "type": "message",
        "text": "We really don't need it to be AGI, or a precursor to AGI to be useful, Everest Pipkin had a pretty good take <https://twitter.com/everestpipkin/status/1284524605525446656?s=19|https://twitter.com/everestpipkin/status/1284524605525446656?s=19>",
        "user": "UBSMEUXAA",
        "ts": "1595189178.499700",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "fallback": "<https://twitter.com/everestpipkin|@everestpipkin>: listen.... ... the text / code / etc generation from GPT-3 *is* super impressive but you have you remember its basically just a real good search engine",
                "ts": 1595089505,
                "author_name": "everest",
                "author_link": "https://twitter.com/everestpipkin/status/1284524605525446656",
                "author_icon": "https://pbs.twimg.com/profile_images/1136338476826222592/KjpOXa7E_normal.png",
                "author_subname": "@everestpipkin",
                "text": "listen.... ... the text / code / etc generation from GPT-3 *is* super impressive but you have you remember its basically just a real good search engine",
                "service_name": "twitter",
                "service_url": "https://twitter.com/",
                "from_url": "https://twitter.com/everestpipkin/status/1284524605525446656?s=19",
                "id": 1,
                "original_url": "https://twitter.com/everestpipkin/status/1284524605525446656?s=19",
                "footer": "Twitter",
                "footer_icon": "https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "elE",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "We really don't need it to be AGI, or a precursor to AGI to be useful, Everest Pipkin had a pretty good take "
                            },
                            {
                                "type": "link",
                                "url": "https://twitter.com/everestpipkin/status/1284524605525446656?s=19",
                                "text": "https://twitter.com/everestpipkin/status/1284524605525446656?s=19"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "386eba74-7257-474c-b713-de4cbaba30e1",
        "type": "message",
        "text": "Real good search engine of course is a little bit of a stretch",
        "user": "UBSMEUXAA",
        "ts": "1595189265.000000",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "nGUF",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Real good search engine of course is a little bit of a stretch"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "846a5b9f-2b87-4076-85d2-401e17ad4234",
        "type": "message",
        "text": "I guess it could be considered a probalistic search engine, you're searching a distribution instead of searching speaking data, they wanted links back to the dataset, I guess this would involve assigning weights or some vector to source data and ranking it based on influence in the generated text, not sure how feasible that is with transformers but it's a cool idea",
        "user": "UBSMEUXAA",
        "ts": "1595189565.000200",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "e4zZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I guess it could be considered a probalistic search engine, you're searching a distribution instead of searching speaking data, they wanted links back to the dataset, I guess this would involve assigning weights or some vector to source data and ranking it based on influence in the generated text, not sure how feasible that is with transformers but it's a cool idea"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "4ae49d8a-8c75-46f9-b0d2-60d2ccbb63b7",
        "type": "message",
        "text": "From what I see as reactions, people seem to think it understand the code it\u2019s writing for example or what the text is about.\n\n\u201cUnderstanding\u201d means the ability to recognize an object/pattern in multiple dimensions and thus have a subjective representation of the object/pattern ( which works into prediction skills that are needed to survive in the world ) and know it\u2019s relations to it\u2019s context.\n\nGPT-3 is 2.5D, we need nD.\nN \u201cmodels\u201d which constantly self-optimise,minimise and grow under control of 2 agents - internal &amp; external.\n\nBut I agree with <@UBSMEUXAA>, IMO the best way to use it for code generation \u201cis a probalistic search engine\u201d. If someone trained it to write a minor part of the code where \u201cbranches\u201d connect, it could be super useful, but we\u2019d still need a different access to writing code. For now, it could be a great autocomplete.",
        "user": "UNBPP291C",
        "ts": "1595192019.006600",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UNBPP291C",
            "ts": "1595192201.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "BPF2t",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "From what I see as reactions, people seem to think it understand the code it\u2019s writing for example or what the text is about.\n\n\u201cUnderstanding\u201d means the ability to recognize an object/pattern in multiple dimensions and thus have a subjective representation of the object/pattern ( which works into prediction skills that are needed to survive in the world ) and know it\u2019s relations to it\u2019s context.\n\nGPT-3 is 2.5D, we need nD.\nN \u201cmodels\u201d which constantly self-optimise,minimise and grow under control of 2 agents - internal & external.\n\nBut I agree with "
                            },
                            {
                                "type": "user",
                                "user_id": "UBSMEUXAA"
                            },
                            {
                                "type": "text",
                                "text": ", IMO the best way to use it for code generation \u201cis a probalistic search engine\u201d. If someone trained it to write a minor part of the code where \u201cbranches\u201d connect, it could be super useful, but we\u2019d still need a different access to writing code. For now, it could be a great autocomplete."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG",
        "reactions": [
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UKP3B2J5D"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "AB5B93E6-6041-4598-93E8-F498B0470297",
        "type": "message",
        "text": "<@UK3LH8CF5> In philosophy you have epistemology and metaphysics and argue about what understanding \u201cmeans\u201d, what meaning is, what truth is, etc. And there are lots of positions to take and that has all kinds of implications on your world view: realism, objectivism, internalism, experientialism, etc.\n\nWhat I consider somewhat separate from that (and put in the cognitive science bucket) is the part where we figure out how the activity of thinking manifests in the brain, things like embodiment, image schemas, metaphorical structuring and their neural modeling, etc.\n\nIn a way you made a similar distinction yourself when you say \u201c_Understanding how the brain works more does not necessarily get us to understand how understanding works_\u201d \u2014 I agree and somehow think that is almost the point I was making, albeit you phrased it much better.\n\nAnd yet of course these are all interdependent, and what I\u2019m trying to point out is that there are lots of technologists who do not look at philosophy or cognitive science (and therefore likely base their thinking probably on outdated and/or folk theories) and still have strong opinions on how close GPT-3 is to AGI or not.\n\nI don\u2019t understand the connection to the rest of your comment and I'm confused about where your assumption that I might not be interested comes from.",
        "user": "U5STGTB3J",
        "ts": "1595194466.021500",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "dkVy",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UK3LH8CF5"
                            },
                            {
                                "type": "text",
                                "text": " In philosophy you have epistemology and metaphysics and argue about what understanding \u201cmeans\u201d, what meaning is, what truth is, etc. And there are lots of positions to take and that has all kinds of implications on your world view: realism, objectivism, internalism, experientialism, etc.\n\nWhat I consider somewhat separate from that (and put in the cognitive science bucket) is the part where we figure out how the activity of thinking manifests in the brain, things like embodiment, image schemas, metaphorical structuring and their neural modeling, etc.\n\n"
                            },
                            {
                                "type": "text",
                                "text": "In a way you made a similar distinction yourself when you say \u201c"
                            },
                            {
                                "type": "text",
                                "text": "Understanding how the brain works more does not necessarily get us to understand how understanding works",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "\u201d \u2014 I agree and somehow think that is almost the point I was making, albeit you phrased it much better.\n"
                            },
                            {
                                "type": "text",
                                "text": "\nAnd yet of course these are all interdependent, and what I\u2019m trying to point out is that there are lots of technologists who do not look at philosophy or cognitive science (and therefore likely base their thinking probably on outdated and/or folk theories) and still have strong opinions on how close GPT-3 is to AGI or not.\n\n"
                            },
                            {
                                "type": "text",
                                "text": "I don\u2019t understand the connection to the rest of your comment and I'm confused about where your assumption that I might not be interested comes from."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "1be4a7dd-5962-4f81-8521-6cc57b363cd6",
        "type": "message",
        "text": "&gt; Can somebody explain to me what \u201cunderstanding\u201d means? So machines are basically just trained on patterns\u2026 how exactly are humans different\u2026?\n&gt; \nThis is the question I was originally trying to address. Are humans any different than machines? Can we just continue to make better models and achieve understanding or consciousness or intelligence? Studying the brain doesn't give us answers to those questions.\n\nI am glad to hear that you are interested in it. It is probably just a bias that I've picked up where many people are against philosophy.\n\n&gt; there are lots of technologists who do not look at philosophy or cognitive science (and therefore likely base their thinking probably on outdated and/or folk theories) and still have strong opinions on how close GPT-3 is to AGI or not.\n&gt; \nI guess what I was trying to get at is I don't think those views are grounded. The question of even determining if something we created has true understanding, is actually intelligent, or has consciousness is a hard question. In fact, Ned Block calls that the Harder Problem of consciousness.",
        "user": "UK3LH8CF5",
        "ts": "1595195478.021700",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UK3LH8CF5",
            "ts": "1595201263.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "lBN",
                "elements": [
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Can somebody explain to me what \u201cunderstanding\u201d means? So machines are basically just trained on patterns\u2026 how exactly are humans different\u2026?\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "This is the question I was originally trying to address. Are humans any different than machines? Can we just continue to make better models and achieve understanding or consciousness or intelligence? Studying the brain doesn't give us answers to those questions.\n\nI am glad to hear that you are interested in it. It is probably just a bias that I've picked up where many people are against philosophy.\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "there are lots of technologists who do not look at philosophy or cognitive science (and therefore likely base their thinking probably on outdated and/or folk theories) and still have strong opinions on how close GPT-3 is to AGI or not.\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I guess what I was trying to get at is I don't think those views are grounded. The question of even determining if something we created has true understanding, is actually intelligent, or has consciousness is a hard question. In fact, Ned Block calls that the Harder Problem of consciousness."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U5STGTB3J"
                ],
                "count": 1
            }
        ]
    }
]