[
    {
        "client_msg_id": "2ff0fb87-fa39-41af-93c9-d2d26982e10d",
        "type": "message",
        "text": "I'm curious to hear more about Pulumi. I had a similar question after looking at Hashicorp's Terraform CDK over the weekend: what's the point? It has to emit a static configuration. JSON basically. What does having a general-purpose PL buy you if you can't add a loop or conditional to the output? Pulumi seems the same, going by tutorials like <https://www.pulumi.com/docs/tutorials/aws/ec2-webserver>. Can someone point me at a more complex scenario that it can handle?\n\nI'd like to create a host, then monitor its health for 60 seconds before creating a second identical host. Does Pulumi or any other infrastructure-as-code allow me to do that? If I'm reading it right, the declarative-code article above has the same issues with Pulumi.",
        "user": "UCUSW7WVD",
        "ts": "1595214607.023700",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UCUSW7WVD",
            "ts": "1595214683.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "qjWM",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'm curious to hear more about Pulumi. I had a similar question after looking at Hashicorp's Terraform CDK over the weekend: what's the point? It has to emit a static configuration. JSON basically. What does having a general-purpose PL buy you if you can't add a loop or conditional to the output? Pulumi seems the same, going by tutorials like "
                            },
                            {
                                "type": "link",
                                "url": "https://www.pulumi.com/docs/tutorials/aws/ec2-webserver"
                            },
                            {
                                "type": "text",
                                "text": ". Can someone point me at a more complex scenario that it can handle?\n\nI'd like to create a host, then monitor its health for 60 seconds before creating a second identical host. Does Pulumi or any other infrastructure-as-code allow me to do that? If I'm reading it right, the declarative-code article above has the same issues with Pulumi."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595084421.458800",
        "parent_user_id": "UKP3B2J5D"
    },
    {
        "client_msg_id": "172a9009-c5a3-42bf-80df-6077a69c277a",
        "type": "message",
        "text": "Probably asked before but, what is your go-to tool for the implementation of a language prototype in terms of parsing, compiling, etc? Language, library, generator...?",
        "user": "U010328JA1E",
        "ts": "1595219570.025900",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "3v1ON",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Probably asked before but, what is your go-to tool for the implementation of a language prototype in terms of parsing, compiling, etc? Language, library, generator...?"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595219570.025900",
        "reply_count": 12,
        "reply_users_count": 7,
        "latest_reply": "1595265341.054500",
        "reply_users": [
            "UT9TWSZB5",
            "UN9SCH5RD",
            "UUQ2EQW21",
            "U013ZLJARC7",
            "UBN9AFS0N",
            "UNBPP291C",
            "UJN1TAYEQ"
        ],
        "subscribed": true,
        "last_read": "1595265341.054500",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "AF2CCB0F-A81D-4BA4-B569-0C2978C11E14",
        "type": "message",
        "text": "For me, prototype = typescript. Parsimmon is a great parsing library to start with. Or if you feel fancy you can check out ohm which is a compiler-compiler. ",
        "user": "UT9TWSZB5",
        "ts": "1595219950.027400",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "NbcHj",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "For me, prototype = typescript. Parsimmon is a great parsing library to start with. Or if you feel fancy you can check out ohm which is a compiler-compiler. "
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595219570.025900",
        "parent_user_id": "U010328JA1E",
        "reactions": [
            {
                "name": "ok_hand",
                "users": [
                    "U010328JA1E"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "2E94B8B8-DDCA-4B70-B396-C253ED66AA1B",
        "type": "message",
        "text": "<https://github.com/harc/ohm|https://github.com/harc/ohm>",
        "user": "UT9TWSZB5",
        "ts": "1595219972.027700",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "fallback": "harc/ohm",
                "text": "A library and language for building parsers, interpreters, compilers, etc.",
                "title": "harc/ohm",
                "footer": "<https://github.com/harc/ohm|harc/ohm>",
                "id": 1,
                "footer_icon": "https://github.githubassets.com/favicon.ico",
                "ts": 1432222934,
                "color": "24292f",
                "fields": [
                    {
                        "title": "Stars",
                        "value": "2467",
                        "short": true
                    },
                    {
                        "title": "Language",
                        "value": "JavaScript",
                        "short": true
                    }
                ],
                "mrkdwn_in": [
                    "text",
                    "fields"
                ],
                "bot_id": "B011KHY4N3Y",
                "app_unfurl_url": "https://github.com/harc/ohm",
                "is_app_unfurl": true
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "LEfk",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "link",
                                "url": "https://github.com/harc/ohm",
                                "text": "https://github.com/harc/ohm"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595219570.025900",
        "parent_user_id": "U010328JA1E"
    },
    {
        "client_msg_id": "4EC8F492-D429-4599-A7C7-8ABFD5B1461E",
        "type": "message",
        "text": "Meta 2 is a really cool paper about compiler-compilers btw. Here\u2019s a nice overview: <https://youtu.be/L1rwVBLHGiU|https://youtu.be/L1rwVBLHGiU>",
        "user": "UT9TWSZB5",
        "ts": "1595220048.028900",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "service_name": "YouTube",
                "service_url": "https://www.youtube.com/",
                "title": "META II: A Syntax-Oriented Compiler Writing Language - Papers We Love Singapore",
                "title_link": "https://youtu.be/L1rwVBLHGiU",
                "author_name": "Engineers.SG",
                "author_link": "https://www.youtube.com/channel/UCjRZr5HQKHVKP3SZdX8y8Qw",
                "thumb_url": "https://i.ytimg.com/vi/L1rwVBLHGiU/hqdefault.jpg",
                "thumb_width": 480,
                "thumb_height": 360,
                "fallback": "YouTube Video: META II: A Syntax-Oriented Compiler Writing Language - Papers We Love Singapore",
                "video_html": "<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/L1rwVBLHGiU?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>",
                "video_html_width": 400,
                "video_html_height": 225,
                "from_url": "https://youtu.be/L1rwVBLHGiU",
                "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png",
                "id": 1,
                "original_url": "https://youtu.be/L1rwVBLHGiU"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "c/9",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Meta 2 is a really cool paper about compiler-compilers btw. Here\u2019s a nice overview: "
                            },
                            {
                                "type": "link",
                                "url": "https://youtu.be/L1rwVBLHGiU",
                                "text": "https://youtu.be/L1rwVBLHGiU"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595219570.025900",
        "parent_user_id": "U010328JA1E",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U013ZLJARC7"
                ],
                "count": 1
            },
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UJ6LDMMN0"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "7469fedc-46bc-4121-a694-b07c42cc264c",
        "type": "message",
        "text": "I think I'll try instaparse for my next experiment <https://github.com/Engelberg/instaparse> and <https://github.com/noprompt/meander> to manipulate the parse tree",
        "user": "UN9SCH5RD",
        "ts": "1595222597.029500",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "fallback": "Engelberg/instaparse",
                "title": "Engelberg/instaparse",
                "footer": "<https://github.com/Engelberg/instaparse|Engelberg/instaparse>",
                "id": 1,
                "footer_icon": "https://github.githubassets.com/favicon.ico",
                "ts": 1359875974,
                "color": "24292f",
                "fields": [
                    {
                        "title": "Stars",
                        "value": "2301",
                        "short": true
                    },
                    {
                        "title": "Language",
                        "value": "Clojure",
                        "short": true
                    }
                ],
                "mrkdwn_in": [
                    "text",
                    "fields"
                ],
                "bot_id": "B011KHY4N3Y",
                "app_unfurl_url": "https://github.com/Engelberg/instaparse",
                "is_app_unfurl": true
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "O9qyD",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I think I'll try instaparse for my next experiment "
                            },
                            {
                                "type": "link",
                                "url": "https://github.com/Engelberg/instaparse"
                            },
                            {
                                "type": "text",
                                "text": " and "
                            },
                            {
                                "type": "link",
                                "url": "https://github.com/noprompt/meander"
                            },
                            {
                                "type": "text",
                                "text": " to manipulate the parse tree"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595219570.025900",
        "parent_user_id": "U010328JA1E"
    },
    {
        "client_msg_id": "e256c4ab-c382-4078-b755-55bef227c86e",
        "type": "message",
        "text": "If you are not sure about clojure for language implementation this talk might be interesting for you: <https://www.youtube.com/watch?v=t8usj1fN9rs> (since strictly typed languages are often considered \"the best\" for compiler work)",
        "user": "UN9SCH5RD",
        "ts": "1595222683.029900",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "service_name": "YouTube",
                "service_url": "https://www.youtube.com/",
                "title": "The Language of the Language: Comparing compiler construction in Clojure and F# - Ramsey Nasser",
                "title_link": "https://www.youtube.com/watch?v=t8usj1fN9rs",
                "author_name": "Clojure/north",
                "author_link": "https://www.youtube.com/channel/UClJshc6QtMWRqIAwJy85sfA",
                "thumb_url": "https://i.ytimg.com/vi/t8usj1fN9rs/hqdefault.jpg",
                "thumb_width": 480,
                "thumb_height": 360,
                "fallback": "YouTube Video: The Language of the Language: Comparing compiler construction in Clojure and F# - Ramsey Nasser",
                "video_html": "<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/t8usj1fN9rs?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>",
                "video_html_width": 400,
                "video_html_height": 225,
                "from_url": "https://www.youtube.com/watch?v=t8usj1fN9rs",
                "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png",
                "id": 1,
                "original_url": "https://www.youtube.com/watch?v=t8usj1fN9rs"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "utWo9",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "If you are not sure about clojure for language implementation this talk might be interesting for you: "
                            },
                            {
                                "type": "link",
                                "url": "https://www.youtube.com/watch?v=t8usj1fN9rs"
                            },
                            {
                                "type": "text",
                                "text": " (since strictly typed languages are often considered \"the best\" for compiler work)"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595219570.025900",
        "parent_user_id": "U010328JA1E"
    },
    {
        "client_msg_id": "6DE9495D-21A2-43E6-A1B1-8F81F72674EB",
        "type": "message",
        "text": "Whoa. This is really cool! Thanks <@UHWC9PXBL>! \n",
        "user": "UT9TWSZB5",
        "ts": "1595223286.031500",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "YZhv3",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Whoa. This is really cool! Thanks "
                            },
                            {
                                "type": "user",
                                "user_id": "UHWC9PXBL"
                            },
                            {
                                "type": "text",
                                "text": "! \n"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595084261.455800",
        "parent_user_id": "USH01JEDQ"
    },
    {
        "client_msg_id": "53035579-07C7-402F-B3CB-809CF0453304",
        "type": "message",
        "text": "I\u2019ve been working in a project involving datalog as a durable database with p2p collaboration and sync. ",
        "user": "UT9TWSZB5",
        "ts": "1595223361.032600",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Rv2hQ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I\u2019ve been working in a project involving datalog as a durable database with p2p collaboration and sync. "
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595084261.455800",
        "parent_user_id": "USH01JEDQ"
    },
    {
        "client_msg_id": "bf8940fd-2522-421a-ae42-6e1c30336e81",
        "type": "message",
        "text": "I\u2019ve found this library useful in the past, especially for quick parsing tasks. <https://github.com/orangeduck/mpc>\nLast time I did a language, I rolled my own tokenizer and lexer.  I find things easier to understand that way.  I know that Jonathan Blow\u2019s Jai language uses the same hand rolled approach.",
        "user": "UUQ2EQW21",
        "ts": "1595228708.034300",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "fallback": "orangeduck/mpc",
                "text": "A Parser Combinator library for C",
                "title": "orangeduck/mpc",
                "footer": "<https://github.com/orangeduck/mpc|orangeduck/mpc>",
                "id": 1,
                "footer_icon": "https://github.githubassets.com/favicon.ico",
                "ts": 1380201606,
                "color": "24292f",
                "fields": [
                    {
                        "title": "Stars",
                        "value": "1923",
                        "short": true
                    },
                    {
                        "title": "Language",
                        "value": "C",
                        "short": true
                    }
                ],
                "mrkdwn_in": [
                    "text",
                    "fields"
                ],
                "bot_id": "B011KHY4N3Y",
                "app_unfurl_url": "https://github.com/orangeduck/mpc",
                "is_app_unfurl": true
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "7H1A",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I\u2019ve found this library useful in the past, especially for quick parsing tasks. "
                            },
                            {
                                "type": "link",
                                "url": "https://github.com/orangeduck/mpc"
                            },
                            {
                                "type": "text",
                                "text": "\nLast time I did a language, I rolled my own tokenizer and lexer.  I find things easier to understand that way.  I know that Jonathan Blow\u2019s Jai language uses the same hand rolled approach."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595219570.025900",
        "parent_user_id": "U010328JA1E"
    },
    {
        "client_msg_id": "d302e963-aea6-4f2e-a2af-3d2c46f5e118",
        "type": "message",
        "text": "It has the nice feature of being able to just pass a grammar to the library, and it builds the parser combinators.  Very quick and easy.",
        "user": "UUQ2EQW21",
        "ts": "1595229509.034600",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "16J",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "It has the nice feature of being able to just pass a grammar to the library, and it builds the parser combinators.  Very quick and easy."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595219570.025900",
        "parent_user_id": "U010328JA1E"
    },
    {
        "client_msg_id": "12a571b9-0010-4683-a4bf-346678ee0a94",
        "type": "message",
        "text": "I find the question a bit underspecified, as which tools one might choose will hinge on both the specifics of what one is building and a variety of personal preferences. In my case, I like languages/environments that allow me to develop new semantics from within them, only worrying about adding syntactic affordances later. If one prefers that approach, it's hard to beat <https://racket-lang.org>",
        "user": "U013ZLJARC7",
        "ts": "1595230411.034800",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "CLlN",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I find the question a bit underspecified, as which tools one might choose will hinge on both the specifics of what one is building and a variety of personal preferences. In my case, I like languages/environments that allow me to develop new semantics from within them, only worrying about adding syntactic affordances later. If one prefers that approach, it's hard to beat "
                            },
                            {
                                "type": "link",
                                "url": "https://racket-lang.org"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595219570.025900",
        "parent_user_id": "U010328JA1E",
        "reactions": [
            {
                "name": "heavy_plus_sign",
                "users": [
                    "UP28ETUSE",
                    "UJBAJNFLK"
                ],
                "count": 2
            },
            {
                "name": "heavy_check_mark",
                "users": [
                    "U010328JA1E"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "3dae2973-aaaf-43e2-88b2-e217e74fe769",
        "type": "message",
        "text": "I don't know exactly how Pulimi works, but I have some experience with Terraform (I use it on my last project as a corporate employee).\n\nThe point is that generally you define a desired state and ask Terraform to do all it can to create/modify the corresponding infrastructure. And for that it analyzes your code, checks that everything is OK and proposes you a \"plan\" which describes what Terraform will actually do: create new resource, deleting some others or just modifying some. Terraform then asks you if you want to proceed and then actually do the job. Of course, you can tell to Terraform to apply changes automatically without asking, if you are very confident about you code or don't care to break things, but generally this is desired thing to be asked because of the tricky nature of infrastructure management.\n\nSo I guess the scenario \"create something, wait a bit, create something else\" is not very common and is actually \"not in the spirit\". But if this use case is really needed, if I recall well there are some trick to allow doing this kind of pause. In the definition of the first resource you add a script that sleep 60 seconds, maybe with some monitoring, and make the second resource depends on this resource, which will make Terraform wait the end of the script before creating the second resource. The paradigm is to define resources and dependencies.\n\nFor loops, there is something that allows you to create a set of ressources with a single definition. I used it to generate thousands of VM. In fact you have a series of tools for \"loop/conditionals\" at the language level, but always in a spirit of \"templating\".\n\nBut after a bit of practicing, I felt sometime that I would have prefer to code things with a general purpose language. For things like getting env vars, managing some files, etc. I guess it is what Pulumi is about, and I am very curious about it.",
        "user": "UJ6LDMMN0",
        "ts": "1595232493.035700",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "1Uot",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I don't know exactly how Pulimi works, but I have some experience with Terraform (I use it on my last project as a corporate employee).\n\nThe point is that generally you define a desired state and ask Terraform to do all it can to create/modify the corresponding infrastructure. And for that it analyzes your code, checks that everything is OK and proposes you a \"plan\" which describes what Terraform will actually do: create new resource, deleting some others or just modifying some. Terraform then asks you if you want to proceed and then actually do the job. Of course, you can tell to Terraform to apply changes automatically without asking, if you are very confident about you code or don't care to break things, but generally this is desired thing to be asked because of the tricky nature of infrastructure management.\n\nSo I guess the scenario \"create something, wait a bit, create something else\" is not very common and is actually \"not in the spirit\". But if this use case is really needed, if I recall well there are some trick to allow doing this kind of pause. In the definition of the first resource you add a script that sleep 60 seconds, maybe with some monitoring, and make the second resource depends on this resource, which will make Terraform wait the end of the script before creating the second resource. The paradigm is to define resources and dependencies.\n\nFor loops, there is something that allows you to create a set of ressources with a single definition. I used it to generate thousands of VM. In fact you have a series of tools for \"loop/conditionals\" at the language level, but always in a spirit of \"templating\".\n\nBut after a bit of practicing, I felt sometime that I would have prefer to code things with a general purpose language. For things like getting env vars, managing some files, etc. I guess it is what Pulumi is about, and I am very curious about it."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595084421.458800",
        "parent_user_id": "UKP3B2J5D"
    },
    {
        "client_msg_id": "9f778d77-3555-48a3-b326-bb88d75b6614",
        "type": "message",
        "text": "Pulumi is very much like Terraform, it actually uses the Terraform providers behind the scenes (Pulumi does not generate files, as AWS CDK does). The only major difference is that you declare that desired state using an API of a general purpose language. But otherwise, Pulumi does exactly what <@UJ6LDMMN0> said Terraform does \u2014 keeping that desired state, creating a plan, previewing it, applying it, etc.\n\nRegarding <@UCUSW7WVD>'s problem, I think the solution in Pulumi would be similar to the one in Terrraform. Define a custom resource that does nothing than just block execution for an amount of time and then to the health check, then use this resource as a dependency of the second host you want to create.\n\nGoing back to the original question of whether it would make sense to have a visual editor for k8s config files, I don't think it would help that much. The problem with YAML is not that it's YAML, it's that it offers no means composition and abstraction. With only a visual editor that all it does is to offer affordances for YAML concepts, things will be the same. But, if that visual editors starts adding some PL concepts, such as variables and functions, then it can be useful, but at this point I think it's no longer about YAML or k8s, it's just about structural editors in general.",
        "user": "UP28ETUSE",
        "ts": "1595234226.035900",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "cG2",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Pulumi is very much like Terraform, it actually uses the Terraform providers behind the scenes (Pulumi does not generate files, as AWS CDK does). The only major difference is that you declare that desired state using an API of a general purpose language. But otherwise, Pulumi does exactly what "
                            },
                            {
                                "type": "user",
                                "user_id": "UJ6LDMMN0"
                            },
                            {
                                "type": "text",
                                "text": " said Terraform does \u2014 keeping that desired state, creating a plan, previewing it, applying it, etc.\n\nRegarding "
                            },
                            {
                                "type": "user",
                                "user_id": "UCUSW7WVD"
                            },
                            {
                                "type": "text",
                                "text": "'s problem, I think the solution in Pulumi would be similar to the one in Terrraform. Define a custom resource that does nothing than just block execution for an amount of time and then to the health check, then use this resource as a dependency of the second host you want to create.\n\nGoing back to the original question of whether it would make sense to have a visual editor for k8s config files, I don't think it would help that much. The problem with YAML is not that it's YAML, it's that it offers no means composition and abstraction. With only a visual editor that all it does is to offer affordances for YAML concepts, things will be the same. But, if that visual editors starts adding some PL concepts, such as variables and functions, then it can be useful, but at this point I think it's no longer about YAML or k8s, it's just about structural editors in general."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595084421.458800",
        "parent_user_id": "UKP3B2J5D",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UJ6LDMMN0",
                    "UKP3B2J5D"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "b7a03e05-ecd3-41ae-85c7-80bf336a4763",
        "type": "message",
        "text": "I use the compiler tools from erlang, leex, yecc, absform and the compiler module",
        "user": "UBN9AFS0N",
        "ts": "1595234281.036100",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "O7Gan",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I use the compiler tools from erlang, leex, yecc, absform and the compiler module"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595219570.025900",
        "parent_user_id": "U010328JA1E"
    },
    {
        "client_msg_id": "7921916b-71d1-4012-a121-812078ec2892",
        "type": "message",
        "text": "&gt; Are humans any different than machines?\n\nWe are. Our \u201cmodel\u201d does wetware based optimisation, morphing and most importantly localisation, which is something machines cant do while in hardware mode. Yeah, you can rearrange it in memory, but memory is 2D and that means huge overhead we don\u2019t have. You need a multidimensional graph and mocking that in 2D is annoying as hell. And we are geared towards survival and reproduction, so we have \u201cemotions\u201d that reinforce our models\n\n&gt; Can we just continue to make better models and achieve understanding or consciousness or intelligence?\nNot this way. OpenAI has other stuff that is more geared toward better AI and intelligence. If we just continue to make better models but keep them shallow like this, only thing we will understand that intelligence isn\u2019t pattern recognition.",
        "user": "UNBPP291C",
        "ts": "1595236276.036500",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UNBPP291C",
            "ts": "1595236319.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Qd4yZ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "> Are humans any different than machines?\n\nWe are. Our \u201cmodel\u201d does wetware based optimisation, morphing and most importantly localisation, which is something machines cant do while in hardware mode. Yeah, you can rearrange it in memory, but memory is 2D and that means huge overhead we don\u2019t have. You need a multidimensional graph and mocking that in 2D is annoying as hell. And we are geared towards survival and reproduction, so we have \u201cemotions\u201d that reinforce our models\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Can we just continue to make better models and achieve understanding or consciousness or intelligence?"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nNot this way. OpenAI has other stuff that is more geared toward better AI and intelligence. If we just continue to make better models but keep them shallow like this, only thing we will understand that intelligence isn\u2019t pattern recognition."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "c88fb355-8aea-404e-b66f-8efad5a7b8fd",
        "type": "message",
        "text": "I just use kotlin and wrote my own parser, the language feels so nice and expressive that I just keep coming back to it for everything.\nBasically just find special tokens, create a index of [position, token], then recursively parse it breadth first. tho it isn\u2019t a complete \u201clanguage\u201d, but a DSL language so it\u2019s easier than full on lang :)",
        "user": "UNBPP291C",
        "ts": "1595236571.036800",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UNBPP291C",
            "ts": "1595236580.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Hb3M",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I just use kotlin and wrote my own parser, the language feels so nice and expressive that I just keep coming back to it for everything.\nBasically just find special tokens, create a index of [position, token], then recursively parse it breadth first. tho it isn\u2019t a complete \u201clanguage\u201d, but a DSL language so it\u2019s easier than full on lang :)"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595219570.025900",
        "parent_user_id": "U010328JA1E"
    },
    {
        "client_msg_id": "fdb4622d-e897-421d-996f-ecec3678dd52",
        "type": "message",
        "text": "and weird, nobody mentioned ANTLR yet",
        "user": "UNBPP291C",
        "ts": "1595236697.037100",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "8bP",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "and weird, nobody mentioned ANTLR yet"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595219570.025900",
        "parent_user_id": "U010328JA1E"
    },
    {
        "client_msg_id": "e3f1e2f3-171a-460c-8aa8-167bed515743",
        "type": "message",
        "text": "I've read the article last night, awesome stuff there. It's been a while since I also started thinking that codebase should be treated as a portmanteau of code + database, so this article was right up my alley. However, it never occurred to me that Datalog could be used for the database, even though I played a bit with Eve. I always thought of using a graph database, such as Neo4j.\n\n<@UHTPRR5SM> did you follow any resource for your Datalog implementation? Do you know of any tutorial-like resource that shows how to do that? I'm pretty familiar with unification I'd say, since I wrote a few Hindley-Milner type inference implementations, but I haven't yet come across a good exposition of how to write a Datalog interpreter.",
        "user": "UP28ETUSE",
        "ts": "1595237622.037300",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UP28ETUSE",
            "ts": "1595238277.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "bv40p",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I've read the article last night, awesome stuff there. It's been a while since I also started thinking that codebase should be treated as a portmanteau of code + database, so this article was right up my alley. However, it never occurred to me that Datalog could be used for the database, even though I played a bit with Eve. I always thought of using a graph database, such as Neo4j.\n\n"
                            },
                            {
                                "type": "user",
                                "user_id": "UHTPRR5SM"
                            },
                            {
                                "type": "text",
                                "text": " did you follow any resource for your Datalog implementation? Do you know of any tutorial-like resource that shows how to do that? I'm pretty familiar with unification I'd say, since I wrote a few Hindley-Milner type inference implementations, but I haven't yet come across a good exposition of how to write a Datalog interpreter."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595084261.455800",
        "parent_user_id": "USH01JEDQ"
    },
    {
        "client_msg_id": "661bd06d-b34a-4326-9490-de63e7e3405c",
        "type": "message",
        "text": "<@UNBPP291C> I'd love to read some material about what you describe as \"wetware based optimization, morphing and localization\" \u2014 do you have any pointers to sources that go into depth on these?",
        "user": "U5STGTB3J",
        "ts": "1595239135.037700",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "YuNP",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UNBPP291C"
                            },
                            {
                                "type": "text",
                                "text": " I'd love to read some material about what you describe as \"wetware based optimization, morphing and localization\" \u2014 do you have any pointers to sources that go into depth on these?"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "cef66e59-10e7-4bc3-987e-224a04b2fcc3",
        "type": "message",
        "text": "Let me look it up, I remember a paper last year that was about how brain uses spatial localisation to optimise (kinda annoying now Neural networks are muddying up my search results :joy:)\n\n By \u201coptimization\u201d I mean about constant retraining and optimisation our brains go through.\n\nOur \u201cinternal optimization agent\u201d sees we have a  graph G(n) of n nodes and a graph G(m) of m nodes. They get combined into a graph of  k=(&lt;m*n) nodes, while maybe not retaining the absolute combined precision, but probably having a modulator which is extracted as a separate graph.\n\nFor example, Gn is trained for a fluid (oil)  and Gm is trained for oil. Then, they are merged/splitted into a model that recognizes \u201cfluid\u201d pattern and a \u201cviscosity\u201d pattern (our brains are constantly looking for patterns. constantly. they are our primary source of optimization, i believe that this skill is critical to our brains evolution and that that is why geometry is important in our brains arrangements).  Let\u2019s say you input lava, it would be recognized by both models, one recognizing it\u2019s a fluid and the behaviors of fluid and one that can tell you the viscosity of it. Hope I explained it OK, will try to find papers, they do it better probs (i mean, this is my conclusion from reading multiple of papers, so its dot connecting conclusion from multiple sources).",
        "user": "UNBPP291C",
        "ts": "1595240115.037900",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UNBPP291C",
            "ts": "1595243191.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ix=cR",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Let me look it up, I remember a paper last year that was about how brain uses spatial localisation to optimise (kinda annoying now Neural networks are muddying up my search results "
                            },
                            {
                                "type": "emoji",
                                "name": "joy"
                            },
                            {
                                "type": "text",
                                "text": ")\n\n By \u201coptimization\u201d I mean about constant retraining and optimisation our brains go through.\n\nOur \u201cinternal optimization agent\u201d sees we have a  graph G(n) of n nodes and a graph G(m) of m nodes. They get combined into a graph of  k=(<m*n) nodes, while maybe not retaining the absolute combined precision, but probably having a modulator which is extracted as a separate graph.\n\nFor example, Gn is trained for a fluid (oil)  and Gm is trained for oil. Then, they are merged/splitted into a model that recognizes \u201cfluid\u201d pattern and a \u201cviscosity\u201d pattern (our brains are constantly looking for patterns. constantly. they are our primary source of optimization, i believe that this skill is critical to our brains evolution and that that is why geometry is important in our brains arrangements).  Let\u2019s say you input lava, it would be recognized by both models, one recognizing it\u2019s a fluid and the behaviors of fluid and one that can tell you the viscosity of it. Hope I explained it OK, will try to find papers, they do it better probs (i mean, this is my conclusion from reading multiple of papers, so its dot connecting conclusion from multiple sources)."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "36d1b47b-8d61-45c2-a797-677be0c1eac3",
        "type": "message",
        "text": "(<https://gtr.ukri.org/projects?ref=MR%2FL009013%2F1#/tabOverview> here is one that dabbed into that, but can\u2019t find the one I wanted, an article is at <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4598639/> that is a nice intro)",
        "user": "UNBPP291C",
        "ts": "1595242880.039800",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "title": "GtR",
                "title_link": "https://gtr.ukri.org/projects?ref=MR%2FL009013%2F1#/tabOverview",
                "text": "The Gateway to Research: UKRI portal onto publically funded research",
                "fallback": "GtR",
                "from_url": "https://gtr.ukri.org/projects?ref=MR%2FL009013%2F1#/tabOverview",
                "service_icon": "https://gtr.ukri.org/favicon.ico",
                "service_name": "gtr.ukri.org",
                "id": 1,
                "original_url": "https://gtr.ukri.org/projects?ref=MR%2FL009013%2F1#/tabOverview"
            },
            {
                "service_name": "PubMed Central (PMC)",
                "title": "Brain Networks and Cognitive Architectures",
                "title_link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4598639/",
                "text": "Most accounts of human cognitive architectures have focused on computational accounts of cognition while making little contact with the study of anatomical structures and physiological processes. A renewed convergence between neurobiology and cognition ...",
                "fallback": "PubMed Central (PMC): Brain Networks and Cognitive Architectures",
                "thumb_url": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-logo-share.png",
                "from_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4598639/",
                "thumb_width": 1200,
                "thumb_height": 630,
                "service_icon": "http://www.ncbi.nlm.nih.gov/favicon.ico",
                "id": 2,
                "original_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4598639/"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "P=K",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "("
                            },
                            {
                                "type": "link",
                                "url": "https://gtr.ukri.org/projects?ref=MR%2FL009013%2F1#/tabOverview"
                            },
                            {
                                "type": "text",
                                "text": " here is one that dabbed into that, but can\u2019t find the one I wanted, an article is at "
                            },
                            {
                                "type": "link",
                                "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4598639/"
                            },
                            {
                                "type": "text",
                                "text": " that is a nice intro)"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG",
        "reactions": [
            {
                "name": "pray::skin-tone-2",
                "users": [
                    "UP28ETUSE"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "29885abb-454b-49c3-8e18-593d047c6f8f",
        "type": "message",
        "text": "Also, the more I read about GPT-3 it seems like:\n\n\u201cHey, remember that car we invented? Well, after making the engine a 1000 times bigger we get a lot more horsepower out of it!\u201d",
        "user": "UNBPP291C",
        "ts": "1595243512.040200",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UNBPP291C",
            "ts": "1595243521.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Z6KY",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Also, the more I read about GPT-3 it seems like:\n\n\u201cHey, remember that car we invented? Well, after making the engine a 1000 times bigger we get a lot more horsepower out of it!\u201d"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "1B5615F0-9C60-4533-9661-00DCAA583FBA",
        "type": "message",
        "text": "<@UNBPP291C> Thanks for digging this up; looks promising. I have the same issue, often running into neural network stuff when searching for brain research.\n\nI\u2019m specifically interested in categorization and how semantics manifest in our brains, schemas and frames, essentially the parts between the biochemistry of the brain and the philosophy of thought and reasoning \u2014 here\u2019s a good overview from Lakoff: <https://youtu.be/WuUnMCq-ARQ|https://youtu.be/WuUnMCq-ARQ>\n\nIf you or anyone else comes across research in that area, please send it my way.",
        "user": "U5STGTB3J",
        "ts": "1595249972.046300",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "service_name": "YouTube",
                "service_url": "https://www.youtube.com/",
                "title": "George Lakoff: How Brains Think: The Embodiment Hypothesis",
                "title_link": "https://youtu.be/WuUnMCq-ARQ",
                "author_name": "PsychologicalScience",
                "author_link": "https://www.youtube.com/user/PsychologicalScience",
                "thumb_url": "https://i.ytimg.com/vi/WuUnMCq-ARQ/hqdefault.jpg",
                "thumb_width": 480,
                "thumb_height": 360,
                "fallback": "YouTube Video: George Lakoff: How Brains Think: The Embodiment Hypothesis",
                "video_html": "<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/WuUnMCq-ARQ?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>",
                "video_html_width": 400,
                "video_html_height": 225,
                "from_url": "https://youtu.be/WuUnMCq-ARQ",
                "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png",
                "id": 1,
                "original_url": "https://youtu.be/WuUnMCq-ARQ"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "im2T8",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UNBPP291C"
                            },
                            {
                                "type": "text",
                                "text": " Thanks for digging this up; looks promising. I have the same issue, often running into neural network stuff when searching for brain research.\n\nI\u2019m specifically interested in categorization and how semantics manifest in our brains, schemas and frames, essentially the parts between the biochemistry of the brain and the philosophy of thought and reasoning \u2014 here\u2019s a good overview from Lakoff: "
                            },
                            {
                                "type": "link",
                                "url": "https://youtu.be/WuUnMCq-ARQ",
                                "text": "https://youtu.be/WuUnMCq-ARQ"
                            },
                            {
                                "type": "text",
                                "text": "\n\n"
                            },
                            {
                                "type": "text",
                                "text": "If you or anyone else comes across research in that area, please send it my way."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG",
        "reactions": [
            {
                "name": "pray::skin-tone-2",
                "users": [
                    "UP28ETUSE"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "8fca77ce-1c79-4544-b8e8-d5cb743f8784",
        "type": "message",
        "text": "Reading the conversation in this thread kinda makes me wish this Slack also had a philosophy channel :slightly_smiling_face:",
        "user": "UP28ETUSE",
        "ts": "1595250167.046600",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Lz1UG",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Reading the conversation in this thread kinda makes me wish this Slack also had a philosophy channel "
                            },
                            {
                                "type": "emoji",
                                "name": "slightly_smiling_face"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "71e384cc-ed06-4f6c-8323-03d21ba2981a",
        "type": "message",
        "text": "<@U5STGTB3J> oooh interesting video, will check it out later when I have time! tldr as far as I see its about research that tries to find primitive model our brain recognizes and which are used as building blocks to build more advanced models by having a few types of interactions between them?",
        "user": "UNBPP291C",
        "ts": "1595252403.049200",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "EEDK",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U5STGTB3J"
                            },
                            {
                                "type": "text",
                                "text": " oooh interesting video, will check it out later when I have time! tldr as far as I see its about research that tries to find primitive model our brain recognizes and which are used as building blocks to build more advanced models by having a few types of interactions between them?"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "C89676E8-90D4-40CA-9DAA-7A0ACBD41833",
        "type": "message",
        "text": "<@UNBPP291C> Yes, that describes the gist of it. It\u2019s focused on language, which is only one of many parts of thinking \u2014 arguably quite an important one. Helps to be familiar with the work of George Lakoff and Mark Johnson on metaphorical structuring. There\u2019ll be plenty of pointers in the lecture.",
        "user": "U5STGTB3J",
        "ts": "1595254913.053000",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "U5STGTB3J",
            "ts": "1595254973.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "hcY",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UNBPP291C"
                            },
                            {
                                "type": "text",
                                "text": " Yes, that describes the gist of it. It\u2019s focused on language, which is only one of many parts of thinking \u2014 arguably quite an important one. Helps to be familiar with the work of George Lakoff and Mark Johnson on metaphorical structuring. There\u2019ll be plenty of pointers in the lecture."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "23f907fb-bb9d-4ec0-ac34-b895c59c0356",
        "type": "message",
        "text": "No clue who any of those people are but lecture sounds awesome, tnx for the link :thumbsup:",
        "user": "UNBPP291C",
        "ts": "1595254963.053200",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "haLP6",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "No clue who any of those people are but lecture sounds awesome, tnx for the link "
                            },
                            {
                                "type": "emoji",
                                "name": "thumbsup"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595144410.477000",
        "parent_user_id": "U0136G8R8KG"
    },
    {
        "client_msg_id": "38c9d1ff-c60d-4d92-9bb6-daccce145016",
        "type": "message",
        "text": "<https://medium.com/the-long-now-foundation/six-ways-to-think-long-term-da373b3377a4>\nprompt: how does this frame affect your thoughts about the future of programming?",
        "user": "UL3EE9WR1",
        "ts": "1595260067.054200",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "service_name": "Medium",
                "title": "Six Ways to Think Long-term",
                "title_link": "https://medium.com/the-long-now-foundation/six-ways-to-think-long-term-da373b3377a4",
                "text": "A Cognitive Toolkit for Good Ancestors",
                "fallback": "Medium: Six Ways to Think Long-term",
                "image_url": "https://miro.medium.com/max/1200/1*SvVWXKySOzUGPqscVR4AaA.png",
                "fields": [
                    {
                        "title": "Reading time",
                        "value": "13 min read",
                        "short": true
                    }
                ],
                "ts": 1595255653,
                "from_url": "https://medium.com/the-long-now-foundation/six-ways-to-think-long-term-da373b3377a4",
                "image_width": 444,
                "image_height": 250,
                "image_bytes": 857602,
                "service_icon": "https://cdn-images-1.medium.com/fit/c/152/152/1*8I-HPL0bfoIzGied-dzOvA.png",
                "id": 1,
                "original_url": "https://medium.com/the-long-now-foundation/six-ways-to-think-long-term-da373b3377a4"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "v2UD",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "link",
                                "url": "https://medium.com/the-long-now-foundation/six-ways-to-think-long-term-da373b3377a4"
                            },
                            {
                                "type": "text",
                                "text": "\nprompt: how does this frame affect your thoughts about the future of programming?"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595260067.054200",
        "reply_count": 4,
        "reply_users_count": 3,
        "latest_reply": "1595456799.186300",
        "reply_users": [
            "UNBPP291C",
            "UCUSW7WVD",
            "U01661S9F34"
        ],
        "subscribed": false,
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UCUSW7WVD",
                    "UJBAJNFLK"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "325ebcea-41bd-4e73-946e-947d863ccb36",
        "type": "message",
        "text": "I hand rolled the lexer and parser for Curv in C++, because I didn't want to fight tool limitations in defining the syntax or implementing error recovery. In retrospect,\n\u2022 A regex-based scanner generator like re2c would have made the scanner easier to write.\n\u2022 My hand-written recursive descent parser was easy to write and continues to be easy to modify. No regrets.\n\u2022 After hanging out in FoC for a year, I have IDE envy. To properly implement completions and hints, I need an incremental parser. So maybe I should switch to the tree-sitter parser generator?  <https://github.com/tree-sitter/tree-sitter>\n\u2022 For me, the hard part is the back end, not the parser/lexical analyser. What are the libraries/DSLs for semantic analysis, optimization and code generation?",
        "user": "UJN1TAYEQ",
        "ts": "1595265341.054500",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UJN1TAYEQ",
            "ts": "1595265352.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "38n",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I hand rolled the lexer and parser for Curv in C++, because I didn't want to fight tool limitations in defining the syntax or implementing error recovery. In retrospect,\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "A regex-based scanner generator like re2c would have made the scanner easier to write."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "My hand-written recursive descent parser was easy to write and continues to be easy to modify. No regrets."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "After hanging out in FoC for a year, I have IDE envy. To properly implement completions and hints, I need an incremental parser. So maybe I should switch to the tree-sitter parser generator?  "
                                    },
                                    {
                                        "type": "link",
                                        "url": "https://github.com/tree-sitter/tree-sitter"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "For me, the hard part is the back end, not the parser/lexical analyser. What are the libraries/DSLs for semantic analysis, optimization and code generation?"
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0
                    }
                ]
            }
        ],
        "thread_ts": "1595219570.025900",
        "parent_user_id": "U010328JA1E",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "U010328JA1E"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "c8280e9f-d4eb-47af-be2b-7fb44b36e026",
        "type": "message",
        "text": "Re: affecting programming in this frame - less hype chasing, more deep knowledge, research and standardisation. The ego stance of \u201cme and my ass\u201d is affecting programming world a lot, especially through middle management.\n\nre: article - it\u2019s surprisingly bad, 99 cent philosophy. I wrote a lenghty comment on HN about it, but I don\u2019t think this article deserves even a minute more of my time considering how badly thought out it is. <https://news.ycombinator.com/item?id=23899952>",
        "user": "UNBPP291C",
        "ts": "1595266055.054900",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UNBPP291C",
            "ts": "1595266119.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "YMAw",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Re: affecting programming in this frame - less hype chasing, more deep knowledge, research and standardisation. The ego stance of \u201cme and my ass\u201d is affecting programming world a lot, especially through middle management.\n\nre: article - it\u2019s surprisingly bad, 99 cent philosophy. I wrote a lenghty comment on HN about it, but I don\u2019t think this article deserves even a minute more of my time considering how badly thought out it is. "
                            },
                            {
                                "type": "link",
                                "url": "https://news.ycombinator.com/item?id=23899952"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595260067.054200",
        "parent_user_id": "UL3EE9WR1"
    },
    {
        "client_msg_id": "761be2c5-5358-48c7-9667-5ecb8bb37b5d",
        "type": "message",
        "text": "<@UP28ETUSE> the main guide I had is a simple interpreter that a friend wrote, which isn\u2019t open source. So, really the best I can offer up is my own implementation (simpleEvaluate.ts in the repo; not guaranteed to be bug free :stuck_out_tongue:) or these miniKanren implementations (a minimal logic programming language): <http://minikanren.org/>",
        "user": "UHTPRR5SM",
        "ts": "1595269881.055300",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "RMUu",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UP28ETUSE"
                            },
                            {
                                "type": "text",
                                "text": " the main guide I had is a simple interpreter that a friend wrote, which isn\u2019t open source. So, really the best I can offer up is my own implementation (simpleEvaluate.ts in the repo; not guaranteed to be bug free "
                            },
                            {
                                "type": "emoji",
                                "name": "stuck_out_tongue"
                            },
                            {
                                "type": "text",
                                "text": ") or these miniKanren implementations (a minimal logic programming language): "
                            },
                            {
                                "type": "link",
                                "url": "http://minikanren.org/"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1595084261.455800",
        "parent_user_id": "USH01JEDQ"
    }
]