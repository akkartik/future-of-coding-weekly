[
    {
        "client_msg_id": "7106a14b-2f46-4549-adee-e9ae0d72ba4d",
        "type": "message",
        "text": "Yeah, my pinephone was close to two months late... due to covid locking the borders, but what can you do; at least they are transparent about it.",
        "user": "UT60XSVCN",
        "ts": "1606172894.093900",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "=xym",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah, my pinephone was close to two months late... due to covid locking the borders, but what can you do; at least they are transparent about it."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1606072405.090400",
        "parent_user_id": "UCUSW7WVD"
    },
    {
        "client_msg_id": "a0dd1d8a-e4e2-4b1d-ab0a-6ff51acc15ef",
        "type": "message",
        "text": "A pattern I'm using to simplify my HTTP APIs: <https://gist.github.com/EmmanuelOga/8458a500645da511f10ad32fe8084367>",
        "user": "UN9SCH5RD",
        "ts": "1606175454.094800",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "7msd",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "A pattern I'm using to simplify my HTTP APIs: "
                            },
                            {
                                "type": "link",
                                "url": "https://gist.github.com/EmmanuelOga/8458a500645da511f10ad32fe8084367"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "client_msg_id": "5c38b1be-6cc3-4d60-b610-1b56f6194a19",
        "type": "message",
        "text": "I'm not a hardware designer, but I've had classes on HW design and I've done quite a bit of research on it. In general, does it make sense to design hardware that supports functional languages? Correct me if I'm wrong here, but it seems to me that the most expensive operation for languages like clojure are around their <https://en.wikipedia.org/wiki/Persistent_data_structure|data structures> (even though they are really fast). Could fixed function hardware be designed to make persistant data structures a winning choice? e.g. could be stuff like improving cache synchronization. I don't know where this would fit best though - would this type of FF HW be best placed within the cpu core, or perhaps alongside the ram? Just spit balling here, hopefully someone here knows enough to say weather this is dumb or a possible idea.",
        "user": "U01DUNFS2N4",
        "ts": "1606178161.100100",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "j+8",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'm not a hardware designer, but I've had classes on HW design and I've done quite a bit of research on it. In general, does it make sense to design hardware that supports functional languages? Correct me if I'm wrong here, but it seems to me that the most expensive operation for languages like clojure are around their "
                            },
                            {
                                "type": "link",
                                "url": "https://en.wikipedia.org/wiki/Persistent_data_structure",
                                "text": "data structures"
                            },
                            {
                                "type": "text",
                                "text": " (even though they are really fast). Could fixed function hardware be designed to make persistant data structures a winning choice? e.g. could be stuff like improving cache synchronization. I don't know where this would fit best though - would this type of FF HW be best placed within the cpu core, or perhaps alongside the ram? Just spit balling here, hopefully someone here knows enough to say weather this is dumb or a possible idea."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1606178161.100100",
        "reply_count": 10,
        "reply_users_count": 5,
        "latest_reply": "1606234884.109100",
        "reply_users": [
            "UC2A2ARPT",
            "UN9SCH5RD",
            "UCUSW7WVD",
            "U01DUNFS2N4",
            "U013ZLJARC7"
        ],
        "subscribed": false
    },
    {
        "client_msg_id": "cfb622bd-d772-4a11-a38e-42a9aba29342",
        "type": "message",
        "text": "I'm reminded of this recent <https://twitter.com/Catfish_Man/status/1326238434235568128|tweet> from Apple engineer Dave Smith about the perf of the M1 chip:\n\n&gt; fun fact: retaining and releasing an NSObject takes ~30 nanoseconds on current gen Intel, and ~6.5 nanoseconds on an M1\n&gt; \n&gt; \u2026and ~14 nanoseconds on an M1 emulating an Intel :innocent: \nThey designed the M1 chip to do really well at object retain/release because Swift &amp; Obj-C use reference counting extensively (rather than, say, some sort of full-blown GC).\n\nWould be interesting to know what work they did to the hardware to accelerate that particular pattern. Like you said \u2014\u00a0is it just in the CPU, or is it affected by memory latency, or..?\n\nWould also be interesting to know whether other languages could be pulled along in the slipstream of that particular HW optimization.",
        "user": "UC2A2ARPT",
        "ts": "1606178935.100200",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UC2A2ARPT",
            "ts": "1606179374.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "7E75B",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'm reminded of this recent "
                            },
                            {
                                "type": "link",
                                "url": "https://twitter.com/Catfish_Man/status/1326238434235568128",
                                "text": "tweet"
                            },
                            {
                                "type": "text",
                                "text": " from Apple engineer Dave Smith about the perf of the M1 chip:\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_quote",
                        "elements": [
                            {
                                "type": "text",
                                "text": "fun fact: retaining and releasing an NSObject takes ~30 nanoseconds on current gen Intel, and ~6.5 nanoseconds on an M1\n\n\u2026and ~14 nanoseconds on an M1 emulating an Intel "
                            },
                            {
                                "type": "emoji",
                                "name": "innocent"
                            },
                            {
                                "type": "text",
                                "text": " "
                            }
                        ]
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nThey designed the M1 chip to do really well at object retain/release because Swift & Obj-C use reference counting extensively (rather than, say, some sort of full-blown GC).\n\nWould be interesting to know what work they did to the hardware to accelerate that particular pattern. Like you said \u2014\u00a0is it just in the CPU, or is it affected by memory latency, or..?\n\nWould also be interesting to know whether other languages could be pulled along in the slipstream of that particular HW optimization."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1606178161.100100",
        "parent_user_id": "U01DUNFS2N4",
        "reactions": [
            {
                "name": "bulb",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "f837435a-acd2-41c0-b58f-7371b167a1f5",
        "type": "message",
        "text": "I think it is a rabbit hole. Hardware is inherently stateful, state machines are a good model to think about it. There were whole teams trying to come up with Lisp machines and the effort is well documented elsewhere but they ultimately failed to get traction (there's also a distinction to be made between \"functional\" and \"immutable\"). I feel like stateful hardware with an immutable layer on top is the correct way to model something like Clojure.",
        "user": "UN9SCH5RD",
        "ts": "1606182152.101000",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "jhkg0",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I think it is a rabbit hole. Hardware is inherently stateful, state machines are a good model to think about it. There were whole teams trying to come up with Lisp machines and the effort is well documented elsewhere but they ultimately failed to get traction (there's also a distinction to be made between \"functional\" and \"immutable\"). I feel like stateful hardware with an immutable layer on top is the correct way to model something like Clojure."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1606178161.100100",
        "parent_user_id": "U01DUNFS2N4",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UKP3B2J5D"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "e1b5e03a-bc94-4d89-a689-18681389d4f0",
        "type": "message",
        "text": "Yeah, this has been explored a whole lot. I'd have more citations to provide 10+ years ago when I did my PhD in computer architecture. One thing to note here is that the whole CISC thing that RISC was in response to was a trend of adding special instructions for common patterns in software.\n\nWhich is not to say there's nothing to explore here. It's gotten quite unfashionable for 30+ years now. That seems like enough time for another turn of the wheel.",
        "user": "UCUSW7WVD",
        "ts": "1606184017.101300",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UCUSW7WVD",
            "ts": "1606184055.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "CkZ8",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Yeah, this has been explored a whole lot. I'd have more citations to provide 10+ years ago when I did my PhD in computer architecture. One thing to note here is that the whole CISC thing that RISC was in response to was a trend of adding special instructions for common patterns in software.\n\nWhich is not to say there's nothing to explore here. It's gotten quite unfashionable for 30+ years now. That seems like enough time for another turn of the wheel."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1606178161.100100",
        "parent_user_id": "U01DUNFS2N4",
        "reactions": [
            {
                "name": "cake",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            },
            {
                "name": "ferris_wheel",
                "users": [
                    "UN9SCH5RD",
                    "U013ZLJARC7"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "f170a1de-b76e-4f28-91d6-5cc962ba2302",
        "type": "message",
        "text": "On the one hand: yeah, RISC has definitely had a good run for the past 30 years.\n\nOn the other hand: chips are extremely wide now wherever the software is able to make use of that (eg: SIMD, GPU units); SoCs have dedicated image signal processors, ML accelerators, crypto accelerators, video decoding (and sometimes encoding); mobile chips (or, at least, Apple's chips) have heterogeneous cores, some for high-perf and some for low-power.\n\nSo there seems to be a move away from simple, undifferentiated compute and a return to specialized hardware aplenty \u2014 but this time it's physical specialization, rather than instruction specialization.\n\nCuriously, it seems the opposite might be happening in memory. RAM and VRAM are frequently merged (ie. by M1, modern game consoles, mobile devices), there's the thought that we might see NVRAM combine RAM and storage, I wouldn't be surprised if L3 cache fell out of favour.",
        "user": "UC2A2ARPT",
        "ts": "1606192516.101600",
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UC2A2ARPT",
            "ts": "1606192558.000000"
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "HQTFn",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "On the one hand: yeah, RISC has definitely had a good run for the past 30 years.\n\nOn the other hand: chips are extremely wide now wherever the software is able to make use of that (eg: SIMD, GPU units); SoCs have dedicated image signal processors, ML accelerators, crypto accelerators, video decoding (and sometimes encoding); mobile chips (or, at least, Apple's chips) have heterogeneous cores, some for high-perf and some for low-power.\n\nSo there seems to be a move away from simple, undifferentiated compute and a return to specialized hardware aplenty \u2014 but this time it's physical specialization, rather than instruction specialization.\n\nCuriously, it seems the opposite might be happening in memory. RAM and VRAM are frequently merged (ie. by M1, modern game consoles, mobile devices), there's the thought that we might see NVRAM combine RAM and storage, I wouldn't be surprised if L3 cache fell out of favour."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1606178161.100100",
        "parent_user_id": "U01DUNFS2N4",
        "reactions": [
            {
                "name": "100",
                "users": [
                    "U5STGTB3J"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "ED293135-3110-4274-8367-3C5992202D16",
        "type": "message",
        "text": "<@UCUSW7WVD> my only disagreement with your post is that, yes, lisp machine have been tried. However, afaik most lisps before clojure used more out less standard mutable data structures. My theory (could still be wrong) is that the data structures provide the biggest possible ROI for hardware. ",
        "user": "U01DUNFS2N4",
        "ts": "1606202711.106000",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "RFQ",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "UCUSW7WVD"
                            },
                            {
                                "type": "text",
                                "text": " my only disagreement with your post is that, yes, lisp machine have been tried. However, afaik most lisps before clojure used more out less standard mutable data structures. My theory (could still be wrong) is that the data structures provide the biggest possible ROI for hardware. "
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1606178161.100100",
        "parent_user_id": "U01DUNFS2N4"
    },
    {
        "client_msg_id": "e3b5f728-64e0-4d7f-91c6-20c7ca07f637",
        "type": "message",
        "text": "Perhaps you're responding to Emanuel's comment? I didn't really mention Lisp machines.",
        "user": "UCUSW7WVD",
        "ts": "1606203055.106200",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "km9",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Perhaps you're responding to Emanuel's comment? I didn't really mention Lisp machines."
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1606178161.100100",
        "parent_user_id": "U01DUNFS2N4"
    },
    {
        "client_msg_id": "BCB3D7B7-0D3C-4BF8-8BBB-B3BA80B2C371",
        "type": "message",
        "text": "Oops, mobile is hard to read :)",
        "user": "U01DUNFS2N4",
        "ts": "1606226570.107100",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "TiLp",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Oops, mobile is hard to read :)"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1606178161.100100",
        "parent_user_id": "U01DUNFS2N4"
    },
    {
        "client_msg_id": "9241C51C-77A2-4CCC-9F54-333CC1EC4650",
        "type": "message",
        "text": "I thought you had made both comments, but with each of you making one my comment applies less",
        "user": "U01DUNFS2N4",
        "ts": "1606226703.108400",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Goc1H",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I thought you had made both comments, but with each of you making one my comment applies less"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1606178161.100100",
        "parent_user_id": "U01DUNFS2N4"
    },
    {
        "client_msg_id": "81d14db2-1912-4719-807e-a296ff889511",
        "type": "message",
        "text": "<@U01DUNFS2N4> While most Lisps allow one to tinker with the inner workings of cons cells, it's probably worth noting that the standard list building process of `(cons elem the-list)`  (construct a new list with `elem` as the head and `the-list` as the tail) does not modify `the-list` in any way, allowing other reference holders to continue as if nothing has happened. It's a form of \"unenforced immutability,\" if you will.\n\nYou can read about how this works in the context of Common Lisp here:\n<http://blog.thezerobit.com/2012/07/21/immutable-persistent-data-structures-in-common-lisp.html>",
        "user": "U013ZLJARC7",
        "ts": "1606229953.108800",
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "title": "Immutable Persistent Data Structures in Common Lisp - the zero bit stream",
                "title_link": "http://blog.thezerobit.com/2012/07/21/immutable-persistent-data-structures-in-common-lisp.html",
                "text": "0. The Rationale Clojure, Scala, and Haskell (and other languages) have recently brought the idea of immutable (and persistent) data structures into \u2026",
                "fallback": "Immutable Persistent Data Structures in Common Lisp - the zero bit stream",
                "from_url": "http://blog.thezerobit.com/2012/07/21/immutable-persistent-data-structures-in-common-lisp.html",
                "service_name": "blog.thezerobit.com",
                "id": 1,
                "original_url": "http://blog.thezerobit.com/2012/07/21/immutable-persistent-data-structures-in-common-lisp.html"
            }
        ],
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "TV=c6",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "user",
                                "user_id": "U01DUNFS2N4"
                            },
                            {
                                "type": "text",
                                "text": " While most Lisps allow one to tinker with the inner workings of cons cells, it's probably worth noting that the standard list building process of "
                            },
                            {
                                "type": "text",
                                "text": "(cons elem the-list)",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "  (construct a new list with "
                            },
                            {
                                "type": "text",
                                "text": "elem",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " as the head and "
                            },
                            {
                                "type": "text",
                                "text": "the-list",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " as the tail) does not modify "
                            },
                            {
                                "type": "text",
                                "text": "the-list ",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "in any way, allowing other reference holders to continue as if nothing has happened. It's a form of \"unenforced immutability,\" if you will.\n\nYou can read about how this works in the context of Common Lisp here:\n"
                            },
                            {
                                "type": "link",
                                "url": "http://blog.thezerobit.com/2012/07/21/immutable-persistent-data-structures-in-common-lisp.html"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1606178161.100100",
        "parent_user_id": "U01DUNFS2N4"
    },
    {
        "client_msg_id": "590c0ee9-00f7-408f-bcd8-92a367374406",
        "type": "message",
        "text": "Ah, interesting. I've come across this before, but I didn't think about it w.r.t. this topic",
        "user": "U01DUNFS2N4",
        "ts": "1606234884.109100",
        "team": "T5TCAFTA9",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "AE/s",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Ah, interesting. I've come across this before, but I didn't think about it w.r.t. this topic"
                            }
                        ]
                    }
                ]
            }
        ],
        "thread_ts": "1606178161.100100",
        "parent_user_id": "U01DUNFS2N4"
    }
]