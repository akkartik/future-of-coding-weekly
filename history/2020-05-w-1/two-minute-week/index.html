
<!doctype html>
<html>
  <head>
    <meta charset=utf-8>
    <title>Future of Coding History</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <style>.alert{border-radius:0}.msg-response{background-color:white!important}</style>
  </head>
  <body class="p-3">
<div id="2020-04-20T07:27:05.063Z" class="alert alert-dark msg-root my-1 p-2 bg-light"><span class="small text-muted"><a href="#2020-04-20T07:27:05.063Z">2020-04-20 07:27:05</a></span> <span class="font-weight-bold">Unknown User: </span> <p><p>MSG NOT FOUND</p>
</p> <div id="2020-04-26T22:03:34.126Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-26T22:03:34.126Z">2020-04-26 22:03:34</a></span> <span class="font-weight-bold">Ivan Reese: </span> <p><p>Gary Bernhardt's "The Birth &amp; Death of JavaScript" continues to come true. Love it.</p>
</p></div></div><div id="2020-04-26T13:51:49.114Z" class="alert alert-dark msg-root my-1 p-2 bg-light"><span class="small text-muted"><a href="#2020-04-26T13:51:49.114Z">2020-04-26 13:51:49</a></span> <span class="font-weight-bold">Unknown User: </span> <p><p>MSG NOT FOUND</p>
</p> <div id="2020-04-26T22:13:01.126Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-26T22:13:01.126Z">2020-04-26 22:13:01</a></span> <span class="font-weight-bold">Ivan Reese: </span> <p><p>This is beautiful and elegant. So inspiring to see. I wish I could say more than that, but what you've shown seems very well-considered and I don't have anything meaningful to add.</p>
<p>I also really appreciate the effort you're putting into these videos&nbsp;‚Äî the planning and editing are a real benefit. If there was a way to adjust how you're processing the audio so it doesn't cut in and out so abruptly, that'd help me focus more on the substance of what you're saying. I'd probably find it less distracting if you didn't filter/cut out the "silences" (room tone) between your sentences at all.</p>
</p></div><div id="2020-04-27T07:23:04.137Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-27T07:23:04.137Z">2020-04-27 07:23:04</a></span> <span class="font-weight-bold">Yair Chuchem: </span> <p><p><strong>Ivan Reese</strong> true. I‚Äôm actually quite embarrased about the sound. for our youtube videos I actually went and recorded the sound with a proper setup but here it‚Äôs been a very quick thing..</p>
</p></div><div id="2020-04-27T07:35:06.137Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-27T07:35:06.137Z">2020-04-27 07:35:06</a></span> <span class="font-weight-bold">Ivan Reese: </span> <p><p>Quick is good! All I mean to say is ‚Äî&nbsp;the background noise is not bad. Embrace it, for this format. I'm also going to be embracing a "quick and dirty" aesthetic for my videos. Your audio has good levels, and your voice is loud and clear and pleasing to listen to. No need to try to carve out silences.</p>
</p></div><div id="2020-04-27T07:38:05.137Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-27T07:38:05.137Z">2020-04-27 07:38:05</a></span> <span class="font-weight-bold">Yair Chuchem: </span> <p><p>It‚Äôs not really a conscious effort to carve out, but more of an edit of different takes I‚Äôm recording within final cut as I make the edit, where final cut doesn‚Äôt make it easy if you want to cross fade etc as by default it‚Äôs just layed out as layers attached to the magnetic timeline, but yeah I can try to group together the clips. wrt carving silences actually in our youtube videos my audio engineer friend did put a noise gate on them but the recordings were much better to begin with and didn‚Äôt have much noticeable noise..</p>
</p></div><div id="2020-04-27T14:11:39.145Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-27T14:11:39.145Z">2020-04-27 14:11:39</a></span> <span class="font-weight-bold">Sol Bekic: </span> <p><p><strong>Yair Chuchem</strong> i recorded my video with a pretty bad setup (webcam) and did some very basic noise removal in Audacity - its very easy to do: <a href="https://www.youtube.com/watch?v=xkpzHJGE4Dk">https://www.youtube.com/watch?v=xkpzHJGE4Dk</a>
That and fade in/out should take care of most of it I think :)</p>
</p></div><div id="2020-04-27T14:16:14.145Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-27T14:16:14.145Z">2020-04-27 14:16:14</a></span> <span class="font-weight-bold">Yair Chuchem: </span> <p><p><strong>Sol Bekic</strong> thanks! I also recorded with a webcam and I do have access and some knowledge of audio processing tools, I develop them for a living.. It‚Äôs just that I didn‚Äôt bother ‚Äúgoing pro‚Äù for a quick 2 minutes video. For Lamdu‚Äôs videos on youtube I‚Äôve explicitly went to record at the pro recording studio at my office (which at the moment I don‚Äôt have access to while quarantining at home) and recorded in a quality room with quality hardware and had a pro audio engineer process it a bit (I‚Äôm just a programmer after all..).
For here I just wanted something ready without much effort and recorded with my webcam and only applied the untouched compressor preset I had working on my last youtube video.. But I get it, and will make an effort to improve the sound editing for next week‚Äôs video üôÇ</p>
</p></div><div id="2020-04-27T14:18:44.146Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-27T14:18:44.146Z">2020-04-27 14:18:44</a></span> <span class="font-weight-bold">Sol Bekic: </span> <p><p><strong>Yair Chuchem</strong> oh, I see. In any case, I'm really liking your to-the-point videos! You definitely have my attention ;)</p>
</p></div><div id="2020-04-27T18:51:24.147Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-27T18:51:24.147Z">2020-04-27 18:51:24</a></span> <span class="font-weight-bold">Ivan Reese: </span> <p><p>The best example of the problem I have is, say, from 0:10 to 0:20 in the video. The room noise in the background is less distracting than the fact that it keeps cutting in and out. So when editing in Final Cut, you can the "empty" room tone between your sentences, rather than cutting your audio clips so that they only exist when you're speaking. Again, this isn't super important, it's just a small thing that'd hopefully not cost you any additional effort but make the videos easier to follow.</p>
<p>As for Sol's suggestion to use noise removal, I find that that always introduces artifacts, and the artifacts are just as distracting as the noise. Better to just live with the noise floor, I say ‚Äî but that's just my personal taste.</p>
</p></div><div id="2020-04-27T19:06:14.149Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-27T19:06:14.149Z">2020-04-27 19:06:14</a></span> <span class="font-weight-bold">Yair Chuchem: </span> <p><p><strong>Ivan Reese</strong> I know that some very serious folks swear by some noise removal tools like Izotope‚Äôs, and also Accusonus‚Äôs not bad I think</p>
</p></div><div id="2020-04-27T23:39:57.150Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-27T23:39:57.150Z">2020-04-27 23:39:57</a></span> <span class="font-weight-bold">Ivan Reese: </span> <p><p>Yeah, Izotope makes some amazing tools. But a lot of your success with noise removal depends on the kind of noise being removed. Is it hiss? Is it a pure tone, like 60hz line hum? Those are easier to remove without side effects. But lots of noises are less easily characterized, and even the best tools I've seen will have trouble with them.</p>
<p>That said.. I've yet to see anyone apply ML to this problem, and it seems like the sort of thing that'd be <em>very</em> well suited. Could be there are better solutions now since the last time I checked, even.</p>
</p></div></div><div id="2020-04-26T19:08:35.115Z" class="alert alert-dark msg-root my-1 p-2 bg-light"><span class="small text-muted"><a href="#2020-04-26T19:08:35.115Z">2020-04-26 19:08:35</a></span> <span class="font-weight-bold">Unknown User: </span> <p><p>MSG NOT FOUND</p>
</p> <div id="2020-04-26T22:17:37.126Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-26T22:17:37.126Z">2020-04-26 22:17:37</a></span> <span class="font-weight-bold">Ivan Reese: </span> <p><p>Can we nerd-out for a sec on that FFT view? I love the per-channel idea. Was that inspired by anything in particular?</p>
</p></div><div id="2020-04-26T22:19:26.126Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-26T22:19:26.126Z">2020-04-26 22:19:26</a></span> <span class="font-weight-bold">Ivan Reese: </span> <p><p>(My favourite audio tool, perhaps my favourite software tool of all, is the EQ8 in Ableton Live, which is a parametric EQ with an excellent GUI and a fairly nice spectrum behind it. So it always excites me to see people doing cool things with EQ GUIs or FFT displays)</p>
</p></div><div id="2020-04-26T22:53:46.135Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-26T22:53:46.135Z">2020-04-26 22:53:46</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p><p>Because I need visualisations to pretty much understand anything hard, I needed the FFT to help me understand the synth and check for problems (it has already shown an issue with my triangle wave tables). I solved the problem of polyphony by making my data flow pins have multiple channels - so effectively every unit will generate data for all input channels. That meant that the multiple visualisations just fell out of the design (but note that the visualiser node is attached into the graph before a ‚Äòflattening‚Äô node which combines the polyphony into a single channel (before widening it back to stereo!) hope that makes sense <strong>Ivan Reese</strong> !</p>
</p></div><div id="2020-04-27T08:54:48.138Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-27T08:54:48.138Z">2020-04-27 08:54:48</a></span> <span class="font-weight-bold">Ivan Reese: </span> <p><p>That's an incredibly cool idea. If I understand it right, it's as though all your nodes are doing multiple channels in parallel? That feels a bit like SIMD for visual programming. I'm going to have to think about this a lot more. I think this has very interesting ramifications.</p>
</p></div><div id="2020-04-27T11:38:50.143Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-27T11:38:50.143Z">2020-04-27 11:38:50</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p><p>Yes, that's right.  Imagine the user is playing C Major; 3 notes.  Those 3 notes go into the Oscillator node as control signals.  The oscillator then outputs 3 arrays, each containing, say, 512 audio samples for each of the 3 notes.  The 'output' pin of the oscillator now has 3 internal data streams.  So each unit can operate on the data as a whole.  The next graph node can understand this data and do the right thing.  Imagine that you have 2 oscillators tied into the same note input.  Now you have 2 units emitting the same 3 channels.  If you want to combine the oscillators for each node, then the mixer has no trouble distinguishing the pairs of streams to combine, because each note channel has been tagged with the Id of the note.
```m_spOutData-&gt;MatchChannelInput(*pFlowData);
auto&amp; outChannels = m_spOutData-&gt;GetChannels();
auto&amp; inChannels = pFlowData-&gt;GetChannels();</p>
<p>for (uint32_t ch = 0; ch &lt; pFlowData-&gt;GetNumChannels(); ch++)
{
    for (uint32_t i = 0; i &lt; maud.genFrameCount; i++)
    {
        sp_moogladder_compute(maud.pSP, m_vecMoogLadder[ch], &amp;inChannels[ch].data[i], &amp;outChannels[ch].data[i]);
     }
}```
Above is the simple example of a Low Pass Filter.  It first reads in the input channels, and in this case ensures that the output channels match, before applying the effect.</p>
</p></div><div id="2020-04-27T11:41:36.144Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-27T11:41:36.144Z">2020-04-27 11:41:36</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p><p>I doubt this is a new approach; but it seemed the most sensible to me.  I thought about potentially splitting the directed graph into separate instances for each note, but that felt like it was going to get complicated really quickly.</p>
</p></div><div id="2020-04-27T11:44:39.144Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-27T11:44:39.144Z">2020-04-27 11:44:39</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p><p>I also considered threading issues, but this actually works really well from that point of view.  In my performance analysis, i've noticed that most of the work is in the wave table sampling.  Since all those units are just sitting generating arrays of data for all the held down notes, they can effectively be run in parallel if necessary</p>
</p></div><div id="2020-04-27T11:45:22.144Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-27T11:45:22.144Z">2020-04-27 11:45:22</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p>
</p></div><div id="2020-04-27T11:49:03.144Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-27T11:49:03.144Z">2020-04-27 11:49:03</a></span> <span class="font-weight-bold">Chris Maughan: </span> <p><p>Above is a profile of the graph I showed with several notes playing.  The blocks on the right are the FFT for each note, in worker threads.  The block on the left are the oscillators.  Each oscillator is generating all samples for all notes, but you can see that they run sequentially since they are on the same audio thread.  I'll probably move them to workers (it isn't hard), but I don't want to optimise up front until I have a better feel for things. Since premature optimization is the root of all evil, as you know üòâ</p>
</p></div></div><div id="2020-04-26T21:21:34.125Z" class="alert alert-dark msg-root my-1 p-2 bg-light"><span class="small text-muted"><a href="#2020-04-26T21:21:34.125Z">2020-04-26 21:21:34</a></span> <span class="font-weight-bold">Unknown User: </span> <p><p>MSG NOT FOUND</p>
</p> <div id="2020-04-26T22:22:35.127Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-26T22:22:35.127Z">2020-04-26 22:22:35</a></span> <span class="font-weight-bold">Ivan Reese: </span> <p><p>Nice! If you're wondering what to do a video about next week, I'd love to see a 2-minute demo of the layout system. It's the sort of thing that I've heard you talk about, but it's hard to express what makes it interesting through words alone.</p>
</p></div><div id="2020-04-27T07:51:57.137Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-27T07:51:57.137Z">2020-04-27 07:51:57</a></span> <span class="font-weight-bold">Mariano Guerra: </span> <p><p>looks like the trailer of a netflix show, now I want to see more üòÑ</p>
</p></div><div id="2020-04-27T09:28:14.143Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-27T09:28:14.143Z">2020-04-27 09:28:14</a></span> <span class="font-weight-bold">Duncan Cragg: </span> <p><p>Yeah "renaissance proportions" needs elaboration!</p>
</p></div><div id="2020-04-28T07:58:36.150Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-28T07:58:36.150Z">2020-04-28 07:58:36</a></span> <span class="font-weight-bold">William Taysom: </span> <p><p>I'll second renaissance proportions.  Likewise it is good to say, "with Beads we're focusing on this and wanting to ignore that."  It's a great way to describe any project.</p>
</p></div></div><div id="2020-04-27T09:00:41.142Z" class="alert alert-dark msg-root my-1 p-2 bg-light"><span class="small text-muted"><a href="#2020-04-27T09:00:41.142Z">2020-04-27 09:00:41</a></span> <span class="font-weight-bold">Ivan Reese: </span> <p><p>I just want to take a moment and say ‚Äî this channel is making me incredibly happy. I have been absolutely delighted by every one of these videos, and I'm feeling so inspired by all the work you're doing. There are already a lot of fascinating ideas on display here, and the two minute format is so digestible that it's cracking an accessibility barrier that's kept me from properly appreciating many of them before. Thank you for making these videos and fostering the discussions, and I hope we'll be able to keep the momentum going.</p>
</p> </div><div id="2020-04-29T18:26:48.160Z" class="alert alert-dark msg-root my-1 p-2 bg-light"><span class="small text-muted"><a href="#2020-04-29T18:26:48.160Z">2020-04-29 18:26:48</a></span> <span class="font-weight-bold">Dan Swirsky: </span> <p><p>Here's Hilltop's first two-minute (and change) video!</p>
</p> </div><div id="2020-04-29T18:27:27.161Z" class="alert alert-dark msg-root my-1 p-2 bg-light"><span class="small text-muted"><a href="#2020-04-29T18:27:27.161Z">2020-04-29 18:27:27</a></span> <span class="font-weight-bold">Dan Swirsky: </span> <p><p><a href="https://youtu.be/Z8nXFLWkQmw">Hilltop - Episode 1</a></p>
</p> <div id="2020-04-29T18:34:47.161Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-29T18:34:47.161Z">2020-04-29 18:34:47</a></span> <span class="font-weight-bold">Ivan Reese: </span> <p><p>The video is set to "private" ‚Äî you probably want to set it as "unlisted"</p>
</p></div><div id="2020-04-29T18:37:44.161Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-29T18:37:44.161Z">2020-04-29 18:37:44</a></span> <span class="font-weight-bold">Dan Swirsky: </span> <p><p>Done</p>
</p></div><div id="2020-04-29T20:00:42.161Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-29T20:00:42.161Z">2020-04-29 20:00:42</a></span> <span class="font-weight-bold">Edward de Jong: </span> <p><p>Its nice to see a proportional font programming system. Fixed pitch is so archaic, however many fonts have too thin punctuation marks so unless you use a custom font it is easier to work with. Not sure that notating literals by using a darker color is going to pan out. Sooner or later you are going to want to use that annotation for some other purpose, and are quotes really so bad?</p>
</p></div><div id="2020-04-30T03:22:10.162Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-30T03:22:10.162Z">2020-04-30 03:22:10</a></span> <span class="font-weight-bold">William Taysom: </span> <p><p>Getting Self vibes.  Man, I remember when Verdana was my go to programming font.  üê∫</p>
</p></div><div id="2020-04-30T16:04:09.163Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-30T16:04:09.163Z">2020-04-30 16:04:09</a></span> <span class="font-weight-bold">Ivan Reese: </span> <p><p>Is there a particular kind of app that you intend for Hilltop to be well suited to? Something like hypertext, or CRUD? Also, curious to hear more about what direction your exploration is headed.</p>
</p></div><div id="2020-04-30T18:06:56.163Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-30T18:06:56.163Z">2020-04-30 18:06:56</a></span> <span class="font-weight-bold">Dan Swirsky: </span> <p><p>I don't have a type of app in mind. I'm exploring several things at the same time:
‚Ä¢ What if we took away the row-and-column aspect of a spreadsheet, and just kept the cells, where a cell is something that holds an object definition?
‚Ä¢ And what if when you decide to create a new cell/object definition, it‚Äôs based on a predefined object type, such as of a number, text, an image, a sound, etc. (as opposed to spreadsheets, where you can't immediately tell whether a number in a cell is numeric or text)?
‚Ä¢ And what if predefined object types have predefined attributes, such as ‚Äòvalue‚Äô for primitive object types, X and Y coordinates for object types that can be displayed, etc.?
‚Ä¢ And what if the programmer provides value definitions to whichever attributes she likes, such as literal values or formulas that reference values of other attributes?
‚Ä¢ And what if an app is defined as a collection of these cells/object definitions and the value definitions of their attributes, just as in a spreadsheet?
‚Ä¢ And what if "running" the app simply means instantiating the cells and letting them "do" whatever their object types "do" (e.g., an image-type object "displays" if its X and Y attributes have values; a sound-type object makes a sound if its ‚Äòvolume‚Äô attribute is set to some nonzero value which, according to its value definition, happens when the value of some boolean-type attribute of another object changes)?
‚Ä¢ And what if, as in a spreadsheet, a behind-the-scenes manager propagates value changes to various object attributes when the values of other object attributes change, and this is what manages the app‚Äôs behavior?
‚Ä¢ And what would all this look like as text-based programming (as opposed to visual programming like Scratch)?
‚Ä¢ And could we eliminate syntax errors using a structure editor, where the keyboard is only used when naming objects, entering literal values, and editing comments?
‚Ä¢ And what if the structure editor is in the form of context menus?
‚Ä¢ And what if tapping different types of code elements opens different context menus, each only showing valid programming options based on the tapped code element type?
‚Ä¢ And would this mean that we could program on our phones and tablets?</p>
</p></div><div id="2020-04-30T18:08:37.163Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-30T18:08:37.163Z">2020-04-30 18:08:37</a></span> <span class="font-weight-bold">Ivan Reese: </span> <p><p>This feels like a rich vein! I'm excited to see where you go with it. Do you have a working prototype? How's that going?</p>
</p></div><div id="2020-04-30T18:18:13.163Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-30T18:18:13.163Z">2020-04-30 18:18:13</a></span> <span class="font-weight-bold">Dan Swirsky: </span> <p><p>Nope. It's design and mockups only, at least until I find my Wozniak</p>
</p></div><div id="2020-04-30T19:05:14.164Z" class="alert alert-dark msg-response p-2 ml-1 my-1 bg-light"><span class="small text-muted"><a href="#2020-04-30T19:05:14.164Z">2020-04-30 19:05:14</a></span> <span class="font-weight-bold">Ivan Reese: </span> <p><p>Put out the call here! According to the survey, there are a lot of folks who are looking for projects to contribute to.</p>
</p></div></div><div id="2020-05-02T11:27:43.166Z" class="alert alert-dark msg-root my-1 p-2 bg-light"><span class="small text-muted"><a href="#2020-05-02T11:27:43.166Z">2020-05-02 11:27:43</a></span> <span class="font-weight-bold">Mariano Guerra: </span> <p><p>Instadeq Week in Two Minutes #3: Generalized IO UI &amp; history, Selected output on charts, Keep UI state on IO update, Remove cycles in sankey chart,  Providers and more <a href="https://youtu.be/WcaY3KLj7pY">https://youtu.be/WcaY3KLj7pY</a></p>
</p> </div>
  </body>
</html>
