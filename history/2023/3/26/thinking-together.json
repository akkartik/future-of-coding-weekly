[
    {
        "type": "message",
        "subtype": "thread_broadcast",
        "text": "GPT feels like an existential crisis for the future of programming, if not an extinction event. I am having to rationalize to myself about why that probably isn\u2019t true so I can keep working. The scary truth is that no one knows. We have no idea where we are on the scaling curve or even what constraints will limit it.",
        "user": "U6KQ2S410",
        "ts": "1679865409.191369",
        "thread_ts": "1679642239.661619",
        "root": {
            "client_msg_id": "53df656f-b6b5-4ef6-a470-c1af29f870e6",
            "type": "message",
            "text": "Friends, I don't know what to make of developments in AI these days.  Having worked on dialog systems in the aughts and having loosely followed developments since (I recall preparing a talk around 2010 which left me pretty enthusiastic about ML applications in contrast to the App-and-Facebookification of \"tech\" \u2014 that was on time horizon of a few years, which ended up being a decade plus), every day I check in on Twitter I see more exciting stuff than I can possibly process.  I was just writing someone yesterday about how in six months time, we'll have LLMs acting as the front-end to knowledge bases and rigorous computational systems, and then we'll need to focus on getting the human, AI, and formal model all on the same page.\n\nAs has already been noted in <#C5U3SEW6A|linking-together> today, my estimate was off by roughly six months.  Consider, \"I've developed a lot of plugin systems, and the OpenAI ChatGPT plugin interface might be the damn craziest and most impressive approach I've ever seen in computing in my entire life. For those who aren't aware: you write an OpenAPI manifest for your API, use human language descriptions for everything, and that's it. You let the model figure out how to auth, chain calls, process data in between, format it for viewing, etc. There's absolutely zero glue code\" <https://twitter.com/mitchellh/status/1638967450510458882>.\n\nIf you can tolerate his prose, Stephen Wolfram has a long post <https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/>.  The \"Wolfram Language as the Language for Human-AI Collaboration\" section is most relevant to Future of Coding.  What do these developments mean for the Future of Coding?  And how are you all holding up?  Me?  I can hardly process what's happening, let alone what to do about it.",
            "user": "UA14TGLTC",
            "ts": "1679642239.661619",
            "blocks": [
                {
                    "type": "rich_text",
                    "block_id": "Bvp",
                    "elements": [
                        {
                            "type": "rich_text_section",
                            "elements": [
                                {
                                    "type": "text",
                                    "text": "Friends, I don't know what to make of developments in AI these days.  Having worked on dialog systems in the aughts and having loosely followed developments since (I recall preparing a talk around 2010 which left me pretty enthusiastic about ML applications in contrast to the App-and-Facebookification of \"tech\" \u2014 that was on time horizon of a few years, which ended up being a decade plus), every day I check in on Twitter I see more exciting stuff than I can possibly process.  I was just writing someone yesterday about how in six months time, we'll have LLMs acting as the front-end to knowledge bases and rigorous computational systems, and then we'll need to focus on getting the human, AI, and formal model all on the same page.\n\nAs has already been noted in "
                                },
                                {
                                    "type": "channel",
                                    "channel_id": "C5U3SEW6A"
                                },
                                {
                                    "type": "text",
                                    "text": " today, my estimate was off by roughly six months.  Consider, \"I've developed a lot of plugin systems, and the OpenAI ChatGPT plugin interface might be the damn craziest and most impressive approach I've ever seen in computing in my entire life. For those who aren't aware: you write an OpenAPI manifest for your API, use human language descriptions for everything, and that's it. You let the model figure out how to auth, chain calls, process data in between, format it for viewing, etc. There's absolutely zero glue code\" "
                                },
                                {
                                    "type": "link",
                                    "url": "https://twitter.com/mitchellh/status/1638967450510458882"
                                },
                                {
                                    "type": "text",
                                    "text": ".\n\nIf you can tolerate his prose, Stephen Wolfram has a long post "
                                },
                                {
                                    "type": "link",
                                    "url": "https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/"
                                },
                                {
                                    "type": "text",
                                    "text": ".  The \"Wolfram Language as the Language for Human-AI Collaboration\" section is most relevant to Future of Coding.  What do these developments mean for the Future of Coding?  And how are you all holding up?  Me?  I can hardly process what's happening, let alone what to do about it."
                                }
                            ]
                        }
                    ]
                }
            ],
            "team": "T5TCAFTA9",
            "thread_ts": "1679642239.661619",
            "reply_count": 46,
            "reply_users_count": 12,
            "latest_reply": "1680043681.323419",
            "reply_users": [
                "UJBAJNFLK",
                "UE1JQM9HQ",
                "U5STGTB3J",
                "U04LWR320HK",
                "UA14TGLTC",
                "UC2A2ARPT",
                "U016VUZGUUQ",
                "U01JNTE35QS",
                "U6KQ2S410",
                "UEBG0NPDK",
                "UCGAK10LS",
                "UE6EFEPTQ"
            ],
            "is_locked": false,
            "subscribed": false
        },
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "uuOW",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "GPT feels like an existential crisis for the future of programming, if not an extinction event. I am having to rationalize to myself about why that probably isn\u2019t true so I can keep working. The scary truth is that no one knows. We have no idea where we are on the scaling curve or even what constraints will limit it."
                            }
                        ]
                    }
                ]
            }
        ],
        "client_msg_id": "4e3e3ffa-4adb-4482-80b6-2cfe0f3f81ac",
        "reactions": [
            {
                "name": "100",
                "users": [
                    "UCUSW7WVD",
                    "U03R0B9U1GD",
                    "UEBG0NPDK",
                    "UA14TGLTC",
                    "UPVBV34EL",
                    "UJBAJNFLK"
                ],
                "count": 6
            }
        ]
    }
]