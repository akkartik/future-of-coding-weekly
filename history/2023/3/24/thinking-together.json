[
    {
        "client_msg_id": "53df656f-b6b5-4ef6-a470-c1af29f870e6",
        "type": "message",
        "text": "Friends, I don't know what to make of developments in AI these days.  Having worked on dialog systems in the aughts and having loosely followed developments since (I recall preparing a talk around 2010 which left me pretty enthusiastic about ML applications in contrast to the App-and-Facebookification of \"tech\" \u2014 that was on time horizon of a few years, which ended up being a decade plus), every day I check in on Twitter I see more exciting stuff than I can possibly process.  I was just writing someone yesterday about how in six months time, we'll have LLMs acting as the front-end to knowledge bases and rigorous computational systems, and then we'll need to focus on getting the human, AI, and formal model all on the same page.\n\nAs has already been noted in <#C5U3SEW6A|linking-together> today, my estimate was off by roughly six months.  Consider, \"I've developed a lot of plugin systems, and the OpenAI ChatGPT plugin interface might be the damn craziest and most impressive approach I've ever seen in computing in my entire life. For those who aren't aware: you write an OpenAPI manifest for your API, use human language descriptions for everything, and that's it. You let the model figure out how to auth, chain calls, process data in between, format it for viewing, etc. There's absolutely zero glue code\" <https://twitter.com/mitchellh/status/1638967450510458882>.\n\nIf you can tolerate his prose, Stephen Wolfram has a long post <https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/>.  The \"Wolfram Language as the Language for Human-AI Collaboration\" section is most relevant to Future of Coding.  What do these developments mean for the Future of Coding?  And how are you all holding up?  Me?  I can hardly process what's happening, let alone what to do about it.",
        "user": "UA14TGLTC",
        "ts": "1679642239.661619",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "Bvp",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Friends, I don't know what to make of developments in AI these days.  Having worked on dialog systems in the aughts and having loosely followed developments since (I recall preparing a talk around 2010 which left me pretty enthusiastic about ML applications in contrast to the App-and-Facebookification of \"tech\" \u2014 that was on time horizon of a few years, which ended up being a decade plus), every day I check in on Twitter I see more exciting stuff than I can possibly process.  I was just writing someone yesterday about how in six months time, we'll have LLMs acting as the front-end to knowledge bases and rigorous computational systems, and then we'll need to focus on getting the human, AI, and formal model all on the same page.\n\nAs has already been noted in "
                            },
                            {
                                "type": "channel",
                                "channel_id": "C5U3SEW6A"
                            },
                            {
                                "type": "text",
                                "text": " today, my estimate was off by roughly six months.  Consider, \"I've developed a lot of plugin systems, and the OpenAI ChatGPT plugin interface might be the damn craziest and most impressive approach I've ever seen in computing in my entire life. For those who aren't aware: you write an OpenAPI manifest for your API, use human language descriptions for everything, and that's it. You let the model figure out how to auth, chain calls, process data in between, format it for viewing, etc. There's absolutely zero glue code\" "
                            },
                            {
                                "type": "link",
                                "url": "https://twitter.com/mitchellh/status/1638967450510458882"
                            },
                            {
                                "type": "text",
                                "text": ".\n\nIf you can tolerate his prose, Stephen Wolfram has a long post "
                            },
                            {
                                "type": "link",
                                "url": "https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/"
                            },
                            {
                                "type": "text",
                                "text": ".  The \"Wolfram Language as the Language for Human-AI Collaboration\" section is most relevant to Future of Coding.  What do these developments mean for the Future of Coding?  And how are you all holding up?  Me?  I can hardly process what's happening, let alone what to do about it."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679642239.661619",
        "reply_count": 22,
        "reply_users_count": 8,
        "latest_reply": "1679857701.783789",
        "reply_users": [
            "UJBAJNFLK",
            "UE1JQM9HQ",
            "U5STGTB3J",
            "U04LWR320HK",
            "UA14TGLTC",
            "UC2A2ARPT",
            "U016VUZGUUQ",
            "U01JNTE35QS"
        ],
        "is_locked": false,
        "subscribed": false,
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "UCUSW7WVD",
                    "UMV4B97GT",
                    "UC2A2ARPT",
                    "U01H6M7BVGD",
                    "U04LUG47E0N"
                ],
                "count": 5
            }
        ]
    },
    {
        "client_msg_id": "a5a352da-b719-439f-8b26-547ce880da11",
        "type": "message",
        "text": "Recent AI development are almost a denial-of-service attack on intellectual life. Everybody is struggling to keep up. It's almost guaranteed that the immediate impact of all this will be negative - bad AI applications, rushed attempts at useless forms of integration, etc.\nIt would be great if techies around the world would silently play with these tools for a while before rushing to market with their new toys.",
        "user": "UJBAJNFLK",
        "ts": "1679643607.301909",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "e6tF",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Recent AI development are almost a denial-of-service attack on intellectual life. Everybody is struggling to keep up. It's almost guaranteed that the immediate impact of all this will be negative - bad AI applications, rushed attempts at useless forms of integration, etc.\nIt would be great if techies around the world would silently play with these tools for a while before rushing to market with their new toys."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "reactions": [
            {
                "name": "100",
                "users": [
                    "U013ZLJARC7"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "7a2f4859-5bc6-471f-9848-c847300e8f17",
        "type": "message",
        "text": "That said, I agree about the nice perspective of AI for glue. Or, more generally, for the \"outer\", most user-facing aspects of software. This echoes the structure of pre-computing work based on good old mathematics: plain-language reasoning with embedded formal systems.",
        "user": "UJBAJNFLK",
        "ts": "1679643699.930779",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "mQAFd",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "That said, I agree about the nice perspective of AI for glue. Or, more generally, for the \"outer\", most user-facing aspects of software. This echoes the structure of pre-computing work based on good old mathematics: plain-language reasoning with embedded formal systems."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC"
    },
    {
        "client_msg_id": "b91f4a90-7568-404e-b097-973df4cfdb34",
        "type": "message",
        "text": "Oh, one final advice to techies working on AI integration: wait for Open Source AIs. If you all jump on OpenAI's offerings, you will probably regret it when OpenAI tightens the screws (as it invariably will).",
        "user": "UJBAJNFLK",
        "ts": "1679643773.942429",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "HPh",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Oh, one final advice to techies working on AI integration: wait for Open Source AIs. If you all jump on OpenAI's offerings, you will probably regret it when OpenAI tightens the screws (as it invariably will)."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "reactions": [
            {
                "name": "point_up::skin-tone-3",
                "users": [
                    "UCUSW7WVD"
                ],
                "count": 1
            },
            {
                "name": "heart",
                "users": [
                    "UE1JQM9HQ",
                    "U04KZ8A9WCT"
                ],
                "count": 2
            },
            {
                "name": "point_up",
                "users": [
                    "U04QB9V2RNG",
                    "UA14TGLTC",
                    "U04MTMF6Y4W",
                    "U01JNTE35QS",
                    "U04LUG47E0N"
                ],
                "count": 5
            },
            {
                "name": "100",
                "users": [
                    "UC2A2ARPT",
                    "U023V63MF6V",
                    "U013ZLJARC7",
                    "UML4ZEKDK"
                ],
                "count": 4
            }
        ]
    },
    {
        "client_msg_id": "20f69cc5-9305-4eef-97b7-57d0d1b3830c",
        "type": "message",
        "text": "The integration with Wolfram* is certainly interesting. Still, there is a large difference between something that fits on a screen and a significant system.\n\nAs long as humans decide what goes into a system, there will remain two challenges:\n1. identify a relevant question that holds value. This is a skill that can be built. It\u2019s not about prompt engineering, but about understanding cause and effect in a specific domain.\n2. figure out where, how and why a specific solution fits in the system. A completion is interesting but from a system engineering perspective, we still need to evaluate it. That happens to be the main blocker in system development for quite a while now, even without AI.\nFor both of these, when the problem and the solution fit on a screen, they can potentially be addressed implicitly (picture generation is an extreme case of this: I believe a reason why they are so popular is that people can evaluate them quickly and implicitly). When they do not fit on a screen you still have to evaluate them, but that evaluation can be significantly more expensive. Of course, you can use tools to address that problem, too, and this will raise the next level and so on. Which then leads to a discipline of figuring systems out.\n\nOur approach so far was to pursue compressing the system for a specific perspective, and this turns out to indeed accelerate greatly the ability to reason about systems. I believe this area is in its infancy and I believe there is great potential (both intellectually and as a competitive advantage).",
        "user": "UE1JQM9HQ",
        "ts": "1679645429.572999",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "0X2au",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The integration with Wolfram* is certainly interesting. Still, there is a large difference between something that fits on a screen and a significant system.\n\nAs long as humans decide what goes into a system, there will remain two challenges:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "identify a relevant question that holds value. This is a skill that can be built. It\u2019s not about prompt engineering, but about understanding cause and effect in a specific domain."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "figure out where, how and why a specific solution fits in the system. A completion is interesting but from a system engineering perspective, we still need to evaluate it. That happens to be the main blocker in system development for quite a while now, even without AI."
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nFor both of these, when the problem and the solution fit on a screen, they can potentially be addressed implicitly (picture generation is an extreme case of this: I believe a reason why they are so popular is that people can evaluate them quickly and implicitly). When they do not fit on a screen you still have to evaluate them, but that evaluation can be significantly more expensive. Of course, you can use tools to address that problem, too, and this will raise the next level and so on. Which then leads to a discipline of figuring systems out.\n\nOur approach so far was to pursue compressing the system for a specific perspective, and this turns out to indeed accelerate greatly the ability to reason about systems. I believe this area is in its infancy and I believe there is great potential (both intellectually and as a competitive advantage)."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "reactions": [
            {
                "name": "thinking_face",
                "users": [
                    "UA14TGLTC"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "DDEBF6D1-D2AD-4115-AC35-F547C5A9765F",
        "type": "message",
        "text": "A few friends of mine and I are in a small private chat group where we discuss tech stuff and forward each other links to articles. You can imagine what that chat has become over the last few weeks. Nothing but AI. (We used to debate Apple\u2019s upcoming headset, which feels moot now; I chuckle at the thought of a product announcement that demoes any Siri-based use case at the moment.)\n\nOn top of that, I get articles about AI forwarded from friends outside of my tech bubble. Which is a clear indicator to me that this has a more significant cultural impact than the stuff we go on about usually. That lead me to re-prioritize somewhat, and now I spend quite some time reading about AI, and also playing with it.\n\nAs often with technology, we\u2019re at the whim of the companies that push it on us, so it\u2019s partially like a roller coaster ride where you can do little but make sure you\u2019re strapped in properly and try to enjoy it.\n\nOh, you could choose not to ride it in the first place, of course. But then there\u2019s nobody to talk to anymore, because everybody is on the ride and only wants to talk about it, and about the terrible things that will happen to you at the end of it, where it\u2019s unclear what exactly will happen (part of the marketing that got you on here, I guess) and people suspect the company who built the roller coaster hasn\u2019t fully done all the safety checks (and weirdly there\u2019s no regulation either, so they got away with it).\n\nThe good news is, most of us are in the same car (it\u2019s massive, apparently), so take a deep breath, put your hands in the air, and brace for the next inversion\u2026 :roller_coaster: \n\n(Some people insist that tweeting as loud as you can from the top of your lungs helps you feel better.)",
        "user": "U5STGTB3J",
        "ts": "1679647648.385719",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "3te",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "A few friends of mine and I are in a small private chat group where we discuss tech stuff and forward each other links to articles. You can imagine what that chat has become over the last few weeks. Nothing but AI. (We used to debate Apple\u2019s upcoming headset, which feels moot now; I chuckle at the thought of a product announcement that demoes any Siri-based use case at the moment.)\n\nOn top of that, I get articles about AI forwarded from friends outside of my tech bubble. Which is a clear indicator to me that this has a more significant cultural impact than the stuff we go on about usually. That lead me to re-prioritize somewhat, and now I spend quite some time reading about AI, and also playing with it"
                            },
                            {
                                "type": "text",
                                "text": "."
                            },
                            {
                                "type": "text",
                                "text": "\n\nAs often with technology, "
                            },
                            {
                                "type": "text",
                                "text": "we\u2019re"
                            },
                            {
                                "type": "text",
                                "text": " at the whim of the companies that push it on us, so "
                            },
                            {
                                "type": "text",
                                "text": "it\u2019s"
                            },
                            {
                                "type": "text",
                                "text": " partially like a roller coaster ride where you can do little but make sure "
                            },
                            {
                                "type": "text",
                                "text": "you\u2019re"
                            },
                            {
                                "type": "text",
                                "text": " strapped in properly and try to enjoy it"
                            },
                            {
                                "type": "text",
                                "text": "."
                            },
                            {
                                "type": "text",
                                "text": "\n\nOh, you could choose not to ride it in the first place, of course. But then there\u2019s nobody to talk to anymore, because everybody is on the ride and only wants to talk about it, and about the terrible things that will happen to you at the end of it, where "
                            },
                            {
                                "type": "text",
                                "text": "it\u2019s"
                            },
                            {
                                "type": "text",
                                "text": " unclear what exactly will happen (part of the marketing that got you on here, I guess) and people suspect the company who built the roller coaster "
                            },
                            {
                                "type": "text",
                                "text": "hasn\u2019t"
                            },
                            {
                                "type": "text",
                                "text": " fully done all the safety checks (and weirdly "
                            },
                            {
                                "type": "text",
                                "text": "there\u2019s"
                            },
                            {
                                "type": "text",
                                "text": " no regulation either, so they got away with it)"
                            },
                            {
                                "type": "text",
                                "text": "."
                            },
                            {
                                "type": "text",
                                "text": "\n\nThe good news is, most of us are in the same car ("
                            },
                            {
                                "type": "text",
                                "text": "it\u2019s"
                            },
                            {
                                "type": "text",
                                "text": " massive, apparently), so take a deep breath, put your hands in the air, and brace for the next inversion\u2026 "
                            },
                            {
                                "type": "emoji",
                                "name": "roller_coaster",
                                "unicode": "1f3a2"
                            },
                            {
                                "type": "text",
                                "text": " \n\n(Some people insist that tweeting as loud as you can from the top of your lungs helps you feel better.)"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "reactions": [
            {
                "name": "thinking_face",
                "users": [
                    "UA14TGLTC",
                    "U01JNTE35QS"
                ],
                "count": 2
            },
            {
                "name": "cake",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "a5d45562-a074-4d40-b482-e20229788eea",
        "type": "message",
        "text": "As I mentioned in another thread on here: I'm definitely already thinking about what I'll do with myself in the future - but these considerations can only _ignore_ the wider societal implications of the technology and only ever view AI as a \"programmer replacement tech\", because otherwise, the system of things to consider gets too complex. So really, the thoughts are worthless.\n\nAlso, I don't know if these seismic shifts will come to pass at all/if my considerations will be relevant. Right now it's hard to tell where on the curve of possible progress with transformer based AI we are as well as what capabilities already present in the existing models haven't been discovered, thought of or exploited.\n\nPart of me also isn't entirely sure about the AI safety/alignment talk going on. I'd like more takes by people who aren't directly or indirectly involved with OpenAI, Microsoft etc. in some form. Because these companies and people would certainly stand to benefit from making GPT sound \"more AGI\" than it really is.",
        "user": "U04LWR320HK",
        "ts": "1679652855.371729",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "TD2dB",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "As I mentioned in another thread on here: I'm definitely already thinking about what I'll do with myself in the future - but these considerations can only "
                            },
                            {
                                "type": "text",
                                "text": "ignore",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " the wider societal implications of the technology and only ever view AI as a \"programmer replacement tech\", because otherwise, the system of things to consider gets too complex. So really, the thoughts are worthless.\n\nAlso, I don't know if these seismic shifts will come to pass at all/if my considerations will be relevant. Right now it's hard to tell where on the curve of possible progress with transformer based AI we are as well as what capabilities already present in the existing models haven't been discovered, thought of or exploited.\n\nPart of me also isn't entirely sure about the AI safety/alignment talk going on. I'd like more takes by people who aren't directly or indirectly involved with OpenAI, Microsoft etc. in some form. Because these companies and people would certainly stand to benefit from making GPT sound \"more AGI\" than it really is."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC"
    },
    {
        "client_msg_id": "df632f46-cfa3-4748-ba6d-5bb9dd48ee72",
        "type": "message",
        "text": "The direction that excites me is LLaMa/Alpaca + Langchain. But the direction that I'm fearing all of this will take (and that I currently use and even pay for, to be honest) is the corporate capture that OpenAI and Microsoft are currently executing.",
        "user": "U04LWR320HK",
        "ts": "1679653074.943419",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "0P5=",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "The direction that excites me is LLaMa/Alpaca + Langchain. But the direction that I'm fearing all of this will take (and that I currently use and even pay for, to be honest) is the corporate capture that OpenAI and Microsoft are currently executing."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC"
    },
    {
        "client_msg_id": "91f7290e-e845-4a13-9945-01519953d34b",
        "type": "message",
        "text": "Also, another problem I have: I was a Machine Learning Engineer in the past, at the height of the CNN hype shortly before transformers hit the scene. And when you're not one of the handful of people doing foundational work/research, I feel like ML engineering is super boring. It's basically - ironically - all glue code, all of the time.",
        "user": "U04LWR320HK",
        "ts": "1679653201.142569",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "T36vY",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Also, another problem I have: I was a Machine Learning Engineer in the past, at the height of the CNN hype shortly before transformers hit the scene. And when you're not one of the handful of people doing foundational work/research, I feel like ML engineering is super boring. It's basically - ironically - all glue code, all of the time."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "reactions": [
            {
                "name": "rolling_on_the_floor_laughing",
                "users": [
                    "UA14TGLTC",
                    "U04KZ8A9WCT"
                ],
                "count": 2
            },
            {
                "name": "cake",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "9f87e87a-811b-4e6d-b0f6-8524b13c8955",
        "type": "message",
        "text": "But maybe the curve we're on really is so steep that there won't even be a real transition period where all programmers \"have to become\" ML engineers for a while, and we're going straight for whatever it is that follows? :smiley:",
        "user": "U04LWR320HK",
        "ts": "1679653460.044379",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "U8Z",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "But maybe the curve we're on really is so steep that there won't even be a real transition period where all programmers \"have to become\" ML engineers for a while, and we're going straight for whatever it is that follows? "
                            },
                            {
                                "type": "emoji",
                                "name": "smiley",
                                "unicode": "1f603"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC"
    },
    {
        "client_msg_id": "67d03291-d326-4ebf-bf33-bd7b88eb04b0",
        "type": "message",
        "text": "Psychoanalysis is what follows: the art of using dialog to tune the black box.  Keeping my own years of observation in mind, I wonder if Bryan Caplan has gauged the situation now correctly, \"AI enthusiasts have cried wolf for decades.  GPT-4 is the wolf. I've seen it with my own eyes\"  <https://twitter.com/bryan_caplan/status/1638199348738793473>.\n\nWhat has he seen?  \"To my surprise and no small dismay, GPT-4 got an A.  It earned 73/100, which would have been the fourth-highest score on the test.\"  In contrast, ChatGPT of January did \"a fine job of imitating a very weak GMU econ student.\"  He continues, \"I wouldn\u2019t have been surprised by a C this year, a B in three years, and a 50/50 A/B mix by 2029. An A already? Base rates have clearly failed me.\"  As far as can see, we're at the start of this curve rather than the end, but I can hardly see _anything_ because the curve looks like a _cliff_.",
        "user": "UA14TGLTC",
        "ts": "1679662321.572839",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "r8dS",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Psychoanalysis is what follows: the art of using dialog to tune the black box.  Keeping my own years of observation in mind, I wonder if Bryan Caplan has gauged the situation now correctly, \"AI enthusiasts have cried wolf for decades.  GPT-4 is the wolf. I've seen it with my own eyes\"  "
                            },
                            {
                                "type": "link",
                                "url": "https://twitter.com/bryan_caplan/status/1638199348738793473"
                            },
                            {
                                "type": "text",
                                "text": ".\n\nWhat has he seen?  \"To my surprise and no small dismay, GPT-4 got an A.  It earned 73/100, which would have been the fourth-highest score on the test.\"  In contrast, ChatGPT of January did \"a fine job of imitating a very weak GMU econ student.\"  He continues, \"I wouldn\u2019t have been surprised by a C this year, a B in three years, and a 50/50 A/B mix by 2029. An A already? Base rates have clearly failed me.\"  As far as can see, we're at the start of this curve rather than the end, but I can hardly see "
                            },
                            {
                                "type": "text",
                                "text": "anything",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " because the curve looks like a "
                            },
                            {
                                "type": "text",
                                "text": "cliff",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": "."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "from_url": "https://twitter.com/bryan_caplan/status/1638199348738793473",
                "ts": 1679412135,
                "id": 1,
                "original_url": "https://twitter.com/bryan_caplan/status/1638199348738793473",
                "fallback": "<https://twitter.com/bryan_caplan|@bryan_caplan>: AI enthusiasts have cried wolf for decades.\n\nGPT-4 is the wolf. I've seen it with my own eyes.\n<https://betonit.substack.com/p/gpt-retakes-my-midterm-and-gets-an>",
                "text": "AI enthusiasts have cried wolf for decades.\n\nGPT-4 is the wolf. I've seen it with my own eyes.\n<https://betonit.substack.com/p/gpt-retakes-my-midterm-and-gets-an>",
                "author_name": "Bryan Caplan",
                "author_link": "https://twitter.com/bryan_caplan/status/1638199348738793473",
                "author_icon": "https://pbs.twimg.com/profile_images/1499115147880660992/V_JbBp80_normal.jpg",
                "author_subname": "@bryan_caplan",
                "service_name": "twitter",
                "service_url": "https://twitter.com/",
                "footer": "Twitter",
                "footer_icon": "https://a.slack-edge.com/80588/img/services/twitter_pixel_snapped_32.png"
            }
        ],
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC"
    },
    {
        "client_msg_id": "daff19d9-fb58-4be6-8295-85a9344d4aa7",
        "type": "message",
        "text": "I'm also thinking about this a lot, but I'll be brief:\n\n\u2022 This changes how computers interpret our writing, which changes textual programming, addressing many of the things I dislike about it. I _think_ this is going to be a setback for visual programming research, which seems of most interest to those who are dissatisfied with text code. Yet, it could force the handful of people who stick around working on VP to move on from merely _wrapping text in boxes_.\n\u2022 There's surely going to be some way to use these transformers to invent a new visual programming. Very curious what that could look like. Also curious whether it will ever happen_._ It's possible that this flurry of excitement over new *language-centric* (written and spoken) ways of interacting with computers deprives or displaces all the other kinds of interaction for a good long while. Is this the end of direct manipulation as we know it?",
        "user": "UC2A2ARPT",
        "ts": "1679670191.352299",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "uAB",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I'm also thinking about this a lot, but I'll be brief:\n\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "This changes how computers interpret our writing, which changes textual programming, addressing many of the things I dislike about it. I "
                                    },
                                    {
                                        "type": "text",
                                        "text": "think ",
                                        "style": {
                                            "italic": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": "this is going to be a setback for visual programming research, which seems of most interest to those who are dissatisfied with text code. Yet, it could force the handful of people who stick around working on VP to move on from merely "
                                    },
                                    {
                                        "type": "text",
                                        "text": "wrapping text in boxes",
                                        "style": {
                                            "italic": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": "."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "There's surely going to be some way to use these transformers to invent a new visual programming. Very curious what that could look like. Also curious whether"
                                    },
                                    {
                                        "type": "text",
                                        "text": " ",
                                        "style": {
                                            "italic": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": "it will ever happen"
                                    },
                                    {
                                        "type": "text",
                                        "text": ".",
                                        "style": {
                                            "italic": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " It's possible that this flurry of excitement over new "
                                    },
                                    {
                                        "type": "text",
                                        "text": "language-centric",
                                        "style": {
                                            "bold": true
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": " (written and spoken) ways of interacting with computers deprives or displaces all the other kinds of interaction for a good long while. Is this the end of direct manipulation as we know it?"
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "reactions": [
            {
                "name": "beer",
                "users": [
                    "U023V63MF6V",
                    "U04S5LF5C7R",
                    "UA14TGLTC"
                ],
                "count": 3
            }
        ]
    },
    {
        "client_msg_id": "945DE0C3-F304-4288-90AE-F2D7C39E1CBA",
        "type": "message",
        "text": "My hope for visual programming is the automation of the UI tediousness that currently limits what we can do.  Looking at image gen, prompt engineering is the least good part of the process.  Better are tools that allow for interactive, iterative refinement.  I\u2019m surprised by how good Chat is at selectively editing an existing text.",
        "user": "UA14TGLTC",
        "ts": "1679734459.112359",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "gjyhw",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "My hope for visual programming is the automation of the UI tediousness that currently limits what we can do"
                            },
                            {
                                "type": "text",
                                "text": "."
                            },
                            {
                                "type": "text",
                                "text": "  Looking at image gen, prompt engineering is the least good part of the process"
                            },
                            {
                                "type": "text",
                                "text": "."
                            },
                            {
                                "type": "text",
                                "text": "  Better are tools that allow for interactive, iterative refinement"
                            },
                            {
                                "type": "text",
                                "text": "."
                            },
                            {
                                "type": "text",
                                "text": "  I\u2019m surprised by how good Chat is at selectively editing an existing text"
                            },
                            {
                                "type": "text",
                                "text": "."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC"
    },
    {
        "client_msg_id": "3053a05f-07de-430a-8136-4fb64d91f832",
        "type": "message",
        "text": "Thanks <@U5STGTB3J> for describing very well what I meant with denial-of-service attack.\n\nTwo additions:\n1. The current AI developments are obviously an important step in the evolution of information technology, which is what our focus here is. But from the wider perspective of society, or even just technology, it's a long-term concern. The immediate problems society has to deal with are largely unrelated to AI. That's why I see the denial-of-service attack as so problematic.\n2. As long as AI technology implies corporate capture (i.e. as long as we don't have good-enough Open Source AI), I doubt AI will have any positive impact on society.\nConclusion: our most urgent problem is how to protect ourselves against short-term AI damage.",
        "user": "UJBAJNFLK",
        "ts": "1679739804.701319",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "+eRTy",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Thanks "
                            },
                            {
                                "type": "user",
                                "user_id": "U5STGTB3J"
                            },
                            {
                                "type": "text",
                                "text": " for describing very well what I meant with denial-of-service attack.\n\nTwo additions:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "The current AI developments are obviously an important step in the evolution of information technology, which is what our focus here is. But from the wider perspective of society, or even just technology, it's a long-term concern. The immediate problems society has to deal with are largely unrelated to AI. That's why I see the denial-of-service attack as so problematic."
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "As long as AI technology implies corporate capture (i.e. as long as we don't have good-enough Open Source AI), I doubt AI will have any positive impact on society."
                                    }
                                ]
                            }
                        ],
                        "style": "ordered",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nConclusion: our most urgent problem is how to protect ourselves against short-term AI damage."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UJBAJNFLK",
            "ts": "1679739939.000000"
        },
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "reactions": [
            {
                "name": "cake",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "C357AC0D-03E5-4BC9-B22F-4A298B9A71C1",
        "type": "message",
        "text": "I said elsewhere that I\u2019m sort of optimistic about all this, because I think it gets us to the tipping point of realizing what we've been doing in tech all along: The main objective of most technologies has been for a while to make a rich person (usually an old white dude) even richer. Positive changes to society were basically happy accidents along the way, and we've accepted a lot of not-so-happy accidents along the way too.\n\nIf generative AI transforms business and creative industries as it looks it will, it'll just become harder for tech leaders to pretend that tech is neutral and there's no need to take any responsibility for \u201ca little bit of disruptive innovation\u201d.\n\nI misleadingly proposed it as a naturally following consequence elsewhere, but let me rephrase that as just a hope I personally have: If an AI can do what you can do as well or better than you can do it, than we need to ask ourselves, \u201cWhat is it that I can contribute that AI can't?\u201d And I personally am in love with that question. For me, it is a tough question, but just the process of pondering it already leads to great places and a much deeper sense of purpose and significance than I ever felt in any tech job before.",
        "user": "U5STGTB3J",
        "ts": "1679744980.610859",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "tUJKT",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I said elsewhere that "
                            },
                            {
                                "type": "text",
                                "text": "I\u2019m"
                            },
                            {
                                "type": "text",
                                "text": " sort of optimistic about all this, because I think it gets us to the tipping point of realizing what we've been doing in tech all along: The main objective of most technologies has been for a while to make a rich person (usually an old white dude) even richer"
                            },
                            {
                                "type": "text",
                                "text": "."
                            },
                            {
                                "type": "text",
                                "text": " Positive changes to society were basically happy accidents along the way, and we've accepted a lot of not-so-happy accidents along the way too.\n\nIf generative AI transforms business and creative industries as it looks it will, it'll just become harder for tech leaders to pretend that tech is neutral and there's no need to take any responsibility for \u201ca little bit of disruptive innovation\u201d.\n\nI misleadingly proposed it as a naturally following consequence elsewhere, but let me rephrase that as just a hope I personally have: If an AI can do what you can do as well or better than you can do it, than we need to ask ourselves, \u201cWhat is it that I can contribute that AI can't?\u201d And I personally am in love with that question. For me, it is a tough question, but just the process of pondering it already leads to great places and a much deeper sense of purpose and significance than I ever felt in any tech job before."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "reactions": [
            {
                "name": "thinking_face",
                "users": [
                    "UA14TGLTC"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "7A76A319-0965-4FAE-AE97-E02EAB699A72",
        "type": "message",
        "text": "AI is inauthentic. So taking capitalism as a given, whenever customers value authenticity you'll find humans doing work that could have been done by an AI.",
        "user": "UC2A2ARPT",
        "ts": "1679753480.307179",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "ZOBv2",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "AI is inauthentic. So taking capitalism as a given, whenever customers value authenticity you'll find humans doing work that could have been done by an AI"
                            },
                            {
                                "type": "text",
                                "text": "."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC"
    },
    {
        "client_msg_id": "296acb88-80a2-438c-9555-0e4d096c36b4",
        "type": "message",
        "text": "I found this video to be therapeutic: <https://www.youtube.com/watch?v=dxxCPdcMcFw> (If you dislike iOS or Swift, platform and language aren't really relevant for the point he\u2019s making; I encourage you to watch it anyway.)\n\nIt\u2019s good in demonstrating:\n\u2022 ChatGPT is far from good enough today \u2014 sure, it is likely to improve quickly, but we still have some more time to process this\n\u2022 If you really care about what you\u2019re doing, and you are willing to sweat the details, your results will likely be better in many ways, even as AI improves (one of these ways being more authentic, to connect it to what <@UC2A2ARPT> just wrote)\n\u2022 There\u2019s still lots of opportunity to reframe the question and ask, \u201cHow can we use AI to support us, instead of replace us?\"\nIt\u2019s up to us how we use these AI systems. Do we want them to automate (and eventually make us obsolete) or do we want them to augment? So far it looks like the same technology is equally capable to do either of these things. If AI is going to replace us seems to at least partially depend on how we choose to use it, what we ask it to do for us, and what results we are willing to settle with.",
        "user": "U5STGTB3J",
        "ts": "1679758571.195769",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "3ilPd",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I found this video to be therapeutic: "
                            },
                            {
                                "type": "link",
                                "url": "https://www.youtube.com/watch?v=dxxCPdcMcFw"
                            },
                            {
                                "type": "text",
                                "text": " (If you dislike iOS or Swift, platform and language aren't really relevant for the point he\u2019s making; I encourage you to watch it anyway.)\n\nIt\u2019s good in demonstrating:\n"
                            }
                        ]
                    },
                    {
                        "type": "rich_text_list",
                        "elements": [
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "ChatGPT is far from good enough today \u2014 sure, it is likely to improve quickly, but we still have some more time to process this"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "If you really care about what you\u2019re doing, and you are willing to sweat the details, your results will likely be better in many ways, even as AI improves (one of these ways being more authentic, to connect it to what "
                                    },
                                    {
                                        "type": "user",
                                        "user_id": "UC2A2ARPT"
                                    },
                                    {
                                        "type": "text",
                                        "text": " just wrote)"
                                    }
                                ]
                            },
                            {
                                "type": "rich_text_section",
                                "elements": [
                                    {
                                        "type": "text",
                                        "text": "There\u2019s still lots of opportunity to reframe the question and ask, \u201cHow can we use AI to support us, instead of replace us?\""
                                    }
                                ]
                            }
                        ],
                        "style": "bullet",
                        "indent": 0,
                        "border": 0
                    },
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\nIt\u2019s up to us how we use these AI systems. Do we want them to automate (and eventually make us obsolete) or do we want them to augment? So far it looks like the same technology is equally capable to do either of these things. If AI is going to replace us seems to at least partially depend on how we choose to use it, what we ask it to do for us, and what results we are willing to settle with."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "attachments": [
            {
                "from_url": "https://www.youtube.com/watch?v=dxxCPdcMcFw",
                "thumb_url": "https://i.ytimg.com/vi/dxxCPdcMcFw/hqdefault.jpg",
                "thumb_width": 480,
                "thumb_height": 360,
                "video_html": "<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/dxxCPdcMcFw?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Can ChatGPT write better SwiftUI code than you?\"></iframe>",
                "video_html_width": 400,
                "video_html_height": 225,
                "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png",
                "id": 1,
                "original_url": "https://www.youtube.com/watch?v=dxxCPdcMcFw",
                "fallback": "YouTube Video: Can ChatGPT write better SwiftUI code than you?",
                "title": "Can ChatGPT write better SwiftUI code than you?",
                "title_link": "https://www.youtube.com/watch?v=dxxCPdcMcFw",
                "author_name": "Paul Hudson",
                "author_link": "https://www.youtube.com/@twostraws",
                "service_name": "YouTube",
                "service_url": "https://www.youtube.com/"
            }
        ],
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC"
    },
    {
        "client_msg_id": "9d79be9a-f3ec-4378-af42-298853e3e41d",
        "type": "message",
        "text": "So far, people demonstrably prefer low price over authenticity. That might kick in, in the long run (it's the only hope for fiction IMO, but I think it's a pretty reasonable one). In the near term, people will continue to follow the money. The vast bulk of people won't be confident enough in any particular disaster scenario to sacrifice their (very real) short term cost concerns. They're not wrong: no one knows what's going to happen.\n\nI know I'm not fully processing even the full degree of uncertainty about the world. My brain kind of does a quick spin-up/safety shutdown routine when I try to think about it. What do atoms know when a crystal melts? Can they say whether they'll be integrated in the next structure, if/when the environment cools?\n\nBut of course there's the part of my brain trying to figure out if AI models can directly output structured data for VPLs instead of text. That doesn't stop.",
        "user": "U016VUZGUUQ",
        "ts": "1679775047.749719",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "OIiv",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "So far, people demonstrably prefer low price over authenticity. That might kick in, in the long run (it's the only hope for fiction IMO, but I think it's a pretty reasonable one). In the near term, people will continue to follow the money. The vast bulk of people won't be confident enough in any particular disaster scenario to sacrifice their (very real) short term cost concerns. They're not wrong: no one knows what's going to happen.\n\nI know I'm not fully processing even the full degree of uncertainty about the world. My brain kind of does a quick spin-up/safety shutdown routine when I try to think about it. What do atoms know when a crystal melts? Can they say whether they'll be integrated in the next structure, if/when the environment cools?\n\nBut of course there's the part of my brain trying to figure out if AI models can directly output structured data for VPLs instead of text. That doesn't stop."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "reactions": [
            {
                "name": "+1",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "BBCA515C-DAB5-4B00-8581-D3675C91EE7A",
        "type": "message",
        "text": "\"How can we use AI to support us, instead of replace us?\"\n\nIt's not up to \"us\", where by \"us\" I mean \"99.9999% of people\". As usual, the pervading fear doesn't stem directly from the technology itself, but rather how wealthy and powerful _people_ will use AI to further tighten their grip on the rest of the world.\n\nIt's exactly the same dynamic that makes most current human labour invisible and anonymous. I know who made my belt because it was hand-made for me (see: hipster), but I don't know who made my sneakers. I know who made the art on my walls, but not the art on the covers of my books. I know who made the music in my mp3 folder, but not the music in my streaming playlists.\n\nAI is going to intensify existing forces that separate creation and consumption. It's going to turn up the heat by a few degrees, but we're already on fire.\n\nThis makes me sound pessimistic, but I think I'm feeling more neutral than anything. My guess is that things will continue to go the way they have gone, at roughly the rate they've already been going, maybe a little quicker.",
        "user": "UC2A2ARPT",
        "ts": "1679776546.918969",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "XVm",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "\"How can we use AI to support us, instead of replace us?\"\n\nIt's not up to \"us\", where by \"us\" I mean \"99.9999% of people\". As usual, the pervading fear doesn't stem directly from the technology itself, but rather how wealthy and powerful "
                            },
                            {
                                "type": "text",
                                "text": "people",
                                "style": {
                                    "bold": false,
                                    "italic": true,
                                    "strike": false
                                }
                            },
                            {
                                "type": "text",
                                "text": " will use AI to further tighten their grip on the rest of the world.\n\nIt's exactly the same dynamic that makes most current human labour invisible and anonymous. I know who made my belt because it was hand-made for me (see: hipster), but I don't know who made my sneakers. I know who made the art on my walls, but not the art on the covers of my books. I know who made the music in my mp3 folder, but not the music in my streaming playlists.\n\nAI is going to intensify existing forces that separate creation and consumption. It's going to turn up the heat by a few degrees, but we're already on fire.\n\nThis makes me sound pessimistic, but I think I'm feeling more neutral than anything. My guess is that things will continue to go the way they have gone, at roughly the rate they've already been going, maybe a little quicker."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "UC2A2ARPT",
            "ts": "1679776935.000000"
        },
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "reactions": [
            {
                "name": "thinking_face",
                "users": [
                    "UA14TGLTC"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "93450af0-0154-4ddb-8704-b4113f0ad503",
        "type": "message",
        "text": "I hope so, but I'm afraid you're underestimating the orders of magnitude included on the scale under the heading \"On Fire\". I'm afraid it's going to be a lot quicker, not a little quicker.\n\nRemember that all the comforting takes about ChatGPT we've been hearing for the past few months are obsolete. Any conclusions drawn on the basis of GPT-3's weaknesses are obsolete. And I bet we're going to start from scratch again before anyone is ready (probably including OpenAI, judging by their appsec record to date).",
        "user": "U016VUZGUUQ",
        "ts": "1679777301.662669",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "BqE6M",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "I hope so, but I'm afraid you're underestimating the orders of magnitude included on the scale under the heading \"On Fire\". I'm afraid it's going to be a lot quicker, not a little quicker.\n\nRemember that all the comforting takes about ChatGPT we've been hearing for the past few months are obsolete. Any conclusions drawn on the basis of GPT-3's weaknesses are obsolete. And I bet we're going to start from scratch again before anyone is ready (probably including OpenAI, judging by their appsec record to date)."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "U016VUZGUUQ",
            "ts": "1679777362.000000"
        },
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "reactions": [
            {
                "name": "shrug",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            },
            {
                "name": "fire",
                "users": [
                    "UC2A2ARPT",
                    "UA14TGLTC"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "F6ED8222-37A3-41B8-9504-0DD385F62778",
        "type": "message",
        "text": "To be clear, I was talking about us, the people reading in this forum. We\u2019re not the 99.whatever%. We may not be Musk or Zuckerberg himself, but some of us here probably work for them. Or the next Musk or Zuckerberg could be reading here.\n\nYou may not be rich. You may feel powerless. But if you spend your time here, you are likely privileged. You likely work in tech, even if you\u2019re \u201cjust\u201d an IC \u201cfollowing orders\u201d. But how *we* decide to use AI has disproportionately more impact than those 99% you refer to. I\u2019d say a lot of it is up to us, here, now.\n\nI don\u2019t know what exactly to do about it either. I doubt anybody can. So we could all just agree that we\u2019re all f*cked and maybe there\u2019ll be a chance in the future where we can collectively look back and reminisce in how right we all were that this capitalism thing was ultimately toxic. Or we could try to paint faint pictures of worlds that could be, even if they\u2019re hopelessly unlikely to ever materialize. You know, like we pretend with all that visual programming stuff. :)",
        "user": "U5STGTB3J",
        "ts": "1679782798.148039",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "V31=x",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "To be clear, I was talking about us, the people reading in this forum. We\u2019re not the 99.whatever%. We may not be Musk or Zuckerberg himself, but some of us here probably work for them. Or the next Musk or Zuckerberg could be reading here.\n\nYou may not be rich. You may feel powerless. But if you spend your time here, you are likely privileged. You likely work in tech, even if you\u2019re \u201cjust\u201d an IC \u201cfollowing orders\u201d. But how "
                            },
                            {
                                "type": "text",
                                "text": "we",
                                "style": {
                                    "bold": true,
                                    "italic": false,
                                    "strike": false
                                }
                            },
                            {
                                "type": "text",
                                "text": " decide to use AI has disproportionately more impact than those 99% you refer to. I\u2019d say a lot of it is up to us, here, now.\n\nI don\u2019t know what exactly to do about it either. I doubt anybody can. So we could all just agree that we\u2019re all f*cked and maybe there\u2019ll be a chance in the future where we can collectively look back and reminisce in how right we all were that this capitalism thing was ultimately toxic. Or we could try to paint faint pictures of worlds that could be, even if they\u2019re hopelessly unlikely to ever materialize"
                            },
                            {
                                "type": "text",
                                "text": "."
                            },
                            {
                                "type": "text",
                                "text": " You know, like we pretend with all that visual programming stuff"
                            },
                            {
                                "type": "text",
                                "text": "."
                            },
                            {
                                "type": "text",
                                "text": " :)"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC",
        "reactions": [
            {
                "name": "cake",
                "users": [
                    "UC2A2ARPT",
                    "UA14TGLTC"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "4225CA70-AAD5-4FEA-A996-DBEE4A5256AC",
        "type": "message",
        "text": "We can also choose how (or how not) to use AI in our own lives, for our own pursuits. I'm really fond of Konrad's advice near the top of this thread: use open source AIs. Generalizing: use AI authentically.",
        "user": "UC2A2ARPT",
        "ts": "1679795014.514789",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "fClR",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "W"
                            },
                            {
                                "type": "text",
                                "text": "e can also choose how (or how not) to use AI in our own lives, for our own pursuits. I'm really fond of Konrad's advice near the top of this thread: use open source AIs. Generalizing: use AI authentically."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC"
    },
    {
        "client_msg_id": "395f1ade-b434-4a27-8f81-db9c624eb1e3",
        "type": "message",
        "text": "Not sure you\u2019d have that choice. If people around you use AI to get 10x productivity you\u2019d likely have to do the same\u2026",
        "user": "U01JNTE35QS",
        "ts": "1679857701.783789",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "wy+lU",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Not sure you\u2019d have that choice. If people around you use AI to get 10x productivity you\u2019d likely have to do the same\u2026"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1679642239.661619",
        "parent_user_id": "UA14TGLTC"
    }
]