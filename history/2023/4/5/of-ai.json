[
    {
        "client_msg_id": "969a7d90-a02e-4e00-885d-128267b9b409",
        "type": "message",
        "text": "So is it the case that `langchain` and `agents` are specifically built prompt templates that are backed with some fun interprocess coms, passing the results to various piped tools like a python / JS script to get the next \u2018prompt piece\u2019, and then looping until something \u2018correct\u2019 comes up? I feel <https://github.com/mpaepper/llm_agents> simplified the abstractions a bit to help me understand what was going on.",
        "user": "U04TXPZ1W3S",
        "ts": "1680724848.632619",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "xVy=",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "So is it the case that "
                            },
                            {
                                "type": "text",
                                "text": "langchain",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " and "
                            },
                            {
                                "type": "text",
                                "text": "agents",
                                "style": {
                                    "code": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " are specifically built prompt templates that are backed with some fun interprocess coms, passing the results to various piped tools like a python / JS script to get the next \u2018prompt piece\u2019, and then looping until something \u2018correct\u2019 comes up? I feel "
                            },
                            {
                                "type": "link",
                                "url": "https://github.com/mpaepper/llm_agents"
                            },
                            {
                                "type": "text",
                                "text": " simplified the abstractions a bit to help me understand what was going on."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "edited": {
            "user": "U04TXPZ1W3S",
            "ts": "1680724902.000000"
        },
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "U04LK1R1VC1"
                ],
                "count": 1
            }
        ]
    }
]