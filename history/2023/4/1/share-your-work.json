[
    {
        "client_msg_id": "7f01785c-b4e9-45b1-aabb-17a5564b52ea",
        "type": "message",
        "text": "Future of Coding \u2022 Episode 63\nBen Moseley &amp; Peter Marks \u2022 Out of the Tar Pit\n\ud808\udcb6 <https://futureofcoding.org/episodes/063>\n\n<https://moss.cs.iit.edu/cs100/papers/out-of-the-tar-pit.pdf|Out of the Tar Pit> is in the grand pantheon of great papers, beloved the world over, with just _so much influence_. The resurgence of Functional Programming over the past decade owes its very existence to the Tar Pit\u2019s snarling takedown of mutable state, championed by Hickey &amp; The Cloj-Co. Many a budding computational philosophizer \u2014 both of yours truly counted among them \u2014 have been led onward to the late great <https://futureofcoding.org/episodes/062|Bro86> by this paper\u2019s borrow of his _essence_ and _accident_. But is the paper _actually_ good? Like, really \u2014 is it _that_ good? Does it hold up to the blinding light of hindsight that 2023 offers? Is this episode actually an April Fools joke, or is it a serious episode that Ivan just delayed by a few weeks because of life circumstances and his own incoherent sense of humour? I can\u2019t tell.\n\nApologies in advance. Next time, we\u2019re going back to our usual format to discuss <https://en.wikipedia.org/wiki/INTERCAL|Intercal>.",
        "user": "UC2A2ARPT",
        "ts": "1680370755.360969",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "6Lo8p",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Future of Coding \u2022 Episode 63\nBen Moseley & Peter Marks \u2022 Out of the Tar Pit\n\ud808\udcb6 "
                            },
                            {
                                "type": "link",
                                "url": "https://futureofcoding.org/episodes/063"
                            },
                            {
                                "type": "text",
                                "text": "\n\n"
                            },
                            {
                                "type": "link",
                                "url": "https://moss.cs.iit.edu/cs100/papers/out-of-the-tar-pit.pdf",
                                "text": "Out of the Tar Pit"
                            },
                            {
                                "type": "text",
                                "text": " is in the grand pantheon of great papers, beloved the world over, with just "
                            },
                            {
                                "type": "text",
                                "text": "so much influence",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". The resurgence of Functional Programming over the past decade owes its very existence to the Tar Pit\u2019s snarling takedown of mutable state, championed by Hickey & The Cloj-Co. Many a budding computational philosophizer \u2014 both of yours truly counted among them \u2014 have been led onward to the late great "
                            },
                            {
                                "type": "link",
                                "url": "https://futureofcoding.org/episodes/062",
                                "text": "Bro86"
                            },
                            {
                                "type": "text",
                                "text": " by this paper\u2019s borrow of his "
                            },
                            {
                                "type": "text",
                                "text": "essence",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " and "
                            },
                            {
                                "type": "text",
                                "text": "accident",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": ". But is the paper "
                            },
                            {
                                "type": "text",
                                "text": "actually",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " good? Like, really \u2014 is it "
                            },
                            {
                                "type": "text",
                                "text": "that",
                                "style": {
                                    "italic": true
                                }
                            },
                            {
                                "type": "text",
                                "text": " good? Does it hold up to the blinding light of hindsight that 2023 offers? Is this episode actually an April Fools joke, or is it a serious episode that Ivan just delayed by a few weeks because of life circumstances and his own incoherent sense of humour? I can\u2019t tell.\n\nApologies in advance. Next time, we\u2019re going back to our usual format to discuss "
                            },
                            {
                                "type": "link",
                                "url": "https://en.wikipedia.org/wiki/INTERCAL",
                                "text": "Intercal"
                            },
                            {
                                "type": "text",
                                "text": "."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1680370755.360969",
        "reply_count": 4,
        "reply_users_count": 2,
        "latest_reply": "1680411839.411449",
        "reply_users": [
            "U02U0AS3J49",
            "UC2A2ARPT"
        ],
        "is_locked": false,
        "subscribed": false,
        "reactions": [
            {
                "name": "heart",
                "users": [
                    "U03CEGR3HSL",
                    "UMQ6LR9NZ",
                    "U03R0B9U1GD",
                    "UA14TGLTC"
                ],
                "count": 4
            },
            {
                "name": "headphones",
                "users": [
                    "UMQ6LR9NZ",
                    "U02U0AS3J49",
                    "U0123H7JRDM"
                ],
                "count": 3
            },
            {
                "name": "cake",
                "users": [
                    "U03R0B9U1GD",
                    "UBN9AFS0N"
                ],
                "count": 2
            }
        ]
    },
    {
        "client_msg_id": "65e38837-aad0-420f-8656-79b10e61a1e1",
        "type": "message",
        "text": "If you do programming by generating a LLM to do a task, you cannot use informal reasoning to understand the behaviour of your system. You can't even use formal reasoning. The run-state of the code is so far removed from what you wrote, you can't look at the source code and say \"oh, here's where I made it racist.\". That is a programming that informal reasoning doesn't work for. It requires that you are building systems that build systems, of course, and that it is the system two turtles down you are concerned with understanding. But still, I think it fits?",
        "user": "U02U0AS3J49",
        "ts": "1680387267.285919",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "UqCj",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "If you do programming by generating a LLM to do a task, you cannot use informal reasoning to understand the behaviour of your system. You can't even use formal reasoning. The run-state of the code is so far removed from what you wrote, you can't look at the source code and say \"oh, here's where I made it racist.\". That is a programming that informal reasoning doesn't work for. It requires that you are building systems that build systems, of course, and that it is the system two turtles down you are concerned with understanding. But still, I think it fits?"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1680370755.360969",
        "parent_user_id": "UC2A2ARPT",
        "reactions": [
            {
                "name": "amiga-tick",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "313efc9e-1887-4f0c-aa6f-83023511b7db",
        "type": "message",
        "text": ":point_up::skin-tone-2:That is my answer the challenge #1. Now challenge #2. In Blawx, it would be trivial to take a test, and generalize the inputs of that test by making them abducible, and run the query again. The answer to that second query would be a set of models, with constraints on unground variables, in which the query holds. Essentially, a description of all inputs that would have made your test pass. But of course, there is no reason to have the extra step of starting with a grounded test. You can go straight to the most general query, and say \"give me all the inputs for which the following assertion holds.\" But technically, I think that's an example of #2. The system could answer \"that test passes, because it is an example of this model, anything in that model would work. Also, here are all the other models that work.\" It's also the reason I'm really excited about its potential as a tool for generating tests that can be used to validate the legal reasoning of other systems.",
        "user": "U02U0AS3J49",
        "ts": "1680388464.340919",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "leVgt",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "emoji",
                                "name": "point_up",
                                "unicode": "261d-1f3fb",
                                "skin_tone": 2
                            },
                            {
                                "type": "text",
                                "text": "That is my answer the challenge #1. Now challenge #2. In Blawx, it would be trivial to take a test, and generalize the inputs of that test by making them abducible, and run the query again. The answer to that second query would be a set of models, with constraints on unground variables, in which the query holds. Essentially, a description of all inputs that would have made your test pass. But of course, there is no reason to have the extra step of starting with a grounded test. You can go straight to the most general query, and say \"give me all the inputs for which the following assertion holds.\" But technically, I think that's an example of #2. The system could answer \"that test passes, because it is an example of this model, anything in that model would work. Also, here are all the other models that work.\" It's also the reason I'm really excited about its potential as a tool for generating tests that can be used to validate the legal reasoning of other systems."
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1680370755.360969",
        "parent_user_id": "UC2A2ARPT",
        "reactions": [
            {
                "name": "amiga-tick",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    },
    {
        "client_msg_id": "97F5E441-C9E6-40C4-8A99-FAC12F9D7027",
        "type": "message",
        "text": "Great answers!",
        "user": "UC2A2ARPT",
        "ts": "1680402954.168419",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "hk2H",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Great answers!"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1680370755.360969",
        "parent_user_id": "UC2A2ARPT"
    },
    {
        "client_msg_id": "da79c858-8bf0-4854-b24b-6bf3254d1089",
        "type": "message",
        "text": "Great episode! I wonder if being bad at reasoning over specific examples drives one toward philosophy, which attempts to find broader truths. A weakness that creates a corresponding superpower?",
        "user": "U02U0AS3J49",
        "ts": "1680411839.411449",
        "blocks": [
            {
                "type": "rich_text",
                "block_id": "NF93",
                "elements": [
                    {
                        "type": "rich_text_section",
                        "elements": [
                            {
                                "type": "text",
                                "text": "Great episode! I wonder if being bad at reasoning over specific examples drives one toward philosophy, which attempts to find broader truths. A weakness that creates a corresponding superpower?"
                            }
                        ]
                    }
                ]
            }
        ],
        "team": "T5TCAFTA9",
        "thread_ts": "1680370755.360969",
        "parent_user_id": "UC2A2ARPT",
        "reactions": [
            {
                "name": "face_with_monocle",
                "users": [
                    "UC2A2ARPT"
                ],
                "count": 1
            }
        ]
    }
]